{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arumajirou/loto_forecast/blob/branch_20240506/%E4%BA%88%E6%B8%AC%E5%99%A8_0506.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tNopN-r2uSS"
      },
      "source": [
        "# **<font color='Blue'>ライブラリ、関数定義**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/ColabNotebooks/forecast_loto\n",
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "3-4eSuD2RNN9",
        "outputId": "37e595ee-d6fc-4156-aefd-3c9404658810"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ColabNotebooks/forecast_loto\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/ColabNotebooks/forecast_loto'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def git_save(git_email, git_username, git_token, git_repository):\n",
        "    \"\"\"\n",
        "    Gitコマンドを実行する関数\n",
        "\n",
        "    Parameters:\n",
        "    git_email (str): GitのユーザーEmail\n",
        "    git_username (str): Gitのユーザー名\n",
        "    git_token (str): Gitのトークン\n",
        "    git_repository (str): Gitのリポジトリ名\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # 新しいブランチ名を生成（現在の日付を使用）\n",
        "    branch_name = f\"branch_{datetime.now().strftime('%Y%m%d')}\"\n",
        "\n",
        "    # 実行するGitコマンドのリスト\n",
        "    commands = [\n",
        "        f\"git -C /content/drive/MyDrive/ColabNotebooks/forecast_loto init\",\n",
        "        f\"git config --global user.email {git_email}\",\n",
        "        f\"git config --global user.name  {git_username}\",\n",
        "        f\"git -C /content/drive/MyDrive/ColabNotebooks/forecast_loto checkout -b {branch_name}\",  # 新しいブランチを作成してチェックアウト\n",
        "        f\"git -C /content/drive/MyDrive/ColabNotebooks/forecast_loto add .\",\n",
        "        f\"git -C /content/drive/MyDrive/ColabNotebooks/forecast_loto commit -m 'Added new file.'\",\n",
        "        f\"git -C /content/drive/MyDrive/ColabNotebooks/forecast_loto remote remove origin\",  # 追加\n",
        "        f\"git -C /content/drive/MyDrive/ColabNotebooks/forecast_loto remote add origin https://{git_username}:{git_token}@github.com/{git_username}/{git_repository}.git\",\n",
        "        f\"git -C /content/drive/MyDrive/ColabNotebooks/forecast_loto remote set-url origin https://{git_username}:{git_token}@github.com/{git_username}/{git_repository}.git\",\n",
        "        f\"git -C /content/drive/MyDrive/ColabNotebooks/forecast_loto push -u origin {branch_name}\"  # 新しいブランチをプッシュ\n",
        "    ]\n",
        "\n",
        "    # 各コマンドを順に実行\n",
        "    for command in commands:\n",
        "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        stdout, stderr = process.communicate()\n",
        "\n",
        "        # エラーハンドリング\n",
        "        if process.returncode != 0:\n",
        "            print(f\"エラーが発生しました：\\n{stderr.decode()}\")\n",
        "            # text_to_speech(f\"エラーが発生しました。関数名: git_save, エラーメッセージ: {stderr.decode()}\")\n",
        "        else:\n",
        "            print(f\"成功：\\n{stdout.decode()}\")\n",
        "\n",
        "git_save(git_email, git_username, git_token, git_repository)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAFjYovfF3UN",
        "outputId": "67607b23-3183-481a-b2b0-d3f0cc2c0cb1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "成功：\n",
            "Reinitialized existing Git repository in /content/drive/MyDrive/ColabNotebooks/forecast_loto/.git/\n",
            "\n",
            "成功：\n",
            "\n",
            "成功：\n",
            "\n",
            "エラーが発生しました：\n",
            "fatal: A branch named 'branch_20240506' already exists.\n",
            "\n",
            "成功：\n",
            "\n",
            "エラーが発生しました：\n",
            "\n",
            "成功：\n",
            "\n",
            "成功：\n",
            "\n",
            "成功：\n",
            "\n",
            "成功：\n",
            "Branch 'branch_20240506' set up to track remote branch 'branch_20240506' from 'origin'.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "def run_git_command(cmd):\n",
        "    try:\n",
        "        output = subprocess.check_output(cmd, shell=True)\n",
        "        return output.decode('utf-8')\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"エラーが発生しました：{e.output.decode('utf-8')}\")\n",
        "        return ''\n",
        "\n",
        "# リポジトリのパスを指定します\n",
        "repo_path = \"/content/drive/MyDrive/ColabNotebooks/forecast_loto\"\n",
        "\n",
        "# ブランチ名を指定します\n",
        "branch_name = \"branch_20240506\"\n",
        "\n",
        "# リポジトリに移動します\n",
        "run_git_command(f\"cd {repo_path}\")\n",
        "\n",
        "# ブランチが存在するかどうかを確認します\n",
        "branches = run_git_command(\"git branch\")\n",
        "if branch_name in branches:\n",
        "    print(f\"ブランチ '{branch_name}' は既に存在します。\")\n",
        "else:\n",
        "    # ブランチを作成します\n",
        "    run_git_command(f\"git checkout -b {branch_name}\")\n",
        "\n",
        "# ファイルをステージングします\n",
        "run_git_command(\"git add .\")\n",
        "\n",
        "# コミットします\n",
        "run_git_command(\"git commit -m 'ローカルの変更をコミット'\")\n",
        "\n",
        "# リモートにプッシュします\n",
        "push_output = run_git_command(f\"git push origin {branch_name}\")\n",
        "if \"rejected\" in push_output:\n",
        "    print(\"リモートの変更を取得してマージします\")\n",
        "    run_git_command(f\"git pull origin {branch_name}\")\n",
        "    run_git_command(f\"git push origin {branch_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fIediOYPrG1",
        "outputId": "3ba3c755-61ca-4248-bdff-3cf565c59087"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "エラーが発生しました：\n",
            "エラーが発生しました：\n",
            "エラーが発生しました：\n",
            "エラーが発生しました：\n",
            "エラーが発生しました：\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-K5xO_cWJyQ",
        "outputId": "d2b8ab55-54f3-41d3-d6fb-3fdd1670715b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gtts in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.2.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/ColabNotebooks/forecast_loto\n",
            "Initialized empty Git repository in /content/drive/MyDrive/ColabNotebooks/forecast_loto/.git/\n",
            "/content\n",
            "成功：\n",
            "Reinitialized existing Git repository in /content/drive/MyDrive/ColabNotebooks/forecast_loto/.git/\n",
            "\n",
            "成功：\n",
            "\n",
            "成功：\n",
            "\n",
            "成功：\n",
            "\n",
            "エラーが発生しました：\n",
            "\n",
            "エラーが発生しました：\n",
            "error: No such remote: 'origin'\n",
            "\n",
            "成功：\n",
            "\n",
            "成功：\n",
            "\n",
            "エラーが発生しました：\n",
            "From https://github.com/arumajirou/loto_forecast\n",
            " * branch            main       -> FETCH_HEAD\n",
            " * [new branch]      main       -> origin/main\n",
            "error: could not apply c9f05a8... Commit on 2024-05-06 22:49:37\n",
            "hint: Resolve all conflicts manually, mark them as resolved with\n",
            "hint: \"git add/rm <conflicted_files>\", then run \"git rebase --continue\".\n",
            "hint: You can instead skip this commit: run \"git rebase --skip\".\n",
            "hint: To abort and get back to the state before \"git rebase\", run \"git rebase --abort\".\n",
            "Could not apply c9f05a8... Commit on 2024-05-06 22:49:37\n",
            "\n",
            "エラーが発生しました：\n",
            "To https://github.com/arumajirou/loto_forecast.git\n",
            " ! [rejected]        main -> main (non-fast-forward)\n",
            "error: failed to push some refs to 'https://github.com/arumajirou/loto_forecast.git'\n",
            "hint: Updates were rejected because a pushed branch tip is behind its remote\n",
            "hint: counterpart. Check out this branch and integrate the remote changes\n",
            "hint: (e.g. 'git pull ...') before pushing again.\n",
            "hint: See the 'Note about fast-forwards' in 'git push --help' for details.\n",
            "\n",
            "CPU times: user 132 ms, sys: 20.2 ms, total: 152 ms\n",
            "Wall time: 17.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#@title ドライブのマウント\n",
        "import subprocess\n",
        "!pip install gtts\n",
        "!pip install -q gitpython\n",
        "# 必要なライブラリをインポートします\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "\n",
        "def text_to_speech(text, lang='ja'):\n",
        "    \"\"\"\n",
        "    テキストを音声に変換する関数\n",
        "\n",
        "    Parameters:\n",
        "    text (str): 音声に変換したいテキスト\n",
        "    lang (str): 使用する言語のコード（デフォルトは日本語）\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # gTTSオブジェクトを作成します\n",
        "        tts = gTTS(text=text, lang=lang)\n",
        "        # 音声ファイルを作成します\n",
        "        tts.save('output.mp3')\n",
        "        # 音声ファイルを再生します\n",
        "        return Audio('output.mp3', autoplay=True)\n",
        "    except Exception as e:\n",
        "        print(f\"エラーが発生しました: {e}\")\n",
        "\n",
        "# 関数の使用例\n",
        "text_to_speech('こんにちは、世界')\n",
        "\n",
        "import os\n",
        "import pytz\n",
        "import shutil\n",
        "from datetime import datetime as dt\n",
        "from git import Repo\n",
        "import configparser\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ConfigParserオブジェクトの作成\n",
        "config = configparser.ConfigParser()\n",
        "config.read('/content/drive/MyDrive/config.ini')\n",
        "\n",
        "# Gitの設定\n",
        "git_username  = config['DEFAULT']['GIT_USERNAME']\n",
        "git_email = config['DEFAULT']['GIT_EMAIL']\n",
        "git_repository = config['DEFAULT']['GIT_REPOSITORY']\n",
        "git_token =  config['DEFAULT']['git_token']\n",
        "git_pass =  config['DEFAULT']['git_pass']\n",
        "%cd /content/drive/MyDrive/ColabNotebooks/forecast_loto/\n",
        "\n",
        "# ディレクトリのパスを指定\n",
        "dir_path = '/content/drive/MyDrive/ColabNotebooks/forecast_loto/.git'\n",
        "\n",
        "# ディレクトリが存在するかどうかを確認\n",
        "if os.path.exists(dir_path):\n",
        "    # ディレクトリを削除\n",
        "    shutil.rmtree(dir_path)\n",
        "    text_to_speech(f'ディレクトリ {dir_path} は削除されました。')\n",
        "else:\n",
        "    text_to_speech(f'ディレクトリ {dir_path} は存在しません。')\n",
        "\n",
        "!git init\n",
        "os.system(f\"git config --global user.email {git_email}\")\n",
        "os.system(f\"git config --global user.name  {git_username}\")\n",
        "os.system(f\"git config --global init.defaultBranch main\")\n",
        "os.system(\"git branch -m main\")\n",
        "\n",
        "!git add .\n",
        "# 現在の日付と時刻を取得（日本時間）\n",
        "now = dt.now(pytz.timezone('Asia/Tokyo'))\n",
        "# 日付と時刻を文字列に変換\n",
        "datetime_str = now.strftime('%Y-%m-%d %H:%M:%S')\n",
        "# コミットメッセージを作成\n",
        "commit_message = f\"Commit on {datetime_str}\"\n",
        "# git commitコマンドを実行\n",
        "os.system(f'git commit -m \"{commit_message}\"')\n",
        "%cd /content/\n",
        "git_save(git_email, git_username, git_token, git_repository)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oXbMHVr2qJts",
        "outputId": "5880da76-0027-495e-e00e-6dd50c736e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "パッケージが見つかりませんでした。インストールを開始します。\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">パッケージが見つかりませんでした。インストールを開始します。\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba) (0.41.1)\n",
            "Requirement already satisfied: numpy<1.27,>=1.22 in /usr/local/lib/python3.10/dist-packages (from numba) (1.25.2)\n",
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7394 sha256=1b1c44668d4d5457360fcf8227d8072b6490d5489454acda1916f53fe6d64a74\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Collecting uv\n",
            "  Downloading uv-0.1.39-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uv\n",
            "Successfully installed uv-0.1.39\n",
            "Using Python 3.10.12 interpreter at: \u001b[36m/usr/bin/python3\u001b[39m\n",
            "Creating virtualenv at: \u001b[36m.venv\u001b[39m\n",
            "Activate with: \u001b[32msource .venv/bin/activate\u001b[39m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m46 packages\u001b[0m in 1.33s\u001b[0m\n",
            "\u001b[2K\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m htmlmin\u001b[2m==0.1.12\u001b[0m                                                        \u001b[2mDownloaded \u001b[1m46 packages\u001b[0m in 2.67s\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m46 packages\u001b[0m in 98ms\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==23.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2024.2.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.3.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcontourpy\u001b[0m\u001b[2m==1.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcycler\u001b[0m\u001b[2m==0.12.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdacite\u001b[0m\u001b[2m==1.8.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfonttools\u001b[0m\u001b[2m==4.51.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhtmlmin\u001b[0m\u001b[2m==0.1.12\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mimagehash\u001b[0m\u001b[2m==4.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.4.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkiwisolver\u001b[0m\u001b[2m==1.4.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.42.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==2.1.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.8.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmultimethod\u001b[0m\u001b[2m==1.11.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.59.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==24.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.2.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpatsy\u001b[0m\u001b[2m==0.5.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mphik\u001b[0m\u001b[2m==0.12.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==10.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.18.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyparsing\u001b[0m\u001b[2m==3.1.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-dateutil\u001b[0m\u001b[2m==2.9.0.post0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2024.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpywavelets\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.31.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mscipy\u001b[0m\u001b[2m==1.11.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mseaborn\u001b[0m\u001b[2m==0.12.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.16.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstatsmodels\u001b[0m\u001b[2m==0.14.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.66.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtypeguard\u001b[0m\u001b[2m==4.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.11.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2024.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mvisions\u001b[0m\u001b[2m==0.7.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwordcloud\u001b[0m\u001b[2m==1.9.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mydata-profiling\u001b[0m\u001b[2m==4.7.0\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m20 packages\u001b[0m in 150ms\u001b[0m\n",
            "\u001b[2K\u001b[2mDownloaded \u001b[1m3 packages\u001b[0m in 1.51s\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m in 39ms\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mimportlib-resources\u001b[0m\u001b[2m==6.4.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mscipy\u001b[0m\u001b[2m==1.11.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mscipy\u001b[0m\u001b[2m==1.13.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msweetviz\u001b[0m\u001b[2m==2.3.1\u001b[0m\n",
            "Collecting stumpy\n",
            "  Downloading stumpy-1.12.0-py3-none-any.whl (169 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.1/169.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from stumpy) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from stumpy) (1.11.4)\n",
            "Requirement already satisfied: numba>=0.55.2 in /usr/local/lib/python3.10/dist-packages (from stumpy) (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.2->stumpy) (0.41.1)\n",
            "Installing collected packages: stumpy\n",
            "Successfully installed stumpy-1.12.0\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m13 packages\u001b[0m in 192ms\u001b[0m\n",
            "\u001b[2K\u001b[2mDownloaded \u001b[1m4 packages\u001b[0m in 602ms\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m4 packages\u001b[0m in 37ms\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mscikit-base\u001b[0m\u001b[2m==0.7.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.4.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msktime\u001b[0m\u001b[2m==0.29.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mthreadpoolctl\u001b[0m\u001b[2m==3.5.0\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m10 packages\u001b[0m in 11ms\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m10 packages\u001b[0m in 0.05ms\u001b[0m\n",
            "Collecting tsfresh\n",
            "  Downloading tsfresh-0.20.2-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (2.31.0)\n",
            "Requirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (2.0.3)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (1.11.4)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (0.14.2)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (0.5.6)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (1.2.2)\n",
            "Requirement already satisfied: tqdm>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (4.66.2)\n",
            "Requirement already satisfied: stumpy>=1.7.2 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (1.12.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from tsfresh) (2.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.0->tsfresh) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.0->tsfresh) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.0->tsfresh) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.4.1->tsfresh) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9.1->tsfresh) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9.1->tsfresh) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9.1->tsfresh) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9.1->tsfresh) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->tsfresh) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->tsfresh) (3.5.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13->tsfresh) (24.0)\n",
            "Requirement already satisfied: numba>=0.55.2 in /usr/local/lib/python3.10/dist-packages (from stumpy>=1.7.2->tsfresh) (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.2->stumpy>=1.7.2->tsfresh) (0.41.1)\n",
            "Installing collected packages: tsfresh\n",
            "Successfully installed tsfresh-0.20.2\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m18 packages\u001b[0m in 615ms\u001b[0m\n",
            "\u001b[2K\u001b[2mDownloaded \u001b[1m5 packages\u001b[0m in 149ms\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m5 packages\u001b[0m in 21ms\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcloudpickle\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfeaturetools\u001b[0m\u001b[2m==1.30.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mholidays\u001b[0m\u001b[2m==0.47\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==5.9.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwoodwork\u001b[0m\u001b[2m==0.30.0\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m10 packages\u001b[0m in 328ms\u001b[0m\n",
            "\u001b[2K\u001b[2mDownloaded \u001b[1m2 packages\u001b[0m in 117ms\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m in 14ms\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2024.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmodin\u001b[0m\u001b[2m==0.29.0\u001b[0m\n",
            "\u001b[2K  \u001b[31m×\u001b[0m No solution found when resolving dependencies:\n",
            "\u001b[31m  ╰─▶ \u001b[0mBecause andas==2.2.0 was not found in the package registry and you\n",
            "\u001b[31m      \u001b[0mrequire andas==2.2.0, we can conclude that the requirements are\n",
            "\u001b[31m      \u001b[0munsatisfiable.\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m in 8ms\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m in 0.04ms\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m in 1ms\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m in 0.04ms\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m2 packages\u001b[0m in 7ms\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m2 packages\u001b[0m in 0.04ms\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m2 packages\u001b[0m in 9ms\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m2 packages\u001b[0m in 0.05ms\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m5 packages\u001b[0m in 9ms\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m5 packages\u001b[0m in 0.04ms\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m6 packages\u001b[0m in 98ms\u001b[0m\n",
            "\u001b[2K\u001b[2mDownloaded \u001b[1m1 package\u001b[0m in 44ms\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m in 2ms\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhmmlearn\u001b[0m\u001b[2m==0.3.2\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m6 packages\u001b[0m in 95ms\u001b[0m\n",
            "\u001b[2K\u001b[2mDownloaded \u001b[1m1 package\u001b[0m in 223ms\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m in 2ms\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mseglearn\u001b[0m\u001b[2m==1.2.5\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m21 packages\u001b[0m in 1.47s\u001b[0m\n",
            "\u001b[2K\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m hopcroftkarp\u001b[2m==1.2.5\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m hopcroftkarp\u001b[2m==1.2.5\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m hopcroftkarp\u001b[2m==1.2.5\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m hopcroftkarp\u001b[2m==1.2.5\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m hopcroftkarp\u001b[2m==1.2.5\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m hopcroftkarp\u001b[2m==1.2.5\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m hopcroftkarp\u001b[2m==1.2.5\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m hopcroftkarp\u001b[2m==1.2.5\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m hopcroftkarp\u001b[2m==1.2.5\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m hopcroftkarp\u001b[2m==1.2.5\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m hopcroftkarp\u001b[2m==1.2.5\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m hopcroftkarp\u001b[2m==1.2.5\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m hopcroftkarp\u001b[2m==1.2.5\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m hopcroftkarp\u001b[2m==1.2.5\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m hopcroftkarp\u001b[2m==1.2.5\u001b[0m                                                    \u001b[2mDownloaded \u001b[1m6 packages\u001b[0m in 604ms\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m6 packages\u001b[0m in 8ms\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcython\u001b[0m\u001b[2m==3.0.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdeprecated\u001b[0m\u001b[2m==1.2.14\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhopcroftkarp\u001b[0m\u001b[2m==1.2.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpersim\u001b[0m\u001b[2m==0.3.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mripser\u001b[0m\u001b[2m==0.6.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwrapt\u001b[0m\u001b[2m==1.16.0\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m in 290ms\u001b[0m\n",
            "\u001b[2K\u001b[2mDownloaded \u001b[1m1 package\u001b[0m in 16ms\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m in 2ms\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjpholiday\u001b[0m\u001b[2m==0.1.10\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m8 packages\u001b[0m in 310ms\u001b[0m\n",
            "\u001b[2K\u001b[2mDownloaded \u001b[1m1 package\u001b[0m in 63ms\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m in 3ms\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtslearn\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m60 packages\u001b[0m in 943ms\u001b[0m\n",
            "\u001b[2K\u001b[2mDownloaded \u001b[1m28 packages\u001b[0m in 3.31s\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m28 packages\u001b[0m in 92ms\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mautoviz\u001b[0m\u001b[2m==0.1.904\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbleach\u001b[0m\u001b[2m==6.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbokeh\u001b[0m\u001b[2m==3.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.1.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcolorcet\u001b[0m\u001b[2m==3.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1memoji\u001b[0m\u001b[2m==2.11.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mholoviews\u001b[0m\u001b[2m==1.18.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhvplot\u001b[0m\u001b[2m==0.10.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlinkify-it-py\u001b[0m\u001b[2m==2.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkdown\u001b[0m\u001b[2m==3.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmdit-py-plugins\u001b[0m\u001b[2m==0.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnltk\u001b[0m\u001b[2m==3.8.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpandas-dq\u001b[0m\u001b[2m==1.29\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpanel\u001b[0m\u001b[2m==1.4.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mparam\u001b[0m\u001b[2m==2.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyamg\u001b[0m\u001b[2m==5.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyviz-comms\u001b[0m\u001b[2m==3.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2024.4.28\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mseaborn\u001b[0m\u001b[2m==0.12.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mseaborn\u001b[0m\u001b[2m==0.13.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtextblob\u001b[0m\u001b[2m==0.18.0.post0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtornado\u001b[0m\u001b[2m==6.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1muc-micro-py\u001b[0m\u001b[2m==1.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwebencodings\u001b[0m\u001b[2m==0.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mxgboost\u001b[0m\u001b[2m==1.6.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mxlrd\u001b[0m\u001b[2m==2.0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mxyzservices\u001b[0m\u001b[2m==2024.4.0\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m65 packages\u001b[0m in 1.23s\u001b[0m\n",
            "\u001b[2K\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A\u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-daq\u001b[2m==0.5.0\u001b[0m\n",
            "   \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m dash-colorscales\u001b[2m==0.0.4\u001b[0m                                                \u001b[2mDownloaded \u001b[1m32 packages\u001b[0m in 3.16s\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m33 packages\u001b[0m in 339ms\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbeautifulsoup4\u001b[0m\u001b[2m==4.12.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbrotli\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdash\u001b[0m\u001b[2m==2.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdash-bootstrap-components\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdash-colorscales\u001b[0m\u001b[2m==0.0.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdash-core-components\u001b[0m\u001b[2m==2.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdash-daq\u001b[0m\u001b[2m==0.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdash-html-components\u001b[0m\u001b[2m==2.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdash-table\u001b[0m\u001b[2m==5.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdtale\u001b[0m\u001b[2m==3.12.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1met-xmlfile\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mflask\u001b[0m\u001b[2m==2.2.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mflask-compress\u001b[0m\u001b[2m==1.15\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mflask-ngrok\u001b[0m\u001b[2m==0.0.25\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfuture\u001b[0m\u001b[2m==1.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mimportlib-metadata\u001b[0m\u001b[2m==7.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mitsdangerous\u001b[0m\u001b[2m==2.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkaleido\u001b[0m\u001b[2m==0.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlz4\u001b[0m\u001b[2m==4.3.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmissingno\u001b[0m\u001b[2m==0.5.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnest-asyncio\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopenpyxl\u001b[0m\u001b[2m==3.1.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mplotly\u001b[0m\u001b[2m==5.22.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mretrying\u001b[0m\u001b[2m==1.3.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==69.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msoupsieve\u001b[0m\u001b[2m==2.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msquarify\u001b[0m\u001b[2m==0.4.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstrsimpy\u001b[0m\u001b[2m==0.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtenacity\u001b[0m\u001b[2m==8.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwerkzeug\u001b[0m\u001b[2m==3.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mxarray\u001b[0m\u001b[2m==2024.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mzipp\u001b[0m\u001b[2m==3.18.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mzstandard\u001b[0m\u001b[2m==0.22.0\u001b[0m\n",
            "Collecting dataprep\n",
            "  Downloading dataprep-0.4.5-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0,>=3.6 in /usr/local/lib/python3.10/dist-packages (from dataprep) (3.9.5)\n",
            "Collecting bokeh<3,>=2 (from dataprep)\n",
            "  Downloading bokeh-2.4.3-py3-none-any.whl (18.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.5/18.5 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dask[array,dataframe,delayed]>=2022.3.0 in /usr/local/lib/python3.10/dist-packages (from dataprep) (2023.8.1)\n",
            "Requirement already satisfied: flask<3,>=2 in /usr/local/lib/python3.10/dist-packages (from dataprep) (2.2.5)\n",
            "Collecting flask_cors<4.0.0,>=3.0.10 (from dataprep)\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: ipywidgets<8.0,>=7.5 in /usr/local/lib/python3.10/dist-packages (from dataprep) (7.7.1)\n",
            "Collecting jinja2<3.1,>=3.0 (from dataprep)\n",
            "  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.6/133.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpath-ng<2.0,>=1.5 (from dataprep)\n",
            "  Downloading jsonpath_ng-1.6.1-py3-none-any.whl (29 kB)\n",
            "Collecting metaphone<0.7,>=0.6 (from dataprep)\n",
            "  Downloading Metaphone-0.6.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.7 in /usr/local/lib/python3.10/dist-packages (from dataprep) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.21 in /usr/local/lib/python3.10/dist-packages (from dataprep) (1.25.2)\n",
            "Collecting pandas<2.0,>=1.1 (from dataprep)\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<2.0,>=1.6 (from dataprep)\n",
            "  Downloading pydantic-1.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydot<2.0.0,>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from dataprep) (1.4.2)\n",
            "Collecting python-crfsuite==0.9.8 (from dataprep)\n",
            "  Downloading python_crfsuite-0.9.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-stdnum<2.0,>=1.16 (from dataprep)\n",
            "  Downloading python_stdnum-1.20-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.1.2 (from dataprep)\n",
            "  Downloading rapidfuzz-2.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex<2022.0.0,>=2021.8.3 (from dataprep)\n",
            "  Downloading regex-2021.11.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.0/764.0 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from dataprep) (1.11.4)\n",
            "Collecting sqlalchemy==1.3.24 (from dataprep)\n",
            "  Downloading SQLAlchemy-1.3.24.tar.gz (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm<5.0,>=4.48 in /usr/local/lib/python3.10/dist-packages (from dataprep) (4.66.2)\n",
            "Collecting varname<0.9.0,>=0.8.1 (from dataprep)\n",
            "  Downloading varname-0.8.3-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: wordcloud<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from dataprep) (1.9.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (4.0.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh<3,>=2->dataprep) (24.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh<3,>=2->dataprep) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh<3,>=2->dataprep) (6.0.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh<3,>=2->dataprep) (6.3.3)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from bokeh<3,>=2->dataprep) (4.11.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe,delayed]>=2022.3.0->dataprep) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe,delayed]>=2022.3.0->dataprep) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe,delayed]>=2022.3.0->dataprep) (2023.6.0)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe,delayed]>=2022.3.0->dataprep) (1.4.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe,delayed]>=2022.3.0->dataprep) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe,delayed]>=2022.3.0->dataprep) (7.1.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask<3,>=2->dataprep) (3.0.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask<3,>=2->dataprep) (2.2.0)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.10/dist-packages (from flask_cors<4.0.0,>=3.0.10->dataprep) (1.16.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (3.6.6)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (3.0.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.1,>=3.0->dataprep) (2.1.5)\n",
            "Collecting ply (from jsonpath-ng<2.0,>=1.5->dataprep)\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.7->dataprep) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.1->dataprep) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.1->dataprep) (2023.4)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot<2.0.0,>=1.4.2->dataprep) (3.1.2)\n",
            "Collecting asttokens<3.0.0,>=2.0.0 (from varname<0.9.0,>=0.8.1->dataprep)\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting executing<0.9.0,>=0.8.3 (from varname<0.9.0,>=0.8.1->dataprep)\n",
            "  Downloading executing-0.8.3-py2.py3-none-any.whl (16 kB)\n",
            "Collecting pure_eval<1.0.0 (from varname<0.9.0,>=0.8.1->dataprep)\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from wordcloud<2.0,>=1.8->dataprep) (3.7.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (3.18.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<8.0,>=7.5->dataprep) (6.1.12)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (4.9.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.2.0->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (1.0.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (6.5.5)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<4.0,>=3.6->dataprep) (3.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->dataprep) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->dataprep) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->dataprep) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->dataprep) (1.4.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.8.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (4.2.1)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (4.19.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (21.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.35.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.18.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.8.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.5.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.2.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (2.22)\n",
            "Building wheels for collected packages: sqlalchemy, metaphone\n",
            "  Building wheel for sqlalchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlalchemy: filename=SQLAlchemy-1.3.24-cp310-cp310-linux_x86_64.whl size=1252686 sha256=8ad75e88ff5b48bb9072656000138b889983e231a443071bffa6ca21bdc204c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/51/b3/3481e88d5a5ba95dd4aafedc9316774d941c4ba61cfb93add8\n",
            "  Building wheel for metaphone (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for metaphone: filename=Metaphone-0.6-py3-none-any.whl size=13902 sha256=3018ea980377fd6b2459aceab66f749550588adc9053368d60d8c1dc4aa724dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/dd/1d/6cdd346605db62bde1f60954155e9ce48f4681c243f265b704\n",
            "Successfully built sqlalchemy metaphone\n",
            "Installing collected packages: regex, python-stdnum, python-crfsuite, pure_eval, ply, metaphone, executing, sqlalchemy, rapidfuzz, pydantic, jsonpath-ng, jinja2, jedi, asttokens, varname, pandas, bokeh, flask_cors, dataprep\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2023.12.25\n",
            "    Uninstalling regex-2023.12.25:\n",
            "      Successfully uninstalled regex-2023.12.25\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.29\n",
            "    Uninstalling SQLAlchemy-2.0.29:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.29\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.7.1\n",
            "    Uninstalling pydantic-2.7.1:\n",
            "      Successfully uninstalled pydantic-2.7.1\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.3\n",
            "    Uninstalling Jinja2-3.1.3:\n",
            "      Successfully uninstalled Jinja2-3.1.3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.3\n",
            "    Uninstalling pandas-2.0.3:\n",
            "      Successfully uninstalled pandas-2.0.3\n",
            "  Attempting uninstall: bokeh\n",
            "    Found existing installation: bokeh 3.3.4\n",
            "    Uninstalling bokeh-3.3.4:\n",
            "      Successfully uninstalled bokeh-3.3.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.2.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nccl-cu12==2.19.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "bigframes 1.4.0 requires sqlalchemy<3.0dev,>=1.4, but you have sqlalchemy 1.3.24 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 1.5.3 which is incompatible.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.3.24 which is incompatible.\n",
            "panel 1.3.8 requires bokeh<3.4.0,>=3.2.0, but you have bokeh 2.4.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asttokens-2.4.1 bokeh-2.4.3 dataprep-0.4.5 executing-0.8.3 flask_cors-3.0.10 jedi-0.19.1 jinja2-3.0.3 jsonpath-ng-1.6.1 metaphone-0.6 pandas-1.5.3 ply-3.11 pure_eval-0.2.2 pydantic-1.10.15 python-crfsuite-0.9.8 python-stdnum-1.20 rapidfuzz-2.15.2 regex-2021.11.10 sqlalchemy-1.3.24 varname-0.8.3\n",
            "Collecting japanera\n",
            "  Downloading Japanera-2.1.1-py3-none-any.whl (18 kB)\n",
            "Collecting kanjize==1.4.0 (from japanera)\n",
            "  Downloading kanjize-1.4.0-py3-none-any.whl (5.4 kB)\n",
            "Installing collected packages: kanjize, japanera\n",
            "Successfully installed japanera-2.1.1 kanjize-1.4.0\n",
            "Collecting pyprobables\n",
            "  Downloading pyprobables-0.6.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyprobables\n",
            "Successfully installed pyprobables-0.6.0\n",
            "Collecting ray\n",
            "  Downloading ray-2.20.0-cp310-cp310-manylinux2014_x86_64.whl (65.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.4/65.4 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.14.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray) (24.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.31.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.35.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2024.2.2)\n",
            "Installing collected packages: ray\n",
            "Successfully installed ray-2.20.0\n",
            "Collecting neuralforecast\n",
            "  Downloading neuralforecast-1.7.1-py3-none-any.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coreforecast>=0.0.6 (from neuralforecast)\n",
            "  Downloading coreforecast-0.0.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.5/193.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (2023.6.0)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (1.5.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (2.2.1+cu121)\n",
            "Collecting pytorch-lightning>=2.0.0 (from neuralforecast)\n",
            "  Downloading pytorch_lightning-2.2.4-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.2/802.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ray[tune]>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (2.20.0)\n",
            "Collecting optuna (from neuralforecast)\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting utilsforecast>=0.0.25 (from neuralforecast)\n",
            "  Downloading utilsforecast-0.1.7-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->neuralforecast) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->neuralforecast) (2023.4)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (6.0.1)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning>=2.0.0->neuralforecast)\n",
            "  Downloading torchmetrics-1.4.0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (4.11.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning>=2.0.0->neuralforecast)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (3.14.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (1.0.8)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (3.20.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (2.31.0)\n",
            "Collecting tensorboardX>=1.9 (from ray[tune]>=2.2.0->neuralforecast)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (14.0.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (3.0.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->neuralforecast)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Collecting alembic>=1.5.0 (from optuna->neuralforecast)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna->neuralforecast)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna->neuralforecast) (1.3.24)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna->neuralforecast)\n",
            "  Downloading Mako-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec->neuralforecast) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning>=2.0.0->neuralforecast) (67.7.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.3.5->neuralforecast) (1.16.0)\n",
            "Collecting pretty-errors==1.2.25 (from torchmetrics>=0.7.0->pytorch-lightning>=2.0.0->neuralforecast)\n",
            "  Downloading pretty_errors-1.2.25-py3-none-any.whl (17 kB)\n",
            "Collecting colorama (from pretty-errors==1.2.25->torchmetrics>=0.7.0->pytorch-lightning>=2.0.0->neuralforecast)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->neuralforecast) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (0.35.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (0.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]>=2.2.0->neuralforecast) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]>=2.2.0->neuralforecast) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]>=2.2.0->neuralforecast) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]>=2.2.0->neuralforecast) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->neuralforecast) (1.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->neuralforecast) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->neuralforecast) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->neuralforecast) (4.0.3)\n",
            "Installing collected packages: tensorboardX, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, Mako, lightning-utilities, coreforecast, colorlog, colorama, pretty-errors, nvidia-cusparse-cu12, nvidia-cudnn-cu12, alembic, utilsforecast, optuna, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning, neuralforecast\n",
            "Successfully installed Mako-1.3.3 alembic-1.13.1 colorama-0.4.6 colorlog-6.8.2 coreforecast-0.0.8 lightning-utilities-0.11.2 neuralforecast-1.7.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 optuna-3.6.1 pretty-errors-1.2.25 pytorch-lightning-2.2.4 tensorboardX-2.6.2.2 torchmetrics-1.4.0 utilsforecast-0.1.7\n",
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.10/dist-packages (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.11.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (0.11.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch_lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.0.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->pytorch_lightning) (12.4.127)\n",
            "Requirement already satisfied: pretty-errors==1.2.25 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->pytorch_lightning) (1.2.25)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from pretty-errors==1.2.25->torchmetrics>=0.7.0->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch_lightning) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch_lightning) (1.3.0)\n",
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.26.1-py3-none-any.whl (3.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.7 (from virtualenv)\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.14.0)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (4.2.1)\n",
            "Installing collected packages: distlib, virtualenv\n",
            "Successfully installed distlib-0.3.8 virtualenv-20.26.1\n",
            "Collecting arch\n",
            "  Downloading arch-7.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (983 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.4/983.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from arch) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.10/dist-packages (from arch) (1.11.4)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.10/dist-packages (from arch) (1.5.3)\n",
            "Requirement already satisfied: statsmodels>=0.12 in /usr/local/lib/python3.10/dist-packages (from arch) (0.14.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->arch) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->arch) (2023.4)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.12->arch) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.12->arch) (24.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels>=0.12->arch) (1.16.0)\n",
            "Installing collected packages: arch\n",
            "Successfully installed arch-7.0.0\n",
            "Requirement already satisfied: ray[data,serve,train,tune] in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (3.14.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (24.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (2.31.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (1.5.3)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (2.6.2.2)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (14.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (2023.6.0)\n",
            "Collecting opencensus (from ray[data,serve,train,tune])\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi (from ray[data,serve,train,tune])\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting py-spy>=0.2.0 (from ray[data,serve,train,tune])\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (6.4.0)\n",
            "Collecting colorful (from ray[data,serve,train,tune])\n",
            "  Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (20.26.1)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (0.20.0)\n",
            "Collecting watchfiles (from ray[data,serve,train,tune])\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette (from ray[data,serve,train,tune])\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (3.9.5)\n",
            "Collecting aiohttp-cors (from ray[data,serve,train,tune])\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (1.10.15)\n",
            "Collecting uvicorn[standard] (from ray[data,serve,train,tune])\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (1.63.0)\n",
            "Collecting memray (from ray[data,serve,train,tune])\n",
            "  Downloading memray-1.12.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from ray[data,serve,train,tune]) (1.25.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[data,serve,train,tune]) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[data,serve,train,tune]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[data,serve,train,tune]) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[data,serve,train,tune]) (4.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[data,serve,train,tune]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[data,serve,train,tune]) (2023.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[data,serve,train,tune]) (4.11.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[data,serve,train,tune]) (0.3.8)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[data,serve,train,tune]) (4.2.1)\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi->ray[data,serve,train,tune])\n",
            "  Downloading fastapi_cli-0.0.2-py3-none-any.whl (9.1 kB)\n",
            "Collecting httpx>=0.23.0 (from fastapi->ray[data,serve,train,tune])\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->ray[data,serve,train,tune]) (3.0.3)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi->ray[data,serve,train,tune])\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->ray[data,serve,train,tune])\n",
            "  Downloading ujson-5.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.2.1 (from fastapi->ray[data,serve,train,tune])\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->ray[data,serve,train,tune])\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette->ray[data,serve,train,tune]) (3.7.1)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]->ray[data,serve,train,tune])\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]->ray[data,serve,train,tune])\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]->ray[data,serve,train,tune])\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->ray[data,serve,train,tune])\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]->ray[data,serve,train,tune])\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[data,serve,train,tune]) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[data,serve,train,tune]) (0.35.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[data,serve,train,tune]) (0.18.0)\n",
            "Requirement already satisfied: rich>=11.2.0 in /usr/local/lib/python3.10/dist-packages (from memray->ray[data,serve,train,tune]) (13.7.1)\n",
            "Collecting textual>=0.41.0 (from memray->ray[data,serve,train,tune])\n",
            "  Downloading textual-0.58.1-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.8/549.8 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencensus-context>=0.1.3 (from opencensus->ray[data,serve,train,tune])\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: six~=1.16 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[data,serve,train,tune]) (1.16.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[data,serve,train,tune]) (2.11.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray[data,serve,train,tune]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[data,serve,train,tune]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[data,serve,train,tune]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[data,serve,train,tune]) (2024.2.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->ray[data,serve,train,tune]) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->ray[data,serve,train,tune]) (1.2.1)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->ray[data,serve,train,tune])\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typer>=0.12.3 (from fastapi-cli>=0.0.2->fastapi->ray[data,serve,train,tune])\n",
            "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (1.63.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (2.27.0)\n",
            "Collecting httpcore==1.* (from httpx>=0.23.0->fastapi->ray[data,serve,train,tune])\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi->ray[data,serve,train,tune]) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.2.0->memray->ray[data,serve,train,tune]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.2.0->memray->ray[data,serve,train,tune]) (2.16.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (4.9)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.2.0->memray->ray[data,serve,train,tune]) (0.1.2)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.2.0->memray->ray[data,serve,train,tune]) (0.4.0)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.2.0->memray->ray[data,serve,train,tune]) (2.0.3)\n",
            "Collecting shellingham>=1.3.0 (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->ray[data,serve,train,tune])\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py>=2.2.0->rich>=11.2.0->memray->ray[data,serve,train,tune]) (1.0.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (0.6.0)\n",
            "Installing collected packages: py-spy, opencensus-context, colorful, websockets, uvloop, ujson, shellingham, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, watchfiles, uvicorn, starlette, httpcore, email_validator, typer, httpx, aiohttp-cors, textual, opencensus, memray, fastapi-cli, fastapi\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohttp-cors-0.7.0 colorful-0.5.6 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.2 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 memray-1.12.0 opencensus-0.11.4 opencensus-context-0.1.3 orjson-3.10.3 py-spy-0.3.14 python-dotenv-1.0.1 python-multipart-0.0.9 shellingham-1.5.4 starlette-0.37.2 textual-0.58.1 typer-0.12.3 ujson-5.9.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n",
            "Collecting ray[tune]==2.2.0\n",
            "  Downloading ray-2.2.0-cp310-cp310-manylinux2014_x86_64.whl (57.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from ray[tune]==2.2.0) (23.2.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]==2.2.0) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]==2.2.0) (3.14.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[tune]==2.2.0) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]==2.2.0) (1.0.8)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]==2.2.0) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray[tune]==2.2.0) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[tune]==2.2.0) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[tune]==2.2.0) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[tune]==2.2.0) (2.31.0)\n",
            "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.10/dist-packages (from ray[tune]==2.2.0) (20.26.1)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]==2.2.0) (1.63.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray[tune]==2.2.0) (24.0)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]==2.2.0) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ray[tune]==2.2.0) (1.5.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from ray[tune]==2.2.0) (0.9.0)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.10/dist-packages (from ray[tune]==2.2.0) (2.6.2.2)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.24->ray[tune]==2.2.0) (0.3.8)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.24->ray[tune]==2.2.0) (4.2.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]==2.2.0) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]==2.2.0) (0.35.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]==2.2.0) (0.18.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]==2.2.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]==2.2.0) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]==2.2.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]==2.2.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]==2.2.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]==2.2.0) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->ray[tune]==2.2.0) (1.16.0)\n",
            "Installing collected packages: ray\n",
            "  Attempting uninstall: ray\n",
            "    Found existing installation: ray 2.20.0\n",
            "    Uninstalling ray-2.20.0:\n",
            "      Successfully uninstalled ray-2.20.0\n",
            "Successfully installed ray-2.2.0\n",
            "Requirement already satisfied: hyperopt==0.2.7 in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hyperopt==0.2.7) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hyperopt==0.2.7) (1.11.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt==0.2.7) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt==0.2.7) (3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt==0.2.7) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt==0.2.7) (4.66.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt==0.2.7) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt==0.2.7) (0.10.9.7)\n",
            "Collecting bayesian-optimization==1.3.1\n",
            "  Downloading bayesian_optimization-1.3.1-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization==1.3.1) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization==1.3.1) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization==1.3.1) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization==1.3.1) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization==1.3.1) (3.5.0)\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.3.1\n",
            "Requirement already satisfied: tensorflow>=2.9.0 in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.9.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.9.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.9.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.9.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.9.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.9.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.9.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.9.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.9.0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.9.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.9.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.9.0) (3.2.2)\n",
            "Requirement already satisfied: ray[default] in /usr/local/lib/python3.10/dist-packages (2.2.0)\n",
            "Collecting ray[default]\n",
            "  Using cached ray-2.20.0-cp310-cp310-manylinux2014_x86_64.whl (65.4 MB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[default]) (3.14.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[default]) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray[default]) (24.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[default]) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray[default]) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[default]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[default]) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[default]) (2.31.0)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[default]) (3.9.5)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.10/dist-packages (from ray[default]) (0.7.0)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.10/dist-packages (from ray[default]) (0.5.6)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]) (0.3.14)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.10/dist-packages (from ray[default]) (0.11.4)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3 in /usr/local/lib/python3.10/dist-packages (from ray[default]) (1.10.15)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default]) (0.20.0)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default]) (6.4.0)\n",
            "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /usr/local/lib/python3.10/dist-packages (from ray[default]) (20.26.1)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]) (1.63.0)\n",
            "Requirement already satisfied: memray in /usr/local/lib/python3.10/dist-packages (from ray[default]) (1.12.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default]) (4.11.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]) (0.3.8)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]) (4.2.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[default]) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[default]) (0.35.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[default]) (0.18.0)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from memray->ray[default]) (3.0.3)\n",
            "Requirement already satisfied: rich>=11.2.0 in /usr/local/lib/python3.10/dist-packages (from memray->ray[default]) (13.7.1)\n",
            "Requirement already satisfied: textual>=0.41.0 in /usr/local/lib/python3.10/dist-packages (from memray->ray[default]) (0.58.1)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default]) (0.1.3)\n",
            "Requirement already satisfied: six~=1.16 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default]) (1.16.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default]) (2.11.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray[default]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[default]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[default]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[default]) (2024.2.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (1.63.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (2.27.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9->memray->ray[default]) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.2.0->memray->ray[default]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.2.0->memray->ray[default]) (2.16.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (4.9)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.2.0->memray->ray[default]) (0.1.2)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.2.0->memray->ray[default]) (0.4.0)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.2.0->memray->ray[default]) (2.0.3)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py>=2.2.0->rich>=11.2.0->memray->ray[default]) (1.0.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (0.6.0)\n",
            "Installing collected packages: ray\n",
            "  Attempting uninstall: ray\n",
            "    Found existing installation: ray 2.2.0\n",
            "    Uninstalling ray-2.2.0:\n",
            "      Successfully uninstalled ray-2.2.0\n",
            "Successfully installed ray-2.20.0\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m24 packages\u001b[0m in 323ms\u001b[0m\n",
            "\u001b[2K\u001b[2mDownloaded \u001b[1m22 packages\u001b[0m in 427ms\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m22 packages\u001b[0m in 69ms\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1masttokens\u001b[0m\u001b[2m==2.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcomm\u001b[0m\u001b[2m==0.2.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdecorator\u001b[0m\u001b[2m==5.1.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mexceptiongroup\u001b[0m\u001b[2m==1.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mexecuting\u001b[0m\u001b[2m==2.0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mipython\u001b[0m\u001b[2m==8.24.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mipyvue\u001b[0m\u001b[2m==1.11.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mipyvuetify\u001b[0m\u001b[2m==1.9.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mipywidgets\u001b[0m\u001b[2m==8.1.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyterlab-widgets\u001b[0m\u001b[2m==3.0.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmatplotlib-inline\u001b[0m\u001b[2m==0.1.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mparso\u001b[0m\u001b[2m==0.8.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpexpect\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mprompt-toolkit\u001b[0m\u001b[2m==3.0.43\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mptyprocess\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpure-eval\u001b[0m\u001b[2m==0.2.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.18.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstack-data\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtraitlets\u001b[0m\u001b[2m==5.14.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwcwidth\u001b[0m\u001b[2m==0.2.13\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwidgetsnbextension\u001b[0m\u001b[2m==4.0.10\u001b[0m\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.1-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.0)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-24.4.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-24.4.0 scikit-optimize-0.10.1\n",
            "Collecting ax-platform\n",
            "  Downloading ax_platform-0.4.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botorch==0.11.0 (from ax-platform)\n",
            "  Downloading botorch-0.11.0-py3-none-any.whl (624 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m625.0/625.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from ax-platform) (3.0.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ax-platform) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from ax-platform) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ax-platform) (1.2.2)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from ax-platform) (7.7.1)\n",
            "Requirement already satisfied: plotly>=5.12.0 in /usr/local/lib/python3.10/dist-packages (from ax-platform) (5.15.0)\n",
            "Collecting typeguard (from ax-platform)\n",
            "  Downloading typeguard-4.2.1-py3-none-any.whl (34 kB)\n",
            "Collecting pyre-extensions (from ax-platform)\n",
            "  Downloading pyre_extensions-0.0.30-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from botorch==0.11.0->ax-platform) (1.0.0)\n",
            "Requirement already satisfied: mpmath<=1.3,>=0.19 in /usr/local/lib/python3.10/dist-packages (from botorch==0.11.0->ax-platform) (1.3.0)\n",
            "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from botorch==0.11.0->ax-platform) (2.2.1+cu121)\n",
            "Collecting pyro-ppl>=1.8.4 (from botorch==0.11.0->ax-platform)\n",
            "  Downloading pyro_ppl-1.9.0-py3-none-any.whl (745 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m745.2/745.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gpytorch==1.11 (from botorch==0.11.0->ax-platform)\n",
            "  Downloading gpytorch-1.11-py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.1/266.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting linear-operator==0.5.1 (from botorch==0.11.0->ax-platform)\n",
            "  Downloading linear_operator-0.5.1-py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.5/174.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jaxtyping>=0.2.9 (from linear-operator==0.5.1->botorch==0.11.0->ax-platform)\n",
            "  Downloading jaxtyping-0.2.28-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typeguard (from ax-platform)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.12.0->ax-platform) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=5.12.0->ax-platform) (24.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ax-platform) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ax-platform) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ax-platform) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ax-platform) (3.6.6)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ax-platform) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ax-platform) (3.0.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->ax-platform) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ax-platform) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ax-platform) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->ax-platform) (1.25.2)\n",
            "Collecting typing-inspect (from pyre-extensions->ax-platform)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyre-extensions->ax-platform) (4.11.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ax-platform) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ax-platform) (3.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->ax-platform) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->ax-platform) (6.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ax-platform) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ax-platform) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ax-platform) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ax-platform) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ax-platform) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ax-platform) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ax-platform) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ax-platform) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ax-platform) (4.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.8.4->botorch==0.11.0->ax-platform) (3.3.0)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl>=1.8.4->botorch==0.11.0->ax-platform)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.8.4->botorch==0.11.0->ax-platform) (4.66.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->ax-platform) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch==0.11.0->ax-platform) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch==0.11.0->ax-platform) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch==0.11.0->ax-platform) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch==0.11.0->ax-platform) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch==0.11.0->ax-platform) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch==0.11.0->ax-platform) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch==0.11.0->ax-platform) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch==0.11.0->ax-platform) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch==0.11.0->ax-platform) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch==0.11.0->ax-platform) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch==0.11.0->ax-platform) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch==0.11.0->ax-platform) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch==0.11.0->ax-platform) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch==0.11.0->ax-platform) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch==0.11.0->ax-platform) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->botorch==0.11.0->ax-platform) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.1->botorch==0.11.0->ax-platform) (12.4.127)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (6.5.5)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect->pyre-extensions->ax-platform)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->ax-platform) (0.8.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (1.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->ax-platform) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->ax-platform) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (4.2.1)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (4.19.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (0.35.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (0.18.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (1.8.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (0.5.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (1.2.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ax-platform) (2.22)\n",
            "Installing collected packages: pyro-api, typeguard, mypy-extensions, typing-inspect, jaxtyping, pyre-extensions, pyro-ppl, linear-operator, gpytorch, botorch, ax-platform\n",
            "Successfully installed ax-platform-0.4.0 botorch-0.11.0 gpytorch-1.11 jaxtyping-0.2.28 linear-operator-0.5.1 mypy-extensions-1.0.0 pyre-extensions-0.0.30 pyro-api-0.1.2 pyro-ppl-1.9.0 typeguard-2.13.3 typing-inspect-0.9.0\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m17 packages\u001b[0m in 142ms\u001b[0m\n",
            "\u001b[2K\u001b[2mDownloaded \u001b[1m2 packages\u001b[0m in 69ms\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m in 5ms\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mshap\u001b[0m\u001b[2m==0.45.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mslicer\u001b[0m\u001b[2m==0.0.7\u001b[0m\n",
            "Requirement already satisfied: gtts in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.2.2)\n",
            "CPU times: user 1.96 s, sys: 399 ms, total: 2.36 s\n",
            "Wall time: 4min 27s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "%%time\n",
        "#@title **インストール**\n",
        "!pip install rich\n",
        "import pkg_resources\n",
        "from rich import print as dric\n",
        "# numbaがインストールされているか確認\n",
        "try:\n",
        "    dist = pkg_resources.get_distribution('scikit-optimize')\n",
        "    dric(f\" パッケージは既にインストールされています: {dist}\")\n",
        "    text_to_speech(f\"パッケージは既にインストールされています: {dist}\")\n",
        "except pkg_resources.DistributionNotFound:\n",
        "    dric(\"パッケージが見つかりませんでした。インストールを開始します。\")\n",
        "    text_to_speech(f\"パッケージが見つかりませんでした。インストールを開始します。\")\n",
        "    !pip install numba\n",
        "    !pip install gputil\n",
        "    !pip install uv\n",
        "    !uv venv\n",
        "    # On macOS and Linux.\n",
        "    !source .venv/bin/activate\n",
        "\n",
        "    !uv pip install -U ydata-profiling\n",
        "    !uv pip install -U sweetviz\n",
        "\n",
        "    !pip install -U stumpy\n",
        "    !uv pip install -U sktime\n",
        "    !uv pip install -U statsmodels\n",
        "\n",
        "    !pip install -U tsfresh\n",
        "    !uv pip install -U featuretools\n",
        "\n",
        "    !uv pip install  -U modin\n",
        "    !uv pip install  -U andas==2.2.0\n",
        "    !uv pip install -U numpy\n",
        "\n",
        "    !uv pip install -U urllib3\n",
        "    !uv pip install -U pywavelets\n",
        "\n",
        "    !uv pip install -U scipy\n",
        "    !uv pip install -U scikit-learn\n",
        "    !uv pip install -U hmmlearn\n",
        "\n",
        "    !uv pip install -U seglearn\n",
        "    !uv pip install -U ripser\n",
        "    !uv pip install -U jpholiday\n",
        "\n",
        "    !uv pip install -U  tslearn\n",
        "\n",
        "    !uv pip install -U  autoviz\n",
        "    !uv pip install -U  dtale\n",
        "    !pip install -U dataprep\n",
        "\n",
        "    !pip install -U japanera\n",
        "    !pip install -U pyprobables\n",
        "\n",
        "    !pip install -U ray\n",
        "    !pip install -U neuralforecast\n",
        "    !pip install -U pytorch_lightning\n",
        "    !pip install -U virtualenv\n",
        "    !pip install -U arch\n",
        "    !pip install -U \"ray[data,train,tune,serve]\"\n",
        "    !pip install \"ray[tune]==2.2.0\"\n",
        "    !pip install \"hyperopt==0.2.7\"\n",
        "    !pip install \"bayesian-optimization==1.3.1\"\n",
        "    !pip install \"tensorflow>=2.9.0\"\n",
        "    !pip install -U ray[default]\n",
        "    !uv pip install -U ipyvuetify\n",
        "    !pip install -U scikit-optimize\n",
        "    !pip install -U ax-platform\n",
        "    !uv pip install -U shap\n",
        "    !pip install gtts\n",
        "text_to_speech(f\"インストールが完了しました\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "mE2QJ6XjqByA",
        "outputId": "27fb3b38-09e7-42da-84c6-f1a625235d5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 11.7 s, sys: 3.31 s, total: 15 s\n",
            "Wall time: 19.9 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "%%time\n",
        "#@title **インポート**\n",
        "import sys\n",
        "sys.path.append('/content/.venv/lib/python3.10/site-packages')\n",
        "\n",
        "# 標準ライブラリ\n",
        "# ファイルとディレクトリ操作に関するライブラリ\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import logging\n",
        "# 日付と時間に関するライブラリ\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "# マルチプロセッシングに関するライブラリ\n",
        "\n",
        "import multiprocessing as mp\n",
        "import subprocess\n",
        "# メモリ上のテキストストリームを扱うためのライブラリ\n",
        "from io import StringIO\n",
        "\n",
        "# 型ヒントを提供するためのライブラリ\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "\n",
        "# トレースバック(エラー情報)を扱うためのライブラリ\n",
        "import traceback\n",
        "\n",
        "# サードパーティライブラリ\n",
        "# 数値計算とデータ分析に関するライブラリ\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "\n",
        "# URLとHTTPクライアントを扱うためのライブラリ\n",
        "import urllib.request\n",
        "import urllib3\n",
        "\n",
        "# 進行状況を表示するためのライブラリ\n",
        "\n",
        "\n",
        "# ハイパーパラメータチューニングのためのライブラリ\n",
        "from ray import tune\n",
        "\n",
        "# リッチテキストと美しい出力を提供するライブラリ\n",
        "from rich import print as dric\n",
        "\n",
        "# 高速化のためのライブラリ\n",
        "from numba import jit\n",
        "\n",
        "# 日付と時間に関するライブラリ\n",
        "import pytz\n",
        "import jpholiday\n",
        "import japanera\n",
        "\n",
        "# 対話的なウィジェットと出力表示を制御するためのライブラリ\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# 特徴量生成と抽出を行うためのライブラリ\n",
        "import featuretools as ft\n",
        "from tsfresh import extract_features\n",
        "\n",
        "# 統計モデルと科学技術計算を行うためのライブラリ\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats, interpolate, fftpack, signal\n",
        "from scipy.stats import norm, poisson, expon\n",
        "from scipy.signal import find_peaks, find_peaks_cwt\n",
        "\n",
        "# 時系列データ分析のためのライブラリ\n",
        "import stumpy\n",
        "import sktime\n",
        "import pywt\n",
        "import hmmlearn.hmm as hmm\n",
        "import seglearn\n",
        "\n",
        "# ディープラーニングのためのライブラリ\n",
        "import torch\n",
        "\n",
        "# 機械学習のためのライブラリ\n",
        "from sklearn import datasets\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.decomposition import PCA, FastICA\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, median_absolute_error\n",
        "\n",
        "# 時系列分析のためのライブラリ\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "# データ可視化のためのライブラリ\n",
        "import plotly.express as px\n",
        "import plotly.subplots as sp\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# ニューラルネットワーク予測のためのライブラリ\n",
        "import neuralforecast.auto as nfa\n",
        "\n",
        "# データ準備と探索的データ解析のためのライブラリ\n",
        "from dataprep.datasets import load_dataset\n",
        "from dataprep.eda import create_report\n",
        "from ydata_profiling import ProfileReport\n",
        "import dtale\n",
        "\n",
        "# インスペクションと対話的なウィジェットのためのライブラリ\n",
        "import inspect\n",
        "from ipywidgets import interact, IntSlider, Checkbox\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "%matplotlib inline\n",
        "\n",
        "pd.options.display.float_format = \"{:.2f}\".format\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import jpholiday\n",
        "import inspect\n",
        "import stumpy  # 確認したいモジュール名\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import stumpy\n",
        "from statsmodels.tsa.stattools import acf, pacf\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.arima_model import ARIMAResults\n",
        "from arch import arch_model\n",
        "\n",
        "from ray.util.multiprocessing import Pool\n",
        "from tsfresh import extract_features\n",
        "from tsfresh.utilities.dataframe_functions import impute\n",
        "from tsfresh import select_features\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import webbrowser\n",
        "from google.colab import output\n",
        "import os\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import os\n",
        "import ipyvuetify as v\n",
        "import ipyvue as vue\n",
        "from IPython.display import display\n",
        "import warnings\n",
        "import logging\n",
        "from tsfresh import select_features\n",
        "from tsfresh.utilities.dataframe_functions import impute\n",
        "import ray\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from sklearn.linear_model import LassoCV\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shap\n",
        "from tqdm.notebook import tqdm\n",
        "from neuralforecast.auto import *\n",
        "from neuralforecast import NeuralForecast\n",
        "# 必要なライブラリをインポートします\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "import plotly.express as px\n",
        "warnings.filterwarnings('ignore')\n",
        "text_to_speech(f\"インポートが完了しました\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFlAfDlF-K3F"
      },
      "outputs": [],
      "source": [
        "#@title　**関数の作成**\n",
        "%%time\n",
        "def copy_directories(src_dirs, dst_dir):\n",
        "    \"\"\"\n",
        "    指定されたソースディレクトリを宛先ディレクトリにコピーする関数\n",
        "    Args:\n",
        "        src_dirs (list): ソースディレクトリのパスのリスト\n",
        "        dst_dir (str): 宛先ディレクトリのパス\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 宛先ディレクトリが存在するかどうかを確認します\n",
        "        if not os.path.isdir(dst_dir):\n",
        "            dric(f\"[red bold]エラー: {dst_dir} は有効なディレクトリではありません。[/red bold]\")\n",
        "            return\n",
        "\n",
        "        for src_dir in src_dirs:\n",
        "            # ソースディレクトリが存在するかどうかを確認します\n",
        "            if os.path.isdir(src_dir):\n",
        "                dst_path = os.path.join(dst_dir, os.path.basename(src_dir))\n",
        "                shutil.copytree(src_dir, dst_path, dirs_exist_ok=True)\n",
        "                dric(f\"[green bold]{src_dir} を {dst_path} にコピーしました。[/green bold]\")\n",
        "            else:\n",
        "                dric(f\"[red bold]エラー: {src_dir} は有効なディレクトリではありません。[/red bold]\")\n",
        "                text_to_speech(f\"{src_dir} は有効なディレクトリではありません。\")\n",
        "    except FileNotFoundError:\n",
        "        dric(\"[red bold]エラー: ソースディレクトリが見つかりません。[/red bold]\")\n",
        "        text_to_speech(f\"ソースディレクトリが見つかりません。\")\n",
        "    except PermissionError:\n",
        "        dric(f\"[red bold]エラー: {dst_dir} への書き込み権限がありません。[/red bold]\")\n",
        "        text_to_speech(f\"{dst_dir} への書き込み権限がありません。\")\n",
        "    except Exception as e:\n",
        "        dric(f\"[red bold]エラー: 予期せぬエラーが発生しました: {e}[/red bold]\")\n",
        "        text_to_speech(f\"予期せぬエラーが発生しました: {e}\")\n",
        "@jit(nopython=True)\n",
        "def get_rokuyo(japanese_date) -> str:\n",
        "    \"\"\"\n",
        "    この関数は、日本の日付を受け取り、それを旧暦に変換し、対応する六曜を返します。\n",
        "\n",
        "    :param japanese_date: 変換する日本の日付。\n",
        "    :type japanese_date: JapaneseDate\n",
        "    :return: 対応する六曜。\n",
        "    :rtype: str\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 日本の日付を旧暦に変換します。\n",
        "        old_date = japanese_date.to_julian_date()\n",
        "\n",
        "        # 旧暦の日と月を足し算します。\n",
        "        month_day = int(old_date) % 100 + int(old_date * 100) % 100\n",
        "\n",
        "        # 足し算した結果を6で割った余りを計算します。\n",
        "        remainder = month_day % 6\n",
        "\n",
        "        # 六曜のリストを定義します。これは日本の伝統的なカレンダーシステムです。\n",
        "        rokuyo_list = [\"大安\", \"赤口\", \"先勝\", \"友引\", \"先負\", \"仏滅\"]\n",
        "\n",
        "        # 余りの数に対応する六曜をリストから選び、それを返します。\n",
        "        return rokuyo_list[remainder]\n",
        "    except Exception as e:\n",
        "        dric(f\"[red bold]エラー: 予期せぬエラーが発生しました: {e}[/red bold]\")\n",
        "        text_to_speech(f\"予期せぬエラーが発生しました: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def make_numbers(num: int) -> pd.DataFrame:\n",
        "    '''\n",
        "    この関数は、指定したナンバーズ（数値型）をウェブから取得し、pandasのデータフレームに格納します。\n",
        "\n",
        "    :param num: ウェブから取得するナンバーズの種類を指定します。int型。\n",
        "    :return: 取得したナンバーズのデータを格納したデータフレーム。pandas.DataFrame型。\n",
        "    '''\n",
        "    try:\n",
        "        # 指定されたナンバーズのデータをウェブから読み込みます。読み込んだデータはshift-jisでエンコードされています。\n",
        "        df = pd.read_table('http://vvslot.com/download.php?m=777&f=numbers' + str(num) + '.txt', encoding=\"shift-jis\", sep=\",\", names=[\"part\", \"date\", \"week\", \"eto\", \"抽選数字\"], parse_dates=[1], dtype='object')\n",
        "\n",
        "        # 新たなカラム\"LOTO\"を作成し、\"num\"と指定したナンバーズの種類（num）を連結した文字列を格納します。\n",
        "        df[\"LOTO\"] = \"num\" + str(num)\n",
        "\n",
        "        # データフレームを\"date\"カラム（日付）に基づいてソート（並び替え）します。\n",
        "        df = df.sort_values(by='date')\n",
        "\n",
        "        # 抽選数字の各桁を新しいカラムに分割して格納します。例えば、抽選数字が\"1234\"の場合、\"N1\"には\"1\"、\"N2\"には\"2\"、\"N3\"には\"3\"、\"N4\"には\"4\"が格納されます。\n",
        "        for i in range(4):\n",
        "            df[\"N\" + str(i + 1)] = df[\"抽選数字\"].str[i]\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        dric(f\"[red bold]エラーが発生しました: {e}[/red bold]\")\n",
        "        text_to_speech(f\"エラーが発生しました: {e}\")\n",
        "        dric(\"*\"*100)\n",
        "        return None\n",
        "\n",
        "\n",
        "def make_Bin5() -> pd.DataFrame:\n",
        "    '''\n",
        "    この関数は、ビンゴ5のデータをウェブから取得し、pandasのデータフレームに格納します。\n",
        "\n",
        "    :return: 取得したビンゴ5のデータを格納したデータフレーム。pandas.DataFrame型。\n",
        "    '''\n",
        "    try:\n",
        "        # ビンゴ5のデータをウェブから読み込みます。このデータはHTMLのテーブル形式です。\n",
        "        url = 'http://vvslot.com/bingo5_data.php'\n",
        "        df_Bin5 = pd.read_html(url)\n",
        "\n",
        "        # 読み込んだデータ（HTMLのテーブル）の中から、10番目（インデックスは9）のテーブルを取得します。\n",
        "        # 不要なカラム（\"Ｎ5\",'1等', '2等', '3等'）を削除します。\n",
        "        df_Bin5 = df_Bin5[9].drop([\"Ｎ5\",'1等', '2等', '3等'], axis=1)\n",
        "\n",
        "        # データフレームのカラム名を新しく設定します。\n",
        "        df_Bin5.columns = ['part','date','N1','N2','N3','N4','N5','N6','N7','N8']\n",
        "\n",
        "        # 'date'カラムのデータを日付型に変換します。この際、日付の形式を指定します。\n",
        "        df_Bin5['date'] = pd.to_datetime(df_Bin5['date'], format='%Y年%m月%d日')\n",
        "\n",
        "        # 新たなカラム\"LOTO\"を作成し、その値として\"Bin5\"を格納します。これは、このデータフレームがビンゴ5のデータであることを示します。\n",
        "        df_Bin5[\"LOTO\"] = \"Bin5\"\n",
        "\n",
        "        return df_Bin5\n",
        "\n",
        "    except Exception as e:\n",
        "        dric(f\"[red bold]エラーが発生しました。関数名: make_Bin5, エラーメッセージ: {str(e)}[/red bold]\\n{'*'*100}\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: make_Bin5, エラーメッセージ: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def make_loto(name: str = \"loto6\", col: int = 9, ln: int = 6, b: int = 1) -> pd.DataFrame:\n",
        "    '''\n",
        "    この関数は、指定されたロト（例：loto6）のデータをウェブから取得し、pandasのデータフレームに格納します。\n",
        "\n",
        "    :param name: 取得するロトの名前を指定します。デフォルトは\"loto6\"。str型。\n",
        "    :param col: 取得するカラムの数を指定します。デフォルトは9。int型。\n",
        "    :param ln: ナンバーの数を指定します。デフォルトは6。int型。\n",
        "    :param b: ボーナスの数を指定します。デフォルトは1。int型。\n",
        "    :return: 取得したロトのデータを格納したデータフレーム。pandas.DataFrame型。\n",
        "    '''\n",
        "    try:\n",
        "        # データフレームのカラム名を作成します。\"part\"、\"date\"、ナンバー(\"N1\"~\"N6\")、ボーナス(\"B1\")を含みます。\n",
        "        names = [\"part\", \"date\"] + [\"N\" + str(i) for i in range(1, ln + 1)] + [\"B\" + str(j) for j in range(1, b + 1)]\n",
        "\n",
        "        # 指定されたロトのデータをウェブから読み込みます。読み込んだデータはshift-jisでエンコードされています。\n",
        "        df = pd.read_table('https://' + name + '.thekyo.jp/data/' + name + '.csv', encoding=\"shift-jis\",\n",
        " sep=\",\", skiprows=1, usecols=list(range(col)), parse_dates=[1], names=names)  # datetimeの選択\n",
        "\n",
        "        # 新たなカラム\"LOTO\"を作成し、ロトの名前を格納します。これは、このデータフレームがどのロトのデータであることを示します。\n",
        "        df[\"LOTO\"] = name\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        dric(f\"[red bold]エラーが発生しました。関数名: make_loto, エラーメッセージ: {str(e)}[/red bold]\\n{'*'*100}\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: make_loto, エラーメッセージ: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "@jit(nopython=True)\n",
        "def one_hot_encode_week(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    '''\n",
        "    この関数は、データフレームの'week'カラムをワンホットエンコーディングします。\n",
        "\n",
        "    :param df: ワンホットエンコーディングを行うデータフレーム。pandas.DataFrame型。\n",
        "    :return: 'week'カラムをワンホットエンコーディングしたデータフレーム。pandas.DataFrame型。\n",
        "    '''\n",
        "    try:\n",
        "        # 'week'カラムの各値をワンホットエンコーディングします。これにより、'week'カラムの各値が新たなカラムとして追加されます。\n",
        "        week_dummies = pd.get_dummies(df['week'], prefix='week')\n",
        "\n",
        "        # オリジナルのデータフレームとワンホットエンコーディングしたデータフレームを連結します。\n",
        "        df = pd.concat([df, week_dummies], axis=1)\n",
        "\n",
        "        # 元の'week'カラムはもう必要ないので、データフレームから削除します。\n",
        "        df.drop('week', axis=1, inplace=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        dric(\"[red bold]エラーが発生しました。詳細は以下の通りです。[/red bold]\")\n",
        "        dric(\"[blue bold]関数名:[/blue bold] one_hot_encode_week\")\n",
        "        dric(\"[blue bold]エラーメッセージ:[/blue bold]\", e)\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: one_hot_encode_week, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "    return df\n",
        "\n",
        "def remove_directory(dir_path):\n",
        "    \"\"\"\n",
        "    指定したディレクトリが存在する場合、それを削除します。\n",
        "\n",
        "    Parameters:\n",
        "    dir_path (str): 削除するディレクトリのパス\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if os.path.exists(dir_path):\n",
        "            shutil.rmtree(dir_path)\n",
        "            dric(f\"[green bold]{dir_path}は正常に削除されました。[/green bold]\")\n",
        "        else:\n",
        "            dric(f\"[red bold]{dir_path}にディレクトリが見つかりませんでした。[/red bold]\")\n",
        "    except Exception as e:\n",
        "        dric(\"[red bold]エラーが発生しました。詳細は以下の通りです。[/red bold]\")\n",
        "        dric(\"[blue bold]関数名:[/blue bold] remove_directory\")\n",
        "        dric(\"[blue bold]エラーメッセージ:[/blue bold]\", e)\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: remove_directory, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def select_columns(df, select_loto):\n",
        "    \"\"\"\n",
        "    指定したカラム名を持つデータフレームから、必要なカラムのみを選択します。\n",
        "\n",
        "    Parameters:\n",
        "    df (pandas.DataFrame): 入力のデータフレーム\n",
        "    select_loto (str): 選択するカラム名のリスト\n",
        "\n",
        "    Returns:\n",
        "    pandas.DataFrame: 選択したカラムを持つデータフレーム\n",
        "    \"\"\"\n",
        "    try:\n",
        "        base_columns = ['part', 'date', 'week_月', 'week_木', 'week_水', 'week_火', 'week_金', 'eto_仏滅', 'eto_先勝', 'eto_先負', 'eto_友引', 'eto_大安', 'eto_赤口', 'is_hd_False', 'is_hd_True']\n",
        "        column_dict = {\n",
        "            'num3': ['N1', 'N2', 'N3'],\n",
        "            'num4': ['N1', 'N2', 'N3', 'N4'],\n",
        "            'Bin5': ['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7', 'N8'],\n",
        "            'mini': ['N1', 'N2', 'N3', 'N4', 'N5', 'B1'],\n",
        "            'loto6': ['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'B1'],\n",
        "            'loto7': ['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7', 'B1', 'B2']\n",
        "        }\n",
        "        targets = base_columns + column_dict[select_loto]\n",
        "        return df[targets]\n",
        "    except Exception as e:\n",
        "        dric(\"[red bold]エラーが発生しました。詳細は以下の通りです。[/red bold]\")\n",
        "        dric(\"[blue bold]関数名:[/blue bold] select_columns\")\n",
        "        dric(\"[blue bold]エラーメッセージ:[/blue bold]\", e)\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: select_columns, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def update_variables(df_leng, test_size, select_all_features):\n",
        "    \"\"\"\n",
        "    変数を更新する関数を定義します。\n",
        "\n",
        "    Parameters:\n",
        "    df_leng (int): データフレームの長さ\n",
        "    test_size (int): テストサイズ\n",
        "    select_all_features (bool): すべての特徴を選択するかどうか\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    global features_df_, Y_train_pre_df, Y_test_pre_df, feature, leng, horizon, freq\n",
        "    try:\n",
        "        dric(f\"df_leng={df_leng}, test_size={test_size}, select_all_features={select_all_features}\")\n",
        "        features_df_ = selected_loto_df.tail(df_leng)\n",
        "\n",
        "        # select_all_featuresがFalseの場合、'unique_id'、'y'、および'ds'のみを選択します\n",
        "        if not select_all_features:\n",
        "            Y_train_pre_df = features_df_.iloc[:-test_size]\n",
        "        if test_size == 0:\n",
        "            Y_test_pre_df = features_df_.iloc[-1:]\n",
        "            horizon = 1\n",
        "        else:\n",
        "            Y_test_pre_df = features_df_.iloc[-test_size:]\n",
        "            horizon = test_size\n",
        "        feature = len(Y_train_pre_df.columns)\n",
        "        leng = len(Y_train_pre_df)\n",
        "\n",
        "        freq = 'D'\n",
        "        dric(f\"[blue bold]df_leng:[/blue bold] {df_leng}, [blue bold]test_size:[/blue bold] {test_size}, [blue bold]feature:[/blue bold] {feature}, [blue bold]leng:[/blue bold] {leng}, [blue bold]horizon:[/blue bold] {horizon}, [blue bold]freq:[/blue bold] {freq}\")\n",
        "        dric(f\"selected_loto_dfからY_test_pre_dfとY_train_pre_dfを作成しました\")\n",
        "        text_to_speech(f\"selected_loto_dfからY_test_pre_dfとY_train_pre_dfを作成しました\")\n",
        "\n",
        "    except Exception as e:\n",
        "        dric(\"[red bold]エラーが発生しました。詳細は以下の通りです。[/red bold]\")\n",
        "        dric(\"[blue bold]関数名:[/blue bold] update_variables\")\n",
        "        dric(\"[blue bold]エラーメッセージ:[/blue bold]\", e)\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: update_variables, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "def reshape_dataframe(df):\n",
        "    \"\"\"\n",
        "    データフレームを再形成する関数\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pandas.DataFrame\n",
        "        再形成する対象のデータフレーム\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    reshaped_df : pandas.DataFrame\n",
        "        再形成されたデータフレーム\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if df is None:\n",
        "            raise ValueError(\"データフレームが定義されていません。\")\n",
        "        #dric(f\"df.columns={df.columns}\")\n",
        "            # Check if df is a DataFrame\n",
        "        if not isinstance(df, pd.DataFrame):\n",
        "            raise TypeError(f\"Expected pandas.DataFrame but got {type(df)}\")\n",
        "        # Check if df has columns attribute\n",
        "        if not hasattr(df, 'columns'):\n",
        "            raise AttributeError(\"データフレームには 'columns' 属性が必要です。\")\n",
        "        # n_cols を動的に取得\n",
        "        n_cols = [col for col in df.columns if 'N' in col and '_MA' not in col and '_MS' not in col and '_DF' not in col and '_cum' not in col]\n",
        "        if not n_cols:\n",
        "            raise ValueError(\"n_cols が空です。'N' を含む列がデータフレームに存在しません。\")\n",
        "        # n_ma_cols と n_cumsum_cols を n_cols から作成\n",
        "        n_ma_cols = [f\"{col}_MA\" for col in n_cols]\n",
        "        n_ms_cols = [f\"{col}_MS\" for col in n_cols]\n",
        "        n_df_cols = [f\"{col}_DF\" for col in n_cols]\n",
        "        n_cumsum_cols = [f\"{col}_cum\" for col in n_cols]\n",
        "\n",
        "        dric(f\"n_cols={n_cols}\")\n",
        "        non_n_cols = [col for col in df.columns if col not in n_cols + n_ma_cols + n_ms_cols+ n_df_cols+ n_cumsum_cols]\n",
        "\n",
        "        reshaped_df = pd.DataFrame()\n",
        "        for i, (n, ma, ms, diff, cumsum) in tqdm(enumerate(zip(n_cols, n_ma_cols, n_ms_cols, n_df_cols, n_cumsum_cols))):\n",
        "\n",
        "            temp_df = df[non_n_cols + [n, ma, ms, diff, cumsum]].copy()\n",
        "            temp_df.rename(columns={n: 'N', ma: 'N_MA', ms: 'N_MS', diff: 'N_DF', cumsum: 'N_cum'}, inplace=True)\n",
        "            temp_df['unique_id'] = i\n",
        "            reshaped_df = pd.concat([reshaped_df, temp_df])\n",
        "\n",
        "        reshaped_df.reset_index(drop=True, inplace=True)\n",
        "        reshaped_df[\"No\"] =reshaped_df[\"N\"]\n",
        "        reshaped_df = pd.get_dummies(reshaped_df, columns=['N'])\n",
        "        cols = reshaped_df.columns.drop('date')\n",
        "        reshaped_df[cols] = reshaped_df[cols].astype(int)\n",
        "\n",
        "        # カラム名の置換を効率的に行う\n",
        "        replacements = {\n",
        "            'N_': '',\n",
        "            'eto_': '',\n",
        "            'week_': '',\n",
        "            'True': '1',\n",
        "            'False': '0'\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            reshaped_df.columns = reshaped_df.columns.to_series().replace(replacements, regex=True)\n",
        "            dric(\"カラム名の置換が成功しました。\")\n",
        "            text_to_speech(\"カラム名の置換が成功しました。\")\n",
        "        except Exception as e:\n",
        "            dric(f\"カラム名の置換中にエラーが発生しました: {e}\")\n",
        "            text_to_speech(f\"カラム名の置換中にエラーが発生しました: {e}\")\n",
        "        cols = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "        reshaped_df.columns = [int(col) if col in cols else col for col in reshaped_df.columns]\n",
        "        #dric(f\"reshaped_df.columns={reshaped_df.columns}\")\n",
        "\n",
        "        return reshaped_df\n",
        "    except ValueError as e:\n",
        "        dric(f\"[red bold]エラー: {e}[/red bold]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: reshape_dataframe, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return reshaped_df\n",
        "    except Exception as e:\n",
        "        dric(f\"[red bold]予期しないエラー: {e}[/red bold]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: reshape_dataframe, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return reshaped_df\n",
        "\n",
        "# @jit(nopython=True)\n",
        "def filter_dataframe(change: dict = None) -> None:\n",
        " '''\n",
        " 選択された宝くじの種類に応じてデータフレームをフィルタリングする関数\n",
        "\n",
        " Args:\n",
        " change (dict, optional): ドロップダウンメニューの値が変更されたときに生成される辞書型のデータ。\n",
        " 'new'キーは新しく選択された値を表します。デフォルトはNone。\n",
        "\n",
        " Returns:\n",
        " None: この関数は何も返しません。ただし、グローバル変数filtered_dfが更新されます。\n",
        " '''\n",
        " # グローバル変数を参照します\n",
        " global filtered_df\n",
        " # ドロップダウンメニューで新しく選択された宝くじの種類を取得します\n",
        " # changeがNoneの場合、デフォルトで\"num4\"を選択します\n",
        " selected_column = change['new'] if change else \"num4\"\n",
        " # データフレームをフィルタリングします。\n",
        " # 選択された宝くじの種類の列が1の行だけを残します。\n",
        " try: # ここからエラーハンドリングを追加\n",
        "     filtered_df = df_encoded[df_encoded[selected_column] == 1]\n",
        " except NameError as e: # df_encodedが未定義の場合に発生する例外\n",
        "     dric(f\"データフレームdf_encodedが未定義です。{e}\")\n",
        "     text_to_speech(f\"データフレームdf_encodedが未定義です。{e}\")\n",
        "     traceback.print_exc()\n",
        "     raise e  # エラーを再度発生させてプログラムを終了します\n",
        "\n",
        " except KeyError as e: # 選択された宝くじの種類の列が存在しない場合に発生する例外\n",
        "     dric(f\"データフレームdf_encodedに{selected_column}という列がありません。{e}\")\n",
        "     text_to_speech(f\"データフレームdf_encodedに{selected_column}という列がありません。{e}\")\n",
        "     traceback.print_exc()\n",
        "     raise e  # エラーを再度発生させてプログラムを終了します\n",
        " else: # 例外が発生しなかった場合に実行する処理\n",
        "     # フィルタリングされたデータフレームをHTMLテーブルとして表示します。\n",
        "     #display(HTML(filtered_df.head().to_html()))\n",
        "     pass\n",
        " finally: # 例外の有無に関わらず必ず実行する処理\n",
        "     dric(f\"{selected_column}でフィルタリングしました。\")\n",
        "     text_to_speech(f\"{selected_column}でフィルタリングしました。\")\n",
        "\n",
        "\n",
        "def select_df():\n",
        "  '''\n",
        "  セレクトボックスを表示し、ユーザーが宝くじの種類を選択できるようにする関数\n",
        "\n",
        "  引数: なし\n",
        "  戻り値: なし\n",
        "  '''\n",
        "  try:\n",
        "      # セレクトボックスを表示します。ユーザーが選択するためのものです。\n",
        "      display(select_box)\n",
        "\n",
        "      # 選択された宝くじの種類が変わったときに上記の関数を呼び出すように設定します。\n",
        "      # この操作は「observe」と呼ばれ、ドロップダウンメニューの値が変更されるたびにfilter_dataframe関数が呼び出されるようにします。\n",
        "      select_box.observe(filter_dataframe, names='value')\n",
        "\n",
        "      # 初期状態でfilter_dataframe関数を呼び出し、デフォルトの\"Bin5\"でフィルタリングします。\n",
        "      filter_dataframe()\n",
        "  except Exception as e:\n",
        "      dric(\"[red bold]エラーが発生しました。詳細は以下の通りです。[/red bold]\")\n",
        "      dric(\"[blue bold]関数名:[/blue bold] select_df\")\n",
        "      dric(\"[blue bold]エラーメッセージ:[/blue bold]\", e)\n",
        "      text_to_speech(f\"エラーが発生しました。関数名: select_df, エラーメッセージ: {str(e)}\")\n",
        "      traceback.print_exc()\n",
        "\n",
        "\n",
        "def add_sum_of_cols(df, cols, new_col_name):\n",
        "    \"\"\"\n",
        "    指定された複数のカラムの合計値を新しいカラムとしてデータフレームに追加する関数\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pandas.DataFrame\n",
        "        合計値を追加する対象のデータフレーム\n",
        "    cols : list of str\n",
        "        合計値を計算するためのカラムのリスト\n",
        "    new_col_name : str\n",
        "        新しく追加するカラムの名前\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if df is None:\n",
        "            raise ValueError(\"データフレームが定義されていません。\")\n",
        "        if not set(cols).issubset(df.columns):\n",
        "            raise ValueError(\"一つまたはそれ以上のカラムがデータフレームに存在しません。\")\n",
        "        df[new_col_name] = df.loc[:, cols].sum(axis=1)\n",
        "    except ValueError as e:\n",
        "        dric(f\"[red bold]エラー: {e}[/red bold]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: add_sum_of_cols, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "    except Exception as e:\n",
        "        dric(f\"[red bold]予期しないエラー: {e}[/red bold]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: add_sum_of_cols, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "#@title stumpyを追加\n",
        "def calculate_matrix_profile(df, target, window_sizes):\n",
        "    \"\"\"\n",
        "    指定された列のMatrix Profileを計算し、新しい列に追加する関数\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pandas.DataFrame\n",
        "        Matrix Profileを計算する対象のデータフレーム\n",
        "    target : str\n",
        "        Matrix Profileを計算する対象の列名\n",
        "    window_sizes : list of int\n",
        "        Matrix Profileを計算する際のウィンドウサイズのリスト\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    df : pandas.DataFrame\n",
        "        Matrix Profileが計算され、新しい列が追加されたデータフレーム\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if df is None:\n",
        "            raise ValueError(\"データフレームが定義されていません。\")\n",
        "            text_to_speech(\"データフレームが定義されていません。\")\n",
        "        if target not in df.columns:\n",
        "            raise ValueError(f\"{target}はデータフレームに存在しません。\")\n",
        "            text_to_speech(f\"{target}はデータフレームに存在しません。\")\n",
        "        if not isinstance(window_sizes, list) or not all(isinstance(i, int) for i in window_sizes):\n",
        "            raise ValueError(\"window_sizesは整数のリストでなければなりません。\")\n",
        "            text_to_speech(\"window_sizesは整数のリストでなければなりません。\")\n",
        "\n",
        "        # 'target'カラムのデータ型をnumpy.float64に変換\n",
        "        df[target] = df[target].astype(np.float64)\n",
        "\n",
        "        for window in tqdm(window_sizes):\n",
        "            matrix_profile = stumpy.stump(df[target], m=window)\n",
        "            df.loc[df.index[window - 1:], f'feature_{target}_window_{window}'] = matrix_profile[:, 0]\n",
        "\n",
        "        return df\n",
        "\n",
        "    except ValueError as e:\n",
        "        dric(f\"[red bold]エラー: {e}[/red bold]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: calculate_matrix_profile, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "    except Exception as e:\n",
        "        dric(f\"[red bold]予期しないエラー: {e}[/red bold]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: calculate_matrix_profile, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "# カラムの可視化\n",
        "def plot_columns(df, columns, color='unique_id'):\n",
        "    \"\"\"\n",
        "    データフレームの指定されたカラムをプロットします。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pandas.DataFrame\n",
        "        プロットするデータが含まれているデータフレーム\n",
        "    columns : list of str\n",
        "        プロットするカラムのリスト\n",
        "    color : str, default 'unique_id'\n",
        "        プロットの色を指定するカラムの名前\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # colorが\"0\"から\"9\"の文字列である場合に数値に変換\n",
        "        if str(color).isdigit() and 0 <= int(color) <= 9:\n",
        "            color = int(color)\n",
        "        # サブプロットの作成\n",
        "        fig = sp.make_subplots(rows=len(columns), cols=1)\n",
        "\n",
        "        # 各列のデータを追加\n",
        "        for i, column in enumerate(columns, start=1):\n",
        "            if column in df.columns:\n",
        "                for trace in px.line(df, x='date', y=column, color=color, title=column).data:\n",
        "                    fig.add_trace(trace, row=i, col=1)\n",
        "                fig.update_yaxes(title_text=\"値\", row=i, col=1)\n",
        "            else:\n",
        "                dric(f\"[red bold]\\n{'*' * 100}\\n関数plot_columns: {column}はデータフレームに存在しません。\\n{'*' * 100}[/red bold]\")\n",
        "                text_to_speech(f\"{column}はデータフレームに存在しません。\")\n",
        "                traceback.print_exc()\n",
        "        # タイトルの設定と自動サイズ調整\n",
        "        fig.update_layout(autosize=True, height=300*len(columns), title_text=\"時間経過による各カラムのサブプロット\")\n",
        "\n",
        "        # 日付の形式を年月日に変更\n",
        "        fig.update_xaxes(tickformat=\"%Y-%m-%d\")\n",
        "\n",
        "        # グラフの表示\n",
        "        fig.show()\n",
        "    except Exception as e:\n",
        "        dric(f\"[red bold]\\n{'*' * 100}\\n関数plot_columns: エラーが発生しました: {e}\\n{'*' * 100}[/red bold]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: plot_columns, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "def on_change(change):\n",
        "    \"\"\"\n",
        "    チェックボックスの値が変更されたときの動作を定義する関数。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    change : dict\n",
        "        チェックボックスの値が変更されたときのイベント情報。\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if change['type'] == 'change' and change['name'] == 'value':\n",
        "            # 選択されたモデルをmodelsに設定\n",
        "            global models\n",
        "            models = [pre_models[i] for i in range(len(pre_models)) if checkboxes[i].value]\n",
        "    except Exception as e:\n",
        "        dric(f\"{on_change.__name__}関数でエラーが発生しました。\\n{'*'*100}\\n{e}\\n{'*'*100}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "def undefined_vars_check():\n",
        "    \"\"\"\n",
        "    この関数は、特定の変数が定義されているかどうかをチェックします。\n",
        "    定義されていない変数がある場合、その変数の名前を表示します。\n",
        "    \"\"\"\n",
        "    variables = ['horizon', 'cpus', 'gpus', 'verbose', 'backend', 'refit_with_val', 'num_samples', 'n_series']\n",
        "    undefined_vars = []\n",
        "\n",
        "    for var in variables:\n",
        "        try:\n",
        "            exec(f\"{var}\")\n",
        "        except NameError:\n",
        "            undefined_vars.append(var)\n",
        "\n",
        "    if undefined_vars:\n",
        "        dric(f\"[red bold]以下の変数が定義されていません: {', '.join(undefined_vars)}[/red bold]\")\n",
        "        return False\n",
        "    else:\n",
        "        dric(\"[green bold]すべての変数が正しく定義されています。[/green bold]\")\n",
        "        return True\n",
        "\n",
        "def process_data(df):\n",
        "    \"\"\"\n",
        "    データフレーム内の各カラムについて、移動平均、移動合計、差分、累積和を計算します。\n",
        "\n",
        "    Parameters:\n",
        "    df (pandas.DataFrame): 処理対象のデータフレーム。'N1', 'N2', 'N3', 'N4'の各カラムが必要です。\n",
        "\n",
        "    Returns:\n",
        "    df (pandas.DataFrame): 処理後のデータフレーム。元のデータフレームに新たなカラムが追加されます。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 'N1', 'N2', 'N3', 'N4'の各カラムについて処理\n",
        "        for column in n_cols:\n",
        "            df[column + '_MA'] = df[column].rolling(window=window).mean()\n",
        "            df[column + '_MS'] = df[column].rolling(window=window).sum()\n",
        "            df[column + '_DF'] = df[column].diff(window)\n",
        "            df[column + '_cum'] = df[column].cumsum()\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        dric(f\"エラーが発生しました: {e}\")\n",
        "        return None\n",
        "\n",
        "def worker(task):\n",
        "    \"\"\"\n",
        "    各タスクを実行する関数です。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        function, args = task\n",
        "        return function(*args)\n",
        "    except Exception as e:\n",
        "        dric(f\"{('*'*100)}\\n[red]worker関数でエラーが発生しました: {str(e)}[/red]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: worker, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def make_df_parallel(tasks):\n",
        "    \"\"\"\n",
        "    複数のタスクを並列に実行し、結果をデータフレームとして返す関数です。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with mp.Pool(mp.cpu_count()) as pool:\n",
        "            results = pool.map(worker, tasks)\n",
        "        return pd.concat(results).sort_values('date')\n",
        "    except Exception as e:\n",
        "        dric(f\"{('*'*100)}\\n[red]make_df_parallel関数でエラーが発生しました: {str(e)}[/red]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: make_df_parallel, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def get_rokuyo(date):\n",
        "    \"\"\"\n",
        "    日付から六曜を計算する関数です。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        rokuyo = [\"大安\", \"赤口\", \"先勝\", \"友引\", \"先負\", \"仏滅\"]\n",
        "        return rokuyo[(date.year + date.month + date.day) % 6]\n",
        "    except Exception as e:\n",
        "        dric(f\"{('*'*100)}\\n[red]get_rokuyo関数でエラーが発生しました: {str(e)}[/red]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: get_rokuyo, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def calculate_kabbalah_number(date):\n",
        "    \"\"\"\n",
        "    日付からカバラ数を計算する関数です。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 日付を文字列に変換\n",
        "        date_str = date.strftime(\"%Y%m%d\")\n",
        "\n",
        "        # 各数字を足し合わせる\n",
        "        kabbalah_number = sum(int(digit) for digit in date_str)\n",
        "\n",
        "        # カバラ数が一桁になるまで足し合わせる\n",
        "        while kabbalah_number > 9:\n",
        "            kabbalah_number = sum(int(digit) for digit in str(kabbalah_number))\n",
        "\n",
        "        return kabbalah_number\n",
        "    except Exception as e:\n",
        "        dric(f\"{('*'*100)}\\n[red]calculate_kabbalah_number関数でエラーが発生しました: {str(e)}[/red]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: calculate_kabbalah_number, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "def get_current_time_jst():\n",
        "    \"\"\"\n",
        "    日本時間で現在の日時を取得し、年月日時分秒の形式にフォーマットします。\n",
        "\n",
        "    Returns:\n",
        "        str: 年月日時分秒の形式にフォーマットされた現在の日時\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 日本時間のタイムゾーンを取得\n",
        "        jst = pytz.timezone('Asia/Tokyo')\n",
        "\n",
        "        # 現在の日本時間を取得\n",
        "        now = dt.now(jst)\n",
        "\n",
        "        # 年月日時分秒の形式にフォーマット\n",
        "        formatted_now = now.strftime('%Y_%m_%d')\n",
        "\n",
        "        return formatted_now\n",
        "    except Exception as e:\n",
        "        dric(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def save_dataframe(df, path):\n",
        "    \"\"\"\n",
        "    データフレームを指定したパスにCSVファイルとして保存します。\n",
        "    指定したパスにディレクトリが存在しない場合、新たにディレクトリを作成します。\n",
        "\n",
        "    Args:\n",
        "        df (pandas.DataFrame): 保存するデータフレーム\n",
        "        path (str): 保存先のパス\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # ディレクトリのパスを取得\n",
        "        dir_name = os.path.dirname(path)\n",
        "\n",
        "        # ディレクトリが存在しない場合は作成\n",
        "        if not os.path.exists(dir_name):\n",
        "            os.makedirs(dir_name)\n",
        "\n",
        "        # データフレームをCSVファイルとして保存\n",
        "        # df.to_csv(path)\n",
        "        df.to_csv(path, index=False)\n",
        "    except Exception as e:\n",
        "        dric(f\"エラーが発生しました: {e}\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: save_dataframe, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def preprocess_dataframe(df,num=0.3):\n",
        "    try:\n",
        "        # part列でNaNになっているレコードを削除し、値がすべて同じカラムを削除\n",
        "        # NaNが含まれている列を削除し、レコードの値がすべてNaNのレコードを削除\n",
        "        # dateで昇順に並べ替え、次にunique_idで並べ替え\n",
        "        # インデックスをリセット\n",
        "        df = (\n",
        "            df.dropna(subset=['part'])\n",
        "            .loc[:, df.nunique() != 1]\n",
        "            .dropna(how='all')\n",
        "            .sort_values(by=['date', 'unique_id'])\n",
        "            .reset_index(drop=True)\n",
        "        )\n",
        "    except Exception as e:\n",
        "        dric(f\"エラー: 前処理中に問題が発生しました: {e}\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: preprocess_dataframe, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "    try:\n",
        "        # 各カラムのNaNの割合を計算し、NaNの割合が0.3以上のカラムを取得\n",
        "        columns_to_drop = (df.isnull().sum() / len(df))[lambda x: x > num].index\n",
        "    except Exception as e:\n",
        "        dric(f\"エラー: NaNの割合の計算中に問題が発生しました: {e}\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: preprocess_dataframe, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "    try:\n",
        "        # これらのカラムを削除し、NaNが含まれるレコードを削除\n",
        "        df = (\n",
        "            df.drop(columns_to_drop, axis=1)\n",
        "            .dropna()\n",
        "        )\n",
        "    except Exception as e:\n",
        "        dric(f\"エラー: カラムとレコードの削除中に問題が発生しました: {e}\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: preprocess_dataframe, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # NaNが含まれているか確認\n",
        "    if df.isnull().values.any():\n",
        "        dric(\"警告: 作成したデータフレームにはNaNが含まれています。\")\n",
        "        text_to_speech(\"警告: 作成したデータフレームにはNaNが含まれています。\")\n",
        "    # インデックスを再度リセット\n",
        "    df = df.reset_index(drop=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "#ウィジェットの関数群##############################################################################################################################################\n",
        "class DataHolder:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        DataHolderクラスの初期化メソッドです。\n",
        "        このクラスはデータフレームを保持するためのクラスです。\n",
        "        初期化時には、df属性はNoneに設定されます。\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.df = None\n",
        "            self.check = None\n",
        "            self.filename = None\n",
        "        except Exception as e:\n",
        "            dric(\"[red]エラーが発生しました: {}[/red]\".format(str(e)))\n",
        "            text_to_speech(f\"エラーが発生しました。関数名: DataHolder, エラーメッセージ: {str(e)}\")\n",
        "            traceback.print_exc()\n",
        "            dric(\"*\"*100)\n",
        "data_holder = DataHolder()\n",
        "\n",
        "def on_checkbox_change(change):\n",
        "    \"\"\"\n",
        "    チェックボックスの値が変更されたときに呼び出されるイベントハンドラです。\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        data_holder.check = None\n",
        "        checkbox_value = change['new']\n",
        "        dric(\"[green]Checkbox value: {}[/green]\".format(checkbox_value))\n",
        "        if checkbox_value:\n",
        "            dropdown_widget = create_vuetify_dropdown(path)\n",
        "            dropdown_widget.observe(on_dropdown_value_change, names='v_model')  # ここでobserveを呼び出します\n",
        "            display(vue.Html(tag=\"h10\", children=[\"保存データのロード\"]), v.Spacer(height='100px'), dropdown_widget)\n",
        "            data_holder.check = checkbox_value\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました: {}[/red]\".format(str(e)))\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: on_checkbox_change, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        dric(\"*\"*100)\n",
        "\n",
        "def create_vuetify_checkbox():\n",
        "    \"\"\"\n",
        "    ブール値による有効/無効の切り替えを行うチェックボックスを作成します。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # ラベルを作成し、スタイルを設定\n",
        "        label = v.Html(tag='span', children=['load'], class_='d-inline-block', style_='font-size: 30px; vertical-align: middle;')\n",
        "\n",
        "        # チェックボックスの色を設定\n",
        "        checkbox = v.Checkbox(\n",
        "            v_model=False,\n",
        "            color='primary',\n",
        "            class_='ma-2 d-inline-block',\n",
        "            style_='width: 60px; height: 60px; font-size: 400px; font-family: Arial, sans-serif; vertical-align: middle;'  # フォントの種類を設定\n",
        "        )\n",
        "\n",
        "        # チェックボックスのv_modelが変更されたときにイベントハンドラを呼び出すように設定\n",
        "        checkbox.observe(on_checkbox_change, names='v_model')\n",
        "\n",
        "        # ラベルとチェックボックスを一緒に表示\n",
        "        return v.Layout(children=[label, checkbox])\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました: {}[/red]\".format(str(e)))\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: create_vuetify_checkbox, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        dric(\"*\"*100)\n",
        "\n",
        "def create_vuetify_dropdown(path):\n",
        "    \"\"\"\n",
        "    指定されたパス内のファイルからドロップダウンを作成します。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        files = os.listdir(path)\n",
        "        dropdown = v.Select(\n",
        "            items=files,\n",
        "            label='Select File',\n",
        "            style_='font-size: 25px; width: 1000px; height: 200px;',  # 幅と高さを設定\n",
        "            color='primary',  # ドロップダウンの色を設定\n",
        "            dense=True,\n",
        "            outlined=True,\n",
        "            item_color='primary',  # 選択した項目の色を設定\n",
        "            item_text_style='font-size: 25px;',  # ドロップダウンメニューの文字サイズを設定\n",
        "            v_model=None  # 初期値をNoneに設定\n",
        "        )\n",
        "        return dropdown\n",
        "    except Exception as e:\n",
        "        dric(f\"[red]エラーが発生しました: {str(e)}[/red]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: create_vuetify_dropdown, エラーメッセージ: {str(e)}\")\n",
        "        dric(\"*\"*100)\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "def on_dropdown_value_change(change):\n",
        "    \"\"\"\n",
        "    ドロップダウンの値が変更されたときに呼び出されるイベントハンドラです。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        filename = change['new']\n",
        "        dric(f\"{('*'*100)}\\nDropdown value changed to {filename}\")\n",
        "\n",
        "        # ファイルのパスを作成\n",
        "        file_path = os.path.join(path, filename)\n",
        "\n",
        "        # ファイルからデータフレームを作成\n",
        "        df = pd.read_csv(file_path)\n",
        "        if 'Unnamed: 0' in df.columns:\n",
        "            df = df.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "        # データフレームを表示（または返す）\n",
        "        display(df.tail())\n",
        "        display(f\"カラム数 {len(df.columns)}  \\n レコード数 {len(df)}\")\n",
        "        display(filename)\n",
        "        data_holder.df = None\n",
        "        data_holder.filename = None\n",
        "        # Store the DataFrame in the data_holder object\n",
        "        data_holder.df = df\n",
        "        data_holder.filename = path\n",
        "\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        dric(f\"{('*'*100)}\\n[red]Error occurred in function on_dropdown_value_change: {str(e)}[/red]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: on_dropdown_value_change, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "#############################################################################################################################################\n",
        "# データフレームの成形を行う関数\n",
        "@ray.remote\n",
        "def reshape_df(filtered_df, other_columns, i):\n",
        "    try:\n",
        "        # 選択した列を取得します\n",
        "        col = other_columns[i]\n",
        "\n",
        "        # フィルタリングされたデータフレームから特定の列を選択します\n",
        "        temp_df = filtered_df[['part', 'date', col]]\n",
        "\n",
        "        # 列名を変更します\n",
        "        temp_df.columns = ['part', 'date', 'No']\n",
        "\n",
        "        # 新しい列を追加し、その値を設定します\n",
        "        temp_df['origin_column'] = f'N{i+1}'\n",
        "\n",
        "        # 'No'列の値に基づいてダミー変数を作成します\n",
        "        one_hot = pd.get_dummies(temp_df['No'])\n",
        "\n",
        "        # ダミー変数のデータ型を整数に変換します\n",
        "        one_hot = one_hot.astype(int)\n",
        "\n",
        "        # データフレームとダミー変数を結合します\n",
        "        temp_df = pd.concat([temp_df, one_hot], axis=1)\n",
        "\n",
        "        # 成形されたデータフレームを返します\n",
        "        return temp_df\n",
        "    except Exception as e:\n",
        "        # エラーメッセージを表示します\n",
        "        dric(\"[red]エラーが発生しました: {}[/red]\".format(str(e)))\n",
        "        dric(\"*\"*100)\n",
        "        # どの関数でエラーが発生したかを表示します\n",
        "        dric(\"[red]エラーが発生した関数: reshape_df[/red]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: reshape_df, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        dric(\"*\"*100)\n",
        "\n",
        "# @title データの成形　修正版 { run: \"auto\" }\n",
        "def select_columns_by_lottery_type(df_encoded, select_loto):\n",
        "    try:\n",
        "        # 宝くじの種類に応じて選択するカラムを定義\n",
        "        columns_dict = {\n",
        "            \"num4\": [\"part\", \"date\", \"N1\", \"N2\", \"N3\", \"N4\"],\n",
        "            \"num3\": [\"part\", \"date\", \"N1\", \"N2\", \"N3\"],\n",
        "            \"Bin5\": [\"part\", \"date\", \"N1\", \"N2\", \"N3\", \"N4\", \"N5\", \"N6\", \"N7\", \"N8\"],\n",
        "            \"loto6\": [\"part\", \"date\", \"N1\", \"N2\", \"N3\", \"N4\", \"N5\", \"B1\", \"N6\"],\n",
        "            \"loto7\": [\"part\", \"date\", \"N1\", \"N2\", \"N3\", \"N4\", \"N5\", \"B1\", \"N6\", \"N7\", \"B2\"],\n",
        "            \"miniloto\": [\"part\", \"date\", \"N1\", \"N2\", \"N3\", \"N4\", \"N5\", \"B1\"]\n",
        "        }\n",
        "\n",
        "        # select_lotoカラムが1の行だけを抽出\n",
        "        df_filtered = df_encoded[df_encoded[select_loto] == 1]\n",
        "\n",
        "        # 選択された宝くじの種類に応じてカラムを選択\n",
        "        selected_columns = columns_dict[select_loto]\n",
        "\n",
        "        # 選択したカラムでデータフレームをフィルタリング\n",
        "        df_filtered = df_filtered[selected_columns]\n",
        "\n",
        "        return df_filtered\n",
        "    except Exception as e:\n",
        "        # エラーメッセージを表示します\n",
        "        dric(\"[red]エラーが発生しました: {}[/red]\".format(str(e)))\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: select_columns_by_lottery_type, エラーメッセージ: {str(e)}\")\n",
        "        dric(\"*\"*100)\n",
        "        # どの関数でエラーが発生したかを表示します\n",
        "        dric(\"[red]エラーが発生した関数: select_columns_by_lottery_type[/red]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: select_columns_by_lottery_type, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        dric(\"*\"*100)\n",
        "@ray.remote\n",
        "def process(unique_id):\n",
        "    \"\"\"\n",
        "    この関数は、指定されたユニークIDを持つデータをフィルタリングし、そのデータに対して様々な統計的処理を行います。\n",
        "    移動平均、移動合計、変化率、差分、自己相関、指数平滑化、ARIMAモデルのパラメータ、マトリックスプロファイルの計算が含まれます。\n",
        "\n",
        "    パラメータ:\n",
        "        unique_id (str): フィルタリングするデータのユニークID。\n",
        "\n",
        "    戻り値:\n",
        "        df_filtered (pd.DataFrame): 処理後のデータフレーム。\n",
        "\n",
        "    例外:\n",
        "        この関数は、処理中にエラーが発生した場合にエラーメッセージを表示します。\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        df_filtered = final_df[final_df['unique_id'] == unique_id]\n",
        "        # ユニークな日付の数を取得し、その長さの10%をｎとする\n",
        "        n = int(len(df_filtered['date'].unique()) * 0.05)\n",
        "        if n >30:\n",
        "            n=30\n",
        "        # for window in tqdm(range(3, n), file=sys.stderr):\n",
        "        df_filtered['cumsum'] = df_filtered[selected_column].cumsum()\n",
        "        for window in tqdm(range(3, n), desc='Processing windows', leave=False, file=sys.stderr):\n",
        "\n",
        "            # 移動平均\n",
        "            df_filtered[f'{selected_column}_rolling_mean_{window}'] = df_filtered[selected_column].rolling(window=window).mean()\n",
        "\n",
        "            # 移動合計\n",
        "            df_filtered[f'{selected_column}_rolling_sum_{window}'] = df_filtered[selected_column].rolling(window=window).sum()\n",
        "\n",
        "            # 変化率\n",
        "            df_filtered[f'{selected_column}_pct_change_{window}'] = df_filtered[selected_column].pct_change(window)\n",
        "\n",
        "            # 差分\n",
        "            df_filtered[f'{selected_column}_diff_{window}'] = df_filtered[selected_column].diff(window)\n",
        "\n",
        "            # 自己相関\n",
        "            acf_values = acf(df_filtered[selected_column], nlags=window)\n",
        "            acf_df = pd.DataFrame(acf_values, columns=[f'{selected_column}_acf_{window}'])\n",
        "            df_filtered = pd.concat([df_filtered, acf_df], axis=1)\n",
        "\n",
        "            # 指数平滑化\n",
        "            df_filtered[f'{selected_column}_ewm_{window}'] = df_filtered[selected_column].ewm(span=window).mean()\n",
        "\n",
        "            # ARIMAモデルのパラメータ（p, d, q）\n",
        "            model = ARIMA(df_filtered[selected_column], order=(1, 1, 1))\n",
        "            model_fit = model.fit()\n",
        "            df_filtered[f'{selected_column}_arima_params_{window}'] = model_fit.params\n",
        "\n",
        "            # stumpyを使用したマトリックスプロファイル\n",
        "            matrix_profile = stumpy.stump(df_filtered[selected_column].astype(np.float64), m=window)\n",
        "            df_filtered.loc[df_filtered.index[window - 1:], f'{selected_column}_matrix_profile_{window}'] = matrix_profile[:, 0]\n",
        "            df_filtered.reset_index(drop=True, inplace=True)  # インデックスをリセット\n",
        "            df_filtered = pd.concat([df_filtered, acf_df], axis=1)\n",
        "            df_filtered.reset_index(drop=True, inplace=True)  # インデックスをリセット\n",
        "        return df_filtered\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました[/red]\")\n",
        "        dric(f\"[red]エラーが発生した関数: {process.__name__}[/red]\")\n",
        "        dric(f\"[red]エラーメッセージ: {str(e)}[/red]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: {process.__name__}, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "def initialize_ray(lib_list=None):\n",
        "    \"\"\"\n",
        "    この関数は、Rayライブラリをシャットダウンし、次に初期化します。\n",
        "    初期化の際には、ダッシュボードの表示、使用可能なCPUとGPUの数、必要なパッケージのインストール、\n",
        "    ロギングレベルとフォーマットの設定などを行います。\n",
        "\n",
        "    戻り値:\n",
        "        なし\n",
        "\n",
        "    例外:\n",
        "        この関数は、初期化中にエラーが発生した場合にエラーメッセージを表示します。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Rayライブラリをシャットダウンします\n",
        "        ray.shutdown()\n",
        "\n",
        "        # Rayライブラリを初期化します\n",
        "        ray.init(include_dashboard=True ,\n",
        "                 num_cpus=mp.cpu_count(),\n",
        "                 num_gpus=torch.cuda.device_count(),\n",
        "                 runtime_env={\"pip\": lib_list},\n",
        "                 logging_level=logging.ERROR,\n",
        "                 logging_format=\"%(message)s\")\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました[/red]\")\n",
        "        dric(\"[red]エラーが発生した関数: initialize_ray[/red]\")\n",
        "        dric(f\"[red]エラーメッセージ: {str(e)}[/red]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: initialize_ray, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "#寄与率の計算###############################################################################################################################################################################\n",
        "\n",
        "@ray.remote\n",
        "def compute_feature_importance(hyperparameters, model, features_df, target):\n",
        "    \"\"\"\n",
        "    特徴量の重要度を計算する関数です。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    hyperparameters : dict\n",
        "        モデルのハイパーパラメータを指定します。\n",
        "    model : object\n",
        "        学習するモデルのインスタンスを指定します。\n",
        "    features_df : pandas.DataFrame\n",
        "        特徴量を含むデータフレームを指定します。\n",
        "    target : str\n",
        "        目的変数のカラム名を指定します。\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple\n",
        "        各種特徴量の重要度を計算した結果を返します。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        X = features_df.drop(target, axis=1)\n",
        "        y = features_df[target]\n",
        "        model.fit(X, y)\n",
        "\n",
        "        # 特徴量の重要度を計算\n",
        "        importances = model.feature_importances_\n",
        "\n",
        "        # Permutation Importance\n",
        "        perm_importance = permutation_importance(model, X, y, n_repeats=10, random_state=42)\n",
        "\n",
        "        # Mutual Information\n",
        "        mutual_info = mutual_info_regression(X, y)\n",
        "\n",
        "        # Correlation Coefficient\n",
        "        correlation_coef = X.corrwith(y)\n",
        "\n",
        "        # Lasso (L1) Regularization\n",
        "        lasso = LassoCV(cv=5).fit(X, y)\n",
        "        lasso_importance = np.abs(lasso.coef_)\n",
        "\n",
        "        return importances, perm_importance.importances_mean, mutual_info, correlation_coef, lasso_importance\n",
        "\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました。[/red]\")\n",
        "        dric(f\"[red]関数 'compute_feature_importance' でエラーが発生しました: {e}[/red]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: compute_feature_importance, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "#Git関係##########################################################################################################################################################\n",
        "\n",
        "def git_save(git_username, git_repository, git_pass):\n",
        "    \"\"\"\n",
        "    GitHubにコードを保存する関数\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    git_username : str\n",
        "        GitHubのユーザー名\n",
        "    git_repository : str\n",
        "        GitHubのリポジトリ名\n",
        "    git_pass : str\n",
        "        GitHubのパスワード\n",
        "    \"\"\"\n",
        "    try:\n",
        "        os.chdir('/content/drive/MyDrive/ColabNotebooks/forecast_loto')\n",
        "        os.system('git add .')\n",
        "\n",
        "        # 現在の日付と時刻を取得（日本時間）\n",
        "        now = dt.now(pytz.timezone('Asia/Tokyo'))\n",
        "\n",
        "        # 日付と時刻を文字列に変換\n",
        "        datetime_str = now.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        # コミットメッセージを作成\n",
        "        commit_message = f\"Commit on {datetime_str}\"\n",
        "\n",
        "        # git commitコマンドを実行\n",
        "        os.system(f'git commit -m \"{commit_message}\"')\n",
        "        os.system(f\"git push https://{git_username}:{git_pass}@github.com/{git_username}/{git_repository}.git\")\n",
        "        # .gitディレクトリのサイズを表示\n",
        "        dric(subprocess.getoutput('du -sh .git'))\n",
        "        os.chdir('/content/')\n",
        "        dric(\"✅ コードの保存が完了しました。\")\n",
        "        text_to_speech(f\"コードの保存が完了しました。\")\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました。[/red]\")\n",
        "        dric(f\"[red]エラー発生関数: git_save[/red]\")\n",
        "        dric(f\"[red]エラーメッセージ: {str(e)}[/red]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: git_save, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "def git_save(git_email, git_username, git_token, git_repository):\n",
        "    \"\"\"\n",
        "    Gitコマンドを実行する関数\n",
        "\n",
        "    Parameters:\n",
        "    git_email (str): GitのユーザーEmail\n",
        "    git_username (str): Gitのユーザー名\n",
        "    git_token (str): Gitのトークン\n",
        "    git_repository (str): Gitのリポジトリ名\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # 実行するGitコマンドのリスト\n",
        "    commands = [\n",
        "        f\"git -C /content/drive/MyDrive/ColabNotebooks/forecast_loto init\",\n",
        "        f\"git config --global user.email {git_email}\",\n",
        "        f\"git config --global user.name  {git_username}\",\n",
        "        f\"git -C /content/drive/MyDrive/ColabNotebooks/forecast_loto add .\",\n",
        "        f\"git -C /content/drive/MyDrive/ColabNotebooks/forecast_loto commit -m 'Added new file.'\",\n",
        "        f\"git -C /content/drive/MyDrive/ColabNotebooks/forecast_loto remote add origin https://{git_username}:{git_token}@github.com/{git_username}/{git_repository}.git\",\n",
        "        f\"git -C /content/drive/MyDrive/ColabNotebooks/forecast_loto remote set-url origin https://{git_username}:{git_token}@github.com/{git_username}/{git_repository}.git\",\n",
        "        f\"git -C /content/drive/MyDrive/ColabNotebooks/forecast_loto config pull.rebase false\",  # マージ戦略を選択\n",
        "        f\"git -C /content/drive/MyDrive/ColabNotebooks/forecast_loto pull --allow-unrelated-histories origin main\",  # リモートの変更を取得\n",
        "        f\"git -C /content/drive/MyDrive/ColabNotebooks/forecast_loto push -u origin main\"  # 再度プッシュ\n",
        "    ]\n",
        "\n",
        "    # 各コマンドを順に実行\n",
        "    for command in commands:\n",
        "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        stdout, stderr = process.communicate()\n",
        "\n",
        "        # エラーハンドリング\n",
        "        if process.returncode != 0:\n",
        "            print(f\"エラーが発生しました：\\n{stderr.decode()}\")\n",
        "            text_to_speech(f\"エラーが発生しました。関数名: git_save, エラーメッセージ: {stderr.decode()}\")\n",
        "        else:\n",
        "            print(f\"成功：\\n{stdout.decode()}\")\n",
        "\n",
        "def git_log():\n",
        "    \"\"\"\n",
        "    この関数は、.gitディレクトリのサイズとgitのログを表示します。\n",
        "    現在の作業ディレクトリを'/content/drive/MyDrive/ColabNotebooks/forecast_loto'に変更し、\n",
        "    コマンドを実行した後、元のディレクトリに戻ります。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 元の作業ディレクトリを保存\n",
        "        original_dir = os.getcwd()\n",
        "\n",
        "        # 作業ディレクトリを変更\n",
        "        os.chdir('/content/drive/MyDrive/ColabNotebooks/forecast_loto')\n",
        "\n",
        "        # .gitディレクトリのサイズを表示\n",
        "        dric(subprocess.getoutput('du -sh .git'))\n",
        "\n",
        "        # gitのログを表示\n",
        "        dric(subprocess.getoutput('git log'))\n",
        "\n",
        "        # 作業ディレクトリを元に戻す\n",
        "        os.chdir(original_dir)\n",
        "\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました。[/red]\")\n",
        "        dric(f\"[red]エラー発生関数：{git_log.__name__}[/red]\")\n",
        "        dric(f\"[red]エラーメッセージ：{str(e)}[/red]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: git_log, エラーメッセージ: {str(e)}\")\n",
        "        dric(\"[red]\" + \"*\" * 100 + \"[/red]\")\n",
        "        traceback.print_exc()\n",
        "#モデルの定義での関数###############################################################################################################################\n",
        "\n",
        "def on_select_all_change(change):\n",
        "    \"\"\"\n",
        "    全て選択/選択解除のチェックボックスが変更されたときに呼び出される関数\n",
        "    Args:\n",
        "        change: チェックボックスの状態変化\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 全てのチェックボックスの値を全て選択/選択解除のチェックボックスの値と同じに設定\n",
        "        for checkbox in checkboxes:\n",
        "            checkbox.value = select_all.value\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました。[/red]\")\n",
        "        dric(f\"[red]関数名: on_select_all_change[/red]\")\n",
        "        dric(f\"[red]エラーメッセージ: {str(e)}[/red]\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: on_select_all_change, エラーメッセージ: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def beep():\n",
        "  from google.colab import output\n",
        "  output.eval_js('new Audio(\\\n",
        "\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\")\\\n",
        ".play()')\n",
        "\n",
        "def text_to_speech(text, lang='ja', slow=False):\n",
        "    \"\"\"\n",
        "    テキストを音声に変換する関数\n",
        "\n",
        "    Parameters:\n",
        "    text (str): 音声に変換したいテキスト\n",
        "    lang (str): 使用する言語のコード（デフォルトは日本語）\n",
        "    slow (bool): 音声の速度（デフォルトはFalseで、これは高速な読み上げを意味します）\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # gTTSオブジェクトを作成します\n",
        "        tts = gTTS(text=text, lang=lang, slow=slow)\n",
        "        # 音声ファイルを作成します\n",
        "        tts.save('output.mp3')\n",
        "        # 音声ファイルを再生します\n",
        "        return Audio('output.mp3', autoplay=True)\n",
        "    except Exception as e:\n",
        "        print(f\"エラーが発生しました: {e}\")\n",
        "        text_to_speech(f\"エラーが発生しました。関数名: text_to_speech, エラーメッセージ: {str(e)}\")\n",
        "\n",
        "git_log()\n",
        "git_save(git_email, git_username, git_token, git_repository)\n",
        "text_to_speech(f\"関数の作成が完了しました\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzPcnZfa0t2O"
      },
      "source": [
        "# **<font color='Blue'>各種設定**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuYLvxorTGrM"
      },
      "outputs": [],
      "source": [
        "# @title #**各種設定** { run: \"auto\" }\n",
        "%%time\n",
        "#@markdown ---\n",
        "#@markdown #####**ロトの種類**\n",
        "select_loto ='num4'# @param  [\"num4\", \"num3\", \"Bin5\", \"loto6\", \"loto7\", \"miniloto\"]\n",
        "#@markdown ---\n",
        "#@markdown #####**ターゲットカラム**\n",
        "#@markdown - 0or1(No_O)、0or9(No)\n",
        "target ='No_O'# @param [\"No_O\",\"No\"]\n",
        "#@markdown ---\n",
        "#@markdown #####**データフレームの形状を変換するか**\n",
        "#@markdown - **\"reshape\"**\n",
        "#@markdown  - 2段階のカスケード構造\n",
        "#@markdown - **origin**\n",
        "#@markdown  - 1段階のカスケード構造\n",
        "use_reshape_dataframe = \"reshape\" # @param [\"reshape\",\"origin\"]\n",
        "#@markdown ---\n",
        "#@markdown #####**頻度**\n",
        "#@markdown - 日次(D)、週次(W)、月次(M)、四半期(Q)、年次(Y)\n",
        "freq =  'D'# @param [\"D\",\"W\",\"M\",\"Q\",\"Y\"]\n",
        "#@markdown ---\n",
        "#@markdown ##### **学習量**\n",
        "training_volume=100 #@param {type:\"slider\", min:100, max:7000, step:100}\n",
        "#@markdown ---\n",
        "#@markdown #####**test_size**\n",
        "test_size = 1 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "#@markdown ---\n",
        "#@markdown #####**特徴量の操作**\n",
        "#@markdown - 特徴量を全選択するかds,y,unique_idの3カラムのみにするか\n",
        "select_all_features = False #@param {type:\"boolean\"}\n",
        "# @title **backendとnum_samplesの設定**\n",
        "#@markdown ---\n",
        "#@markdown #####**ハイパーパラメータの探索空間を探索するために使用するバックエンド**\n",
        "#@markdown - **ray**\n",
        "#@markdown  - 大規模なデータセット、複雑なモデル\n",
        "#@markdown -**optuna**\n",
        "#@markdown  - 小規模、中規模なデータセット、シンプルなモデル\n",
        "backend=\"ray\"# @param [\"ray\", \"optuna\"]\n",
        "#@markdown ---\n",
        "#@markdown ##### **ハイパーパラメータ最適化のステップ数**\n",
        "#@markdown - **増やす場合**\n",
        "#@markdown  - 最適なハイパーパラメータを見つける可能性が高まります。\n",
        "#@markdown - **減らす場合**\n",
        "#@markdown  - 計算リソースと時間を節約できます。\n",
        "num_samples=20# @param {type:\"slider\", min:10, max:100, step:10}\n",
        "#@markdown ---\n",
        "#@markdown ##### **検証データセットを保持するかどうかを指定**\n",
        "#@markdown - **True**\n",
        "#@markdown  - モデルは未見のデータに対してより一般化する可能性があります\n",
        "#@markdown - **False**\n",
        "#@markdown  - モデルが訓練データに対して最適化され、過学習のリスクを減らすことができます\n",
        "refit_with_val=True  # @param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown #####**最適化プロセスの進行状況の表示**\n",
        "#@markdown - **True**\n",
        "#@markdown  - 最適化プロセスの進行状況が表示されます\n",
        "#@markdown - **False**\n",
        "#@markdown  - 計算リソースやディスクスペースを節約できます\n",
        "verbose=True # @param {type:\"boolean\"}\n",
        "cpus = mp.cpu_count()\n",
        "gpus = torch.cuda.device_count()\n",
        "if test_size==0:\n",
        "    horizon=1\n",
        "else:\n",
        "    horizon=test_size\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #####**寄与率の計算**\n",
        "#@markdown - 特徴量の寄与率を計算\n",
        "feature_contribution = False # @param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown #####**最適化プロセスの進行状況の表示**\n",
        "#@markdown - **True**\n",
        "#@markdown  - 最適化プロセスの進行状況が表示されます\n",
        "#@markdown - **False**\n",
        "#@markdown  - 計算リソースやディスクスペースを節約できます\n",
        "verbose=True # @param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown #####**実行の有無**\n",
        "#@markdown\n",
        "#@markdown  **データフレームの作成**\n",
        "calculate_stats=True # @param {type:\"boolean\"}\n",
        "#@markdown  **データの成形**\n",
        "create_dataframe=True # @param {type:\"boolean\"}\n",
        "#@markdown  **統計計算**\n",
        "compute_statistics=True # @param {type:\"boolean\"}\n",
        "#@markdown  **特徴量の選択**\n",
        "select_features_process=True # @param {type:\"boolean\"}\n",
        "#@markdown  **カラム名の変更**\n",
        "rename_columns=True # @param {type:\"boolean\"}\n",
        "#@markdown  **モデルの再学習と予測の評価**\n",
        "retrain_and_evaluate_model=True # @param {type:\"boolean\"}\n",
        "#@markdown  **モデルの生成**\n",
        "create_model=True # @param {type:\"boolean\"}\n",
        "#@markdown  **EDA (Exploratory Data Analysis)**\n",
        "perform_eda=True # @param {type:\"boolean\"}\n",
        "# ラベルとスライダーを垂直に配置\n",
        "dric(f\"backend: {backend}\")\n",
        "dric(f\"num_samples: {num_samples}\")\n",
        "dric(f\"refit_with_val: {refit_with_val}\")\n",
        "dric(f\"verbose: {verbose}\")\n",
        "dric(f\"horizon: {horizon}\")\n",
        "dric(f\"cpus: {cpus}\")\n",
        "dric(f\"gpus: {gpus}\")\n",
        "dric(f\"target={target}\")\n",
        "dric(f\"freq={freq}\")\n",
        "dric(f\"feature_contribution={feature_contribution}\")\n",
        "# @title rayのURL { run: \"auto\" }\n",
        "try:\n",
        "    # rayが初期化されているかどうかを確認します\n",
        "    if ray.is_initialized():\n",
        "        # rayが初期化されている場合は、シャットダウンします\n",
        "        ray.shutdown()\n",
        "\n",
        "    # rayを初期化し、その出力を変数に格納します\n",
        "    ray_output = ray.init()\n",
        "\n",
        "    # URLの出力を変数に格納します\n",
        "    output.serve_kernel_port_as_window(8265, path=\"\")\n",
        "except Exception as e:\n",
        "    # エラーメッセージを表示します\n",
        "    dric(\"[red]エラーが発生しました: {}[/red]\".format(str(e)))\n",
        "    dric(\"*\"*100)\n",
        "    # どの関数でエラーが発生したかを表示します\n",
        "    dric(\"[red]エラーが発生した関数: {}[/red]\".format(traceback.print_exc()))\n",
        "    text_to_speech(f\"エラーが発生しました。関数名: ray_init, エラーメッセージ: {str(e)}\"\n",
        "    dric(\"*\"*100)\n",
        "git_save(git_email, git_username, git_token, git_repository)\n",
        "text_to_speech(f\"各種設定が完了しました\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQaE2MNI2YEd"
      },
      "source": [
        "# **<font color='Blue'>データの作成と成形**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "PFKuXP2h0IrT",
        "outputId": "fb8e3678-330d-4d56-f700-fba7fbdd7ee6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;32mdf_encoded はすでに作成済みなので処理をスキップしました\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">df_encoded はすでに作成済みなので処理をスキップしました</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      part       date  N1  N2  N3  N4  N5  N6  N7  N8  B1  B2  week_月  week_木  \\\n",
              "6458  6460 2024-05-02   3   1   3   0   0   0   0   0   0   0       0       1   \n",
              "1891  1892 2024-05-02   7   8   9  19  22  38   0   0  24   0       0       0   \n",
              "6460  6461 2024-05-03   1   3   2   3   0   0   0   0   0   0       0       0   \n",
              "6459  6461 2024-05-03   6   6   6   0   0   0   0   0   0   0       0       0   \n",
              "572    573 2024-05-03  11  12  18  19  23  26  31   0  15  25       0       0   \n",
              "\n",
              "      week_水  week_火  week_金  eto_仏滅  eto_先勝  eto_先負  eto_友引  eto_大安  eto_赤口  \\\n",
              "6458       0       0       0       0       0       0       1       0       0   \n",
              "1891       0       0       0       0       0       0       0       0       0   \n",
              "6460       0       0       1       0       0       1       0       0       0   \n",
              "6459       0       0       1       0       0       1       0       0       0   \n",
              "572        0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "      Bin5  loto6  loto7  mini  num3  num4  is_hd_False  is_hd_True  \n",
              "6458     0      0      0     0     1     0            1           0  \n",
              "1891     0      1      0     0     0     0            1           0  \n",
              "6460     0      0      0     0     0     1            0           1  \n",
              "6459     0      0      0     0     1     0            0           1  \n",
              "572      0      0      1     0     0     0            0           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c2b39ef-c96d-4136-a3ec-160dcb1fba46\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>part</th>\n",
              "      <th>date</th>\n",
              "      <th>N1</th>\n",
              "      <th>N2</th>\n",
              "      <th>N3</th>\n",
              "      <th>N4</th>\n",
              "      <th>N5</th>\n",
              "      <th>N6</th>\n",
              "      <th>N7</th>\n",
              "      <th>N8</th>\n",
              "      <th>B1</th>\n",
              "      <th>B2</th>\n",
              "      <th>week_月</th>\n",
              "      <th>week_木</th>\n",
              "      <th>week_水</th>\n",
              "      <th>week_火</th>\n",
              "      <th>week_金</th>\n",
              "      <th>eto_仏滅</th>\n",
              "      <th>eto_先勝</th>\n",
              "      <th>eto_先負</th>\n",
              "      <th>eto_友引</th>\n",
              "      <th>eto_大安</th>\n",
              "      <th>eto_赤口</th>\n",
              "      <th>Bin5</th>\n",
              "      <th>loto6</th>\n",
              "      <th>loto7</th>\n",
              "      <th>mini</th>\n",
              "      <th>num3</th>\n",
              "      <th>num4</th>\n",
              "      <th>is_hd_False</th>\n",
              "      <th>is_hd_True</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6458</th>\n",
              "      <td>6460</td>\n",
              "      <td>2024-05-02</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1891</th>\n",
              "      <td>1892</td>\n",
              "      <td>2024-05-02</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>22</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6460</th>\n",
              "      <td>6461</td>\n",
              "      <td>2024-05-03</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6459</th>\n",
              "      <td>6461</td>\n",
              "      <td>2024-05-03</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>572</th>\n",
              "      <td>573</td>\n",
              "      <td>2024-05-03</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>18</td>\n",
              "      <td>19</td>\n",
              "      <td>23</td>\n",
              "      <td>26</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c2b39ef-c96d-4136-a3ec-160dcb1fba46')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c2b39ef-c96d-4136-a3ec-160dcb1fba46 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c2b39ef-c96d-4136-a3ec-160dcb1fba46');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ae4e4a9e-a32e-497d-9825-904b8f694631\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ae4e4a9e-a32e-497d-9825-904b8f694631')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ae4e4a9e-a32e-497d-9825-904b8f694631 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m9.\u001b[0m0M    .git\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.</span>0M    .git\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "✅ コードの保存が完了しました。\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ コードの保存が完了しました。\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 17.1 ms, sys: 7.57 ms, total: 24.7 ms\n",
            "Wall time: 287 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if calculate_stats:\n",
        "    #@title **データフレームの作成**\n",
        "    try:\n",
        "\n",
        "        # dfがすでに定義されていてNoneでない場合は、以下の処理をスキップ\n",
        "        if \"df_encoded\" not in locals() or df_encoded is None or df_encoded_len !=len(df_encoded):\n",
        "            import multiprocessing as mp\n",
        "            import pandas as pd\n",
        "\n",
        "            # タスクのリストを作成します\n",
        "            tasks = [\n",
        "                (make_numbers, (4,)),  # ナンバーズ4のデータフレームを作成\n",
        "                (make_numbers, (3,)),  # ナンバーズ3のデータフレームを作成\n",
        "                (make_Bin5, ()),  # ビンゴ5のデータフレームを作成\n",
        "                (make_loto, (\"miniloto\", 8, 5, 1)),  # ミニロトのデータフレームを作成\n",
        "                (make_loto, ()),  # ロト6のデータフレームを作成\n",
        "                (make_loto, (\"loto7\", 11, 7, 2))  # ロト7のデータフレームを作成\n",
        "            ]\n",
        "\n",
        "            # 並列化されたデータフレームの作成\n",
        "            df_sorted = make_df_parallel(tasks)\n",
        "\n",
        "\n",
        "            # '抽選数字'カラムは不要なので削除\n",
        "            df_sorted.drop('抽選数字', axis=1, inplace=True)\n",
        "\n",
        "            # データフレームを日付で並び替え\n",
        "            df_sorted = df_sorted.sort_values(by='date')\n",
        "            # dateカラムがdatetime型であることを確認\n",
        "            assert pd.api.types.is_datetime64_any_dtype(df_sorted['date']), \"dateカラムはdatetime型ではありません\"\n",
        "\n",
        "            # dateカラムをjpholidayで休日を判別し、新たなis_holidayカラムを作成\n",
        "            df_sorted['is_hd'] = df_sorted['date'].apply(jpholiday.is_holiday)\n",
        "            # カテゴリ変数をワンホットエンコーディング\n",
        "            df_encoded = pd.get_dummies(df_sorted, columns=['week', 'eto', 'LOTO','is_hd'])\n",
        "\n",
        "            # Convert the num1 to num8 columns to integer type\n",
        "            df_encoded[['part','N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7','N8','B1', 'B2']] = df_encoded[['part','N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7','N8','B1', 'B2']].replace('missing', 0).replace([np.inf, -np.inf], np.nan).fillna(0).astype(int)\n",
        "\n",
        "            # データの情報\n",
        "            df_encoded.columns = df_encoded.columns.str.replace('LOTO_', '')\n",
        "            df_encoded.rename(columns={'miniloto': 'mini'}, inplace=True)\n",
        "            df_encoded_len =len(df_encoded)\n",
        "            display(df_encoded.tail())\n",
        "            display(f\"カラム数 {len(df_encoded.columns)}  \\n レコード数 {len(df_encoded)}\")\n",
        "\n",
        "        else:\n",
        "            dric(\"[green bold]df_encoded はすでに作成済みなので処理をスキップしました\")\n",
        "            display(df_encoded.tail())\n",
        "\n",
        "    except Exception as e:\n",
        "        dric(\"[red bold]エラーが発生しました。詳細は以下の通りです:[/red bold]\")\n",
        "        traceback.print_exc()\n",
        "git_save(git_email, git_username, git_token, git_repository)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6XcuB-81P5C"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# @title **データの成形** { run: \"auto\" }\n",
        "if create_dataframe:\n",
        "    try:\n",
        "        filtered_df=select_columns_by_lottery_type(df_encoded, select_loto)\n",
        "        filtered_df=filtered_df.tail(training_volume)\n",
        "        initialize_ray(lib_list=None)\n",
        "\n",
        "        # 各カラムについてループ\n",
        "        other_columns = [col for col in filtered_df.columns if col not in ['part', 'date']]\n",
        "        futures = [reshape_df.remote(filtered_df, other_columns, i) for i in range(len(other_columns))]\n",
        "        merged_df = pd.concat(ray.get(futures), axis=0)\n",
        "\n",
        "        if use_reshape_dataframe ==\"reshape\":\n",
        "            # 2段階のカスケード構造を作成\n",
        "            final_df = pd.DataFrame()\n",
        "\n",
        "            if 'origin_column' in merged_df.columns:\n",
        "                for col in tqdm(merged_df.columns.drop(['part', 'date', 'No', 'origin_column'])):\n",
        "                    temp_df = merged_df[['part', 'date', 'No', 'origin_column', col]]\n",
        "                    temp_df.columns = ['part', 'date', 'No', 'origin_column', target]\n",
        "                    temp_df['origin_column2'] = col\n",
        "                    final_df = pd.concat([final_df, temp_df])\n",
        "\n",
        "                # origin_columnとorigin_column2の値を組み合わせてユニークIDカラムを作成\n",
        "                final_df['unique_id'] = final_df['origin_column'].astype(str) + '_' + final_df['origin_column2'].astype(str)\n",
        "\n",
        "                # origin_columnとorigin_column2のカラムを削除\n",
        "                final_df = final_df.drop(['origin_column', 'origin_column2'], axis=1)\n",
        "        else:\n",
        "            final_df = merged_df.copy()\n",
        "            # origin_columnをunique_idに変換\n",
        "            final_df.rename(columns={'origin_column': 'unique_id'}, inplace=True)\n",
        "            # Noの値をNo_Oのカラムに入れる\n",
        "            final_df['No_O'] = final_df['No']\n",
        "\n",
        "        dates = pd.date_range(start=final_df['date'].min(), end=final_df['date'].max())\n",
        "        holidays = {date: jpholiday.is_holiday(date) for date in dates}\n",
        "\n",
        "        # 辞書を使用してmap関数を適用\n",
        "        final_df['is_hd'] = final_df['date'].map(holidays)\n",
        "        # 日付範囲全体でカバラ数を計算\n",
        "        dates = pd.date_range(start=final_df['date'].min(), end=final_df['date'].max())\n",
        "        kabbalah_numbers = {date: calculate_kabbalah_number(date) for date in dates}\n",
        "\n",
        "        # 辞書を使用してmap関数を適用\n",
        "        final_df['kabbalah'] = final_df['date'].map(kabbalah_numbers)\n",
        "        # 日付をdatetime型に変換（既にdatetime型の場合は不要）\n",
        "\n",
        "        final_df['date'] = pd.to_datetime(final_df['date'])\n",
        "\n",
        "        # 年、月、日、曜日、週番号、四半期、年の日数、月の日数を一度に取得\n",
        "        date_features = {\n",
        "            \"year\": final_df['date'].dt.year,\n",
        "            \"month\": final_df['date'].dt.month,\n",
        "            \"day\": final_df['date'].dt.day,\n",
        "            \"week\": final_df['date'].dt.dayofweek,\n",
        "            \"week_of_year\": final_df['date'].dt.isocalendar().week,\n",
        "            \"quarter\": final_df['date'].dt.quarter,\n",
        "            \"day_of_year\": final_df['date'].dt.dayofyear,\n",
        "            \"day_of_month\": final_df['date'].dt.days_in_month,\n",
        "            'rokuyo': final_df['date'].apply(get_rokuyo)\n",
        "\n",
        "        }\n",
        "\n",
        "        # 新しい特徴量をデータフレームに追加\n",
        "        final_df = final_df.assign(**date_features)\n",
        "\n",
        "        # ワンホットエンコーディングを適用するカラムのリスト\n",
        "        columns_to_encode = ['month', 'week', 'quarter', 'is_hd', 'rokuyo']\n",
        "\n",
        "        # 各カラムに対してワンホットエンコーディングを適用\n",
        "        for column in tqdm(columns_to_encode):\n",
        "            one_hot = pd.get_dummies(final_df[column], prefix=column).astype(int)\n",
        "            final_df = pd.concat([final_df, one_hot], axis=1)\n",
        "        final_df['week_of_year'] = final_df['week_of_year'].astype('int64')\n",
        "\n",
        "        # 元のカラムを削除\n",
        "        final_df = final_df.drop(columns=columns_to_encode)\n",
        "        final_df = final_df.reset_index(drop=True)\n",
        "        display(final_df.tail())\n",
        "        display(f\"カラム数 {len(final_df.columns)}  \\n レコード数 {len(final_df)}\")\n",
        "\n",
        "        ray.shutdown()\n",
        "    except Exception as e:\n",
        "        dric(\"[red bold] \\n \\n エラーが発生しました。詳細は以下の通りです:[/red bold]\")\n",
        "        text_to_speech(f\"エラーが発生しました。詳細は以下の通りです: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "    ray.shutdown()\n",
        "text_to_speech(f\"データの成形が完了しました\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "pkc_2X-XbVbh",
        "outputId": "b53d50dc-2141-4bbe-e37d-d0b12bdff7ab"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "15",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 60.7 ms, sys: 193 ms, total: 253 ms\n",
            "Wall time: 3.32 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "%%capture\n",
        "#@title **統計計算**\n",
        "if compute_statistics:\n",
        "    try:\n",
        "        selected_column = target\n",
        "        unique_ids = final_df['unique_id'].unique()\n",
        "\n",
        "        initialize_ray(lib_list=None)\n",
        "\n",
        "        results = ray.get([process.options(num_cpus=mp.cpu_count(), num_gpus=torch.cuda.device_count(), runtime_env={\"pip\": [\"stumpy\",\"arch\"]}).remote(unique_id) for unique_id in tqdm(unique_ids, desc='Processing unique IDs', leave=False)])\n",
        "        final_df = pd.concat(results, ignore_index=True)\n",
        "\n",
        "        final_df = pd.concat(results)\n",
        "\n",
        "        processed_df_path =f'/content/drive/MyDrive/ColabNotebooks/forecast_loto/{select_loto}/processed_data/pre_processed/{use_reshape_dataframe}/pre_processed/pre_processed_df_{len(final_df.columns)}_{len(final_df)}_{get_current_time_jst()}.csv'\n",
        "        save_dataframe(final_df, processed_df_path)\n",
        "\n",
        "        cleaned_df =preprocess_dataframe(final_df,num=0.3)\n",
        "        cleaned_df_path =f'/content/drive/MyDrive/ColabNotebooks/forecast_loto/{select_loto}/processed_data/pre_processed/{use_reshape_dataframe}/cleaned/cleaned_df_{len(cleaned_df.columns)}_{len(cleaned_df)}_{get_current_time_jst()}.csv'\n",
        "        save_dataframe(cleaned_df, cleaned_df_path)\n",
        "        display(cleaned_df.tail())\n",
        "        display(f\"カラム数 {len(cleaned_df.columns)}  \\n レコード数 {len(cleaned_df)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました[/red]\")\n",
        "\n",
        "        dric(f\"[red]エラーメッセージ: {str(e)}[/red]\")\n",
        "        text_to_speech(f\"エラーが発生しました。詳細は以下の通りです: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "    ray.shutdown()\n",
        "git_save(git_email, git_username, git_token, git_repository)\n",
        "text_to_speech(f\"統計計算が完了しました\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InYPQHJe1Ow4"
      },
      "source": [
        "# **<font color='Blue'>統計データをロード**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403,
          "referenced_widgets": [
            "1e817324ff0c4cdd8b0428953532722c",
            "6c7915c1fbed45689f279ebfd98ec936",
            "d7a2a06b29364c84bb52b9ceda58386e",
            "ba71d7a9fbc54fb48ac4621c169f9407"
          ]
        },
        "id": "wiC3VT6tgXZg",
        "outputId": "e194839e-0316-4cf1-c5ac-26a87a8320cf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Html(children=['統計結果の保存データのロード'], layout=None, tag='h2')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e817324ff0c4cdd8b0428953532722c"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Layout(children=[Html(children=['load'], class_='d-inline-block', layout=None, style_='font-size: 30px; vertic…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c7915c1fbed45689f279ebfd98ec936"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mエラーが発生しました: \u001b[0m\u001b[1;31m[\u001b[0m\u001b[31mErrno \u001b[0m\u001b[1;31m2\u001b[0m\u001b[1;31m]\u001b[0m\u001b[31m No such file or directory: \u001b[0m\u001b[31m'/content/drive/MyDrive/Colab \u001b[0m\n",
              "\u001b[31mNotebooks/forecast_loto/num4/processed_data/pre_processed/reshape/cleaned'\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">エラーが発生しました: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">[</span><span style=\"color: #800000; text-decoration-color: #800000\">Errno </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">2</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">]</span><span style=\"color: #800000; text-decoration-color: #800000\"> No such file or directory: </span><span style=\"color: #800000; text-decoration-color: #800000\">'/content/drive/MyDrive/Colab </span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">Notebooks/forecast_loto/num4/processed_data/pre_processed/reshape/cleaned'</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "****************************************************************************************************\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">****************************************************************************************************\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<timed exec>\", line 799, in create_vuetify_dropdown\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/forecast_loto/num4/processed_data/pre_processed/reshape/cleaned'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mエラーが発生しました\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">エラーが発生しました</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mエラーメッセージ: \u001b[0m\u001b[31m'NoneType'\u001b[0m\u001b[31m object has no attribute \u001b[0m\u001b[31m'observe'\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">エラーメッセージ: </span><span style=\"color: #800000; text-decoration-color: #800000\">'NoneType'</span><span style=\"color: #800000; text-decoration-color: #800000\"> object has no attribute </span><span style=\"color: #800000; text-decoration-color: #800000\">'observe'</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-114-e490a30edf10>\", line 15, in <cell line: 2>\n",
            "    dropdown_widget.observe(on_dropdown_value_change, names='v_model')\n",
            "AttributeError: 'NoneType' object has no attribute 'observe'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m9.\u001b[0m0M    .git\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.</span>0M    .git\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "✅ コードの保存が完了しました。\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ コードの保存が完了しました。\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "#@title **<font color='Green'>統計データのロード**\n",
        "try:\n",
        "    cleaned_df_path =f'/content/drive/MyDrive/ColabNotebooks/forecast_loto/{select_loto}/processed_data/pre_processed/{use_reshape_dataframe}/cleaned'\n",
        "\n",
        "    path=cleaned_df_path\n",
        "    data_holder.df = None\n",
        "    data_holder.ckeck = None\n",
        "    data_holder.filename = None\n",
        "\n",
        "    # ipyvueのHtmlウィジェットを先に表示し、その後にipyvuetifyのウィジェットを表示します。\n",
        "    checkbox_widget = create_vuetify_checkbox()\n",
        "    display(vue.Html(tag=\"h2\", children=[\"統計結果の保存データのロード\"]), checkbox_widget)\n",
        "    # ipyvueのHtmlウィジェットを先に表示し、その後にipyvuetifyのウィジェットを表示します。\n",
        "    dropdown_widget = create_vuetify_dropdown(path)\n",
        "    dropdown_widget.observe(on_dropdown_value_change, names='v_model')\n",
        "except Exception as e:\n",
        "    dric(\"[red]エラーが発生しました[/red]\")\n",
        "    dric(f\"[red]エラーメッセージ: {str(e)}[/red]\")\n",
        "    text_to_speech(f\"エラーが発生しました。詳細は以下の通りです: {str(e)}\")\n",
        "    traceback.print_exc()\n",
        "git_save(git_email, git_username, git_token, git_repository)\n",
        "text_to_speech(f\"統計データのロードが完了しました\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "QHyW6ToFbYXu",
        "outputId": "905eeb78-6c49-43ee-cbf9-0a34b301005a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "条件1の結果: \u001b[3;91mFalse\u001b[0m \u001b[1m(\u001b[0mdata_holderに'filename'属性が存在し、その値がcleaned_pathと一致するかどうか\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">条件1の結果: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span> <span style=\"font-weight: bold\">(</span>data_holderに'filename'属性が存在し、その値がcleaned_pathと一致するかどうか<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "条件2の結果: \u001b[3;91mFalse\u001b[0m \u001b[1m(\u001b[0mdata_holderに'check'属性が存在し、その値がTrueであるかどうか\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">条件2の結果: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span> <span style=\"font-weight: bold\">(</span>data_holderに'check'属性が存在し、その値がTrueであるかどうか<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "条件3の結果: \u001b[3;91mFalse\u001b[0m \u001b[1m(\u001b[0mdata_holderに'df'属性が存在し、その値がNoneでないかどうか\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">条件3の結果: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span> <span style=\"font-weight: bold\">(</span>data_holderに'df'属性が存在し、その値がNoneでないかどうか<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m特徴量の保存データのロードが失敗しました\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">特徴量の保存データのロードが失敗しました</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mエラーが発生しました\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">エラーが発生しました</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mエラーメッセージ: name \u001b[0m\u001b[31m'csv_cleaned_df'\u001b[0m\u001b[31m is not defined\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">エラーメッセージ: name </span><span style=\"color: #800000; text-decoration-color: #800000\">'csv_cleaned_df'</span><span style=\"color: #800000; text-decoration-color: #800000\"> is not defined</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-115-87ac15f30f59>\", line 25, in <cell line: 3>\n",
            "    missing_columns = [col for col in required_columns if col not in csv_cleaned_df.columns]\n",
            "  File \"<ipython-input-115-87ac15f30f59>\", line 25, in <listcomp>\n",
            "    missing_columns = [col for col in required_columns if col not in csv_cleaned_df.columns]\n",
            "NameError: name 'csv_cleaned_df' is not defined\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m9.\u001b[0m0M    .git\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.</span>0M    .git\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "✅ コードの保存が完了しました。\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ コードの保存が完了しました。\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title **<font color='Green'>統計結果を書き込む**\n",
        "\n",
        "try:\n",
        "    condition1 = hasattr(data_holder, 'filename') and data_holder.filename == cleaned_df_path\n",
        "    dric(f\"条件1の結果: {condition1} (data_holderに'filename'属性が存在し、その値がcleaned_pathと一致するかどうか)\")\n",
        "\n",
        "    condition2 = hasattr(data_holder, 'check') and data_holder.check is True\n",
        "    dric(f\"条件2の結果: {condition2} (data_holderに'check'属性が存在し、その値がTrueであるかどうか)\")\n",
        "\n",
        "    condition3 = hasattr(data_holder, 'df') and data_holder.df is not None\n",
        "    dric(f\"条件3の結果: {condition3} (data_holderに'df'属性が存在し、その値がNoneでないかどうか)\")\n",
        "\n",
        "    if condition1 and condition2 and condition3:\n",
        "        csv_cleaned_df = data_holder.df\n",
        "        display(csv_cleaned_df.tail())\n",
        "        display(f\"カラム数 {len(csv_cleaned_df.columns)}  \\n レコード数 {len(csv_cleaned_df)}\")\n",
        "\n",
        "    else:\n",
        "        dric(\"[red]特徴量の保存データのロードが失敗しました\")\n",
        "        text_to_speech(f\"特徴量の保存データのロードが失敗しました\")\n",
        "\n",
        "    # 必要なカラムのリストを作成します\n",
        "    required_columns = [target, 'date', 'unique_id']\n",
        "\n",
        "    # 存在しないカラムを確認します\n",
        "    missing_columns = [col for col in required_columns if col not in csv_cleaned_df.columns]\n",
        "\n",
        "    if len(missing_columns) > 0:\n",
        "        raise ValueError(f\"以下の必要なカラムがfeatures_dfに存在しません：{', '.join(missing_columns)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    dric(\"[red]エラーが発生しました[/red]\")\n",
        "    dric(f\"[red]エラーメッセージ: {str(e)}[/red]\")\n",
        "    text_to_speech(f\"エラーが発生しました。詳細は以下の通りです: {str(e)}\")\n",
        "    traceback.print_exc()\n",
        "text_to_speech(f\"統計結果の書き込みが完了しました\")\n",
        "git_save(git_email, git_username, git_token, git_repository)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8PYJS9k2gie"
      },
      "source": [
        "# **<font color='Blue'>特徴量の選択**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGPNvhgYNKTH"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# @title **特徴量の選択** { run: \"auto\" }\n",
        "if select_features_process:\n",
        "\n",
        "    initialize_ray(lib_list=None)\n",
        "\n",
        "    if 'csv_cleaned_df' in globals() or 'csv_cleaned_df' in locals():\n",
        "        if not csv_cleaned_df.empty:\n",
        "            cleaned_df = csv_cleaned_df\n",
        "\n",
        "\n",
        "    # unique_idのユニーク値を取得\n",
        "    unique_ids = cleaned_df['unique_id'].unique()\n",
        "\n",
        "    # 空のデータフレームを作成\n",
        "    select_features_df = pd.DataFrame()\n",
        "    all_features_df = pd.DataFrame()\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Rayのプールを作成\n",
        "    with Pool() as pool:\n",
        "        for unique_id in tqdm(unique_ids):\n",
        "            dric(f\"unique_id={unique_id}\")\n",
        "            try:\n",
        "                # unique_idでデータをフィルタリング\n",
        "                df_filtered = cleaned_df[cleaned_df['unique_id'] == unique_id]\n",
        "                df_filtered_O = df_filtered.drop('unique_id', axis=1)\n",
        "                df_filtered_1=df_filtered.set_index('date')\n",
        "\n",
        "\n",
        "                # 特徴量の抽出\n",
        "                extracted_features = extract_features(df_filtered_O[[\"date\",target]], column_id=\"date\", column_sort=\"date\")\n",
        "\n",
        "                # 特徴量の補完\n",
        "                imputed_features = impute(extracted_features)\n",
        "\n",
        "                # df_filteredのtargetカラムをimputed_featuresにマージ\n",
        "                merged = imputed_features.merge(df_filtered_1, left_index=True, right_index=True, how='inner')\n",
        "                merged[\"date\"]=merged.index\n",
        "\n",
        "                # Xとyを定義\n",
        "                y = merged[target]\n",
        "\n",
        "                # 重複したインデックスを削除\n",
        "                y = y.loc[~y.index.duplicated(keep='first')]\n",
        "\n",
        "                # 全てのデータフレームのインデックスを一致させる\n",
        "                common_index = y.index.intersection(imputed_features.index)\n",
        "                y = y.loc[common_index]\n",
        "                imputed_features = imputed_features.loc[common_index]\n",
        "                dric(f\"y = {len(y)} imputed_features = {len(imputed_features)}\",\"\\n\",\"*\"*100)\n",
        "\n",
        "                # 特徴量選択\n",
        "                features_filtered = select_features(imputed_features, y)\n",
        "\n",
        "                # unique_idを追加\n",
        "                features_filtered = features_filtered.merge(df_filtered_1[\"unique_id\"], left_index=True, right_index=True, how='inner')\n",
        "                # データフレームをマージ\n",
        "                select_features_df = pd.concat([select_features_df, features_filtered])\n",
        "\n",
        "                # 全てのデータフレームをマージ\n",
        "                all_features_df = pd.concat([all_features_df, merged])\n",
        "\n",
        "            except Exception as e:\n",
        "                dric(f\"Error processing unique_id {unique_id}: {e}\")\n",
        "                raise e\n",
        "\n",
        "    # 処理終了時間を記録し、処理時間を計算\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    # 経過時間を hh:mm:ss の形式に変換\n",
        "    elapsed_time_formatted = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n",
        "    # select_features_dfからカラムを取得\n",
        "    columns = select_features_df.columns.tolist()\n",
        "\n",
        "    # target, date, unique_idカラムが存在するか確認\n",
        "    required_columns = [target, 'date', 'unique_id']\n",
        "    for col in required_columns:\n",
        "        if col not in columns:\n",
        "            columns.append(col)\n",
        "\n",
        "    select_features_df=all_features_df[columns]\n",
        "\n",
        "    select_features_df_path =f'/content/drive/MyDrive/ColabNotebooks/forecast_loto/{select_loto}/processed_data/{use_reshape_dataframe}/select_features/select_features_df_{len(select_features_df.columns)}_{len(select_features_df)}_{get_current_time_jst()}.csv'\n",
        "    save_dataframe(select_features_df, select_features_df_path)\n",
        "\n",
        "    all_features_df_path =f'/content/drive/MyDrive/ColabNotebooks/forecast_loto/{select_loto}/processed_data/{use_reshape_dataframe}/all_features/all_features_df_{len(all_features_df.columns)}_{len(all_features_df)}_{get_current_time_jst()}.csv'\n",
        "    save_dataframe(all_features_df, all_features_df_path)\n",
        "\n",
        "    display(select_features_df.tail())\n",
        "\n",
        "    ray.shutdown()\n",
        "git_save(git_email, git_username, git_token, git_repository)\n",
        "text_to_speech(f\"特徴量の選択が完了しました\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTewSG0o2lhG"
      },
      "source": [
        "# **<font color='Blue'>特徴量の格納**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BUvhhcWWbpy"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title **<font color='Green'>特徴量のデータをロード**\n",
        "target_features ='特徴量選択'# @param [\"全選択\",\"特徴量選択\"]\n",
        "if target_features=='特徴量選択':\n",
        "    features =\"select_features\"\n",
        "else:\n",
        "    features =\"all_features\"\n",
        "\n",
        "features_path =f'/content/drive/MyDrive/ColabNotebooks/forecast_loto/{select_loto}/processed_data/{use_reshape_dataframe}/{features}'\n",
        "path =features_path\n",
        "data_holder.df = None\n",
        "data_holder.check = None\n",
        "data_holder.filename = None\n",
        "\n",
        "# ipyvueのHtmlウィジェットを先に表示し、その後にipyvuetifyのウィジェットを表示します。\n",
        "checkbox_widget = create_vuetify_checkbox()\n",
        "display(vue.Html(tag=\"h2\", children=[f\"特徴量の保存データのロード\"]), checkbox_widget)\n",
        "# ipyvueのHtmlウィジェットを先に表示し、その後にipyvuetifyのウィジェットを表示します。\n",
        "dropdown_widget = create_vuetify_dropdown(path)\n",
        "dropdown_widget.observe(on_dropdown_value_change, names='v_model')\n",
        "dric(path)\n",
        "# data_holder.dfの値の変化をチェック\n",
        "git_save(git_email, git_username, git_token, git_repository)\n",
        "text_to_speech(f\"特徴量のデータのロードが完了しました\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vUATYqxjkuaH"
      },
      "outputs": [],
      "source": [
        "#@title **<font color='Green'>特徴量を格納**\n",
        "try:\n",
        "    dric(path)\n",
        "\n",
        "    condition1 = hasattr(data_holder, 'filename') and data_holder.filename == features_path\n",
        "    dric(f\"条件1の結果: {condition1} (data_holderに'filename'属性が存在し、その値がfeatures_pathと一致するかどうか)\")\n",
        "\n",
        "    condition2 = hasattr(data_holder, 'check') and data_holder.check is True\n",
        "    dric(f\"条件2の結果: {condition2} (data_holderに'check'属性が存在し、その値がTrueであるかどうか)\")\n",
        "\n",
        "    condition3 = hasattr(data_holder, 'df') and data_holder.df is not None\n",
        "    dric(f\"条件3の結果: {condition3} (data_holderに'df'属性が存在し、その値がNoneでないかどうか)\")\n",
        "\n",
        "    if condition1 and condition2 and condition3:\n",
        "        features_df = data_holder.df\n",
        "        features_df_copy=features_df.copy()\n",
        "        display(features_df.tail())\n",
        "    else:\n",
        "        dric(\"[red]特徴量の保存データのロードが失敗しました\")\n",
        "\n",
        "    # 必要なカラムのリストを作成します\n",
        "    required_columns = [target, 'date', 'unique_id']\n",
        "\n",
        "    # 存在しないカラムを確認します\n",
        "    missing_columns = [col for col in required_columns if col not in features_df.columns]\n",
        "\n",
        "    if len(missing_columns) > 0:\n",
        "        raise ValueError(f\"以下の必要なカラムがfeatures_dfに存在しません：{', '.join(missing_columns)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    dric(\"[red]エラーが発生しました[/red]\")\n",
        "    dric(f\"[red]エラーメッセージ: {str(e)}[/red]\")\n",
        "    traceback.print_exc()\n",
        "git_save(git_email, git_username, git_token, git_repository)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djKrH8Oe1ks0"
      },
      "outputs": [],
      "source": [
        "#@title **特徴量の寄与率の計算**\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "# 特徴量の重要度を計算する関数\n",
        "@ray.remote\n",
        "def compute_feature_importance(hyperparameters, model, features_df, target):\n",
        "    try:\n",
        "        X = features_df.drop(target, axis=1)\n",
        "        y = features_df[target]\n",
        "        model.fit(X, y)\n",
        "\n",
        "        # 特徴量の重要度を計算\n",
        "        importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "\n",
        "        # Permutation Importance\n",
        "        perm_importance = pd.Series(permutation_importance(model, X, y, n_repeats=10, random_state=42).importances_mean, index=X.columns)\n",
        "\n",
        "        # Mutual Information\n",
        "        mutual_info = pd.Series(mutual_info_regression(X, y), index=X.columns)\n",
        "\n",
        "        # Correlation Coefficient\n",
        "        correlation_coef = X.corrwith(y)\n",
        "\n",
        "        # Lasso (L1) Regularization\n",
        "        lasso = LassoCV(cv=5).fit(X, y)\n",
        "        lasso_importance = pd.Series(np.abs(lasso.coef_), index=X.columns)\n",
        "\n",
        "        return importances, perm_importance, mutual_info, correlation_coef, lasso_importance\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました。[/red]\")\n",
        "        dric(f\"[red]関数 'compute_feature_importance' でエラーが発生しました: {e}[/red]\")\n",
        "        text_to_speech(f\"エラーが発生しました。詳細は以下の通りです: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "# Rayの初期化\n",
        "initialize_ray()\n",
        "models = [RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, AdaBoostRegressor, XGBRegressor]\n",
        "\n",
        "# ハイパーパラメータの設定\n",
        "hyperparameters = {\n",
        "    'n_estimators': [50, 100, 200, 300],\n",
        "    'max_depth': [None, 5, 10, 15],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# 文字列が含まれているカラムを抽出\n",
        "categorical_cols = features_df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# ワンホットエンコーディングを行う\n",
        "features_df = pd.get_dummies(features_df, columns=categorical_cols)\n",
        "\n",
        "# 相関分析を行い、予測に寄与する可能性のある特徴量だけを選択\n",
        "correlation_threshold = 0.001\n",
        "correlation = features_df.corrwith(features_df[target])\n",
        "selected_features = correlation[correlation.abs() > correlation_threshold].index\n",
        "features_df = features_df[selected_features]\n",
        "\n",
        "# グリッドサーチを用いて最適なハイパーパラメータを選択\n",
        "grid_search = GridSearchCV(RandomForestRegressor(), hyperparameters, cv=5)\n",
        "grid_search.fit(features_df.drop(target, axis=1), features_df[target])\n",
        "best_hyperparameters = grid_search.best_params_\n",
        "\n",
        "# 各ハイパーパラメータに対して特徴量の重要度を計算\n",
        "total_tasks = len(models)\n",
        "progress_bar = tqdm(total=total_tasks, desc='Overall Progress')\n",
        "\n",
        "results = []\n",
        "start_time = time.time()\n",
        "for model in (models):\n",
        "    # XGBRegressorのインスタンス作成時にGPUを利用するように設定\n",
        "    if model == XGBRegressor:\n",
        "        # GPUが利用可能でない場合は、'hist'を使用\n",
        "        hyperparameters['tree_method'] = 'hist'\n",
        "    elif model == AdaBoostRegressor:\n",
        "        # DecisionTreeRegressorを基本推定器として設定し、max_depthとmin_samples_splitを設定\n",
        "        base_estimator = DecisionTreeRegressor(max_depth=best_hyperparameters['max_depth'], min_samples_split=best_hyperparameters['min_samples_split'])\n",
        "        best_hyperparameters['base_estimator'] = base_estimator\n",
        "        # max_depthとmin_samples_splitはもう必要ないので削除\n",
        "        del best_hyperparameters['max_depth']\n",
        "        del best_hyperparameters['min_samples_split']\n",
        "    model_instance = model(**best_hyperparameters)\n",
        "\n",
        "\n",
        "    result_id = compute_feature_importance.remote(best_hyperparameters, model_instance, features_df, target)\n",
        "    results.append(result_id)\n",
        "\n",
        "    # Update the progress bar\n",
        "    progress_bar.update()\n",
        "    elapsed_time = time.time() - start_time\n",
        "    remaining_time = (total_tasks - progress_bar.n) * (elapsed_time / progress_bar.n)\n",
        "    progress_bar.set_description(f\"Processing {model.__name__} with {best_hyperparameters}, Elapsed Time: {elapsed_time:.2f}s, Estimated Remaining Time: {remaining_time:.2f}s\")\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "# プログレスバーを作成\n",
        "progress_bar = tqdm(total=len(results), desc='Fetching results')\n",
        "\n",
        "# すべての結果が利用可能になるまで待つ\n",
        "feature_importances = []\n",
        "while len(results) > 0:\n",
        "    ready, results = ray.wait(results)\n",
        "    for result_id in ready:\n",
        "        try:\n",
        "            feature_importances.append(ray.get(result_id))\n",
        "        except Exception as e:\n",
        "            dric(\"[red]エラーが発生しました。[/red]\")\n",
        "            dric(f\"[red]結果の取得中にエラーが発生しました: {e}[/red]\")\n",
        "            text_to_speech(f\"エラーが発生しました。詳細は以下の通りです: {str(e)}\")\n",
        "            traceback.print_exc()\n",
        "        # プログレスバーを更新\n",
        "        progress_bar.update()\n",
        "    # 短いスリープ時間を設けて、他のタスクが進行するのを待つ\n",
        "    time.sleep(0.1)\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "# 特徴量の重要度をデータフレームに保存\n",
        "feature_importances_df = pd.concat([result[0] for result in feature_importances], axis=1, keys=['Importance', 'Permutation_Importance', 'Mutual_Information', 'Correlation_Coefficient', 'Lasso_Importance'])\n",
        "\n",
        "# 特徴量の重要度が0のものを除外\n",
        "feature_importances_df = feature_importances_df.loc[:, (feature_importances_df != 0).any(axis=0)]\n",
        "\n",
        "# 各モデルと各重要度の計算のセットに対してプロットを作成\n",
        "for column in feature_importances_df.columns:\n",
        "    fig = px.histogram(feature_importances_df, x=column, title=f'{column} Distribution', nbins=50)\n",
        "    fig.update_layout(autosize=False, width=1000, height=800)\n",
        "    fig.show()\n",
        "\n",
        "# アンサンブル学習の結果を取得\n",
        "ensemble_importances = feature_importances_df.mean(axis=1)\n",
        "\n",
        "# アンサンブルした特徴量の重要度をデータフレームに保存\n",
        "ensemble_importances_df = ensemble_importances.to_frame(name='Ensemble_Importance')\n",
        "\n",
        "# アンサンブルした特徴量の重要度のプロットを作成\n",
        "non_zero_importances = ensemble_importances_df[ensemble_importances_df['Ensemble_Importance'] != 0]\n",
        "fig = px.histogram(non_zero_importances, x='Ensemble_Importance', title='Ensemble_Importance_Distribution', nbins=50)\n",
        "fig.update_layout(autosize=False, width=1000, height=800)\n",
        "fig.show()\n",
        "\n",
        "text_to_speech(f\"特徴量の寄与率の計算が完了しました\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hjhq-UTZD5M"
      },
      "outputs": [],
      "source": [
        "@ray.remote\n",
        "def compute_feature_importance(hyperparameters, model, features_df, target):\n",
        "    try:\n",
        "        X = features_df.drop(target, axis=1)\n",
        "        y = features_df[target]\n",
        "        model.fit(X, y)\n",
        "\n",
        "        # 特徴量の重要度を計算\n",
        "        importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "\n",
        "        # Permutation Importance\n",
        "        perm_importance = pd.Series(permutation_importance(model, X, y, n_repeats=10, random_state=42).importances_mean, index=X.columns)\n",
        "\n",
        "        # Mutual Information\n",
        "        mutual_info = pd.Series(mutual_info_regression(X, y), index=X.columns)\n",
        "\n",
        "        # Correlation Coefficient\n",
        "        correlation_coef = X.corrwith(y)\n",
        "\n",
        "        # Lasso (L1) Regularization\n",
        "        lasso = LassoCV(cv=5).fit(X, y)\n",
        "        lasso_importance = pd.Series(np.abs(lasso.coef_), index=X.columns)\n",
        "\n",
        "        # SHAP Values\n",
        "        explainer = shap.Explainer(model)\n",
        "        shap_values = explainer(X)\n",
        "        shap_importance = pd.Series(np.abs(shap_values.values).mean(axis=0), index=X.columns)\n",
        "\n",
        "        return importances, perm_importance, mutual_info, correlation_coef, lasso_importance, shap_importance\n",
        "    except Exception as e:\n",
        "        dric(\"エラーが発生しました。\")\n",
        "        dric(f\"関数 'compute_feature_importance' でエラーが発生しました: {e}\")\n",
        "        text_to_speech(f\"エラーが発生しました。詳細は以下の通りです: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "# Rayの初期化\n",
        "initialize_ray([\"shap\"])\n",
        "models = [RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, AdaBoostRegressor, XGBRegressor]\n",
        "\n",
        "# ハイパーパラメータの設定\n",
        "hyperparameters = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 5],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "# 文字列が含まれているカラムを抽出\n",
        "categorical_cols = features_df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# ワンホットエンコーディングを行う\n",
        "features_df = pd.get_dummies(features_df, columns=categorical_cols)\n",
        "\n",
        "# 相関分析を行い、予測に寄与する可能性のある特徴量だけを選択\n",
        "correlation_threshold = 0.4\n",
        "correlation = features_df.corrwith(features_df[target])\n",
        "selected_features = correlation[correlation.abs() > correlation_threshold].index\n",
        "features_df = features_df[selected_features]\n",
        "\n",
        "# グリッドサーチを用いて最適なハイパーパラメータを選択\n",
        "grid_search = GridSearchCV(RandomForestRegressor(), hyperparameters, cv=5)\n",
        "grid_search.fit(features_df.drop(target, axis=1), features_df[target])\n",
        "best_hyperparameters = grid_search.best_params_\n",
        "\n",
        "# 各ハイパーパラメータに対して特徴量の重要度を計算\n",
        "total_tasks = len(models)\n",
        "progress_bar = tqdm(total=total_tasks, desc='Overall Progress')\n",
        "\n",
        "# 各ハイパーパラメータに対して特徴量の重要度を計算\n",
        "total_tasks = len(models)\n",
        "progress_bar = tqdm(total=total_tasks, desc='Overall Progress')\n",
        "\n",
        "results = []\n",
        "start_time = time.time()\n",
        "for model in (models):\n",
        "    # XGBRegressorのインスタンス作成時にGPUを利用するように設定\n",
        "    if model == XGBRegressor:\n",
        "        # GPUが利用可能でない場合は、'hist'を使用\n",
        "        hp['tree_method'] = 'hist'\n",
        "    elif model == AdaBoostRegressor:\n",
        "        # max_depthとmin_samples_splitはもう必要ないので削除\n",
        "        del best_hyperparameters['max_depth']\n",
        "        del best_hyperparameters['min_samples_split']\n",
        "    model_instance = model(**best_hyperparameters)\n",
        "\n",
        "    result_id = compute_feature_importance.remote(best_hyperparameters, model_instance, features_df, target)\n",
        "    results.append(result_id)\n",
        "\n",
        "    # Update the progress bar\n",
        "    progress_bar.update()\n",
        "    elapsed_time = time.time() - start_time\n",
        "    remaining_time = (total_tasks - progress_bar.n) * (elapsed_time / progress_bar.n)\n",
        "    progress_bar.set_description(f\"Processing {model.__name__} with {best_hyperparameters}, Elapsed Time: {elapsed_time:.2f}s, Estimated Remaining Time: {remaining_time:.2f}s\")\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "# プログレスバーを作成\n",
        "progress_bar = tqdm(total=len(results), desc='Fetching results')\n",
        "\n",
        "# すべての結果が利用可能になるまで待つ\n",
        "feature_importances = []\n",
        "while len(results) > 0:\n",
        "    ready, results = ray.wait(results)\n",
        "    for result_id in ready:\n",
        "        try:\n",
        "            feature_importances.append(ray.get(result_id))\n",
        "        except Exception as e:\n",
        "            dric(\"[red]エラーが発生しました。[/red]\")\n",
        "            dric(f\"[red]結果の取得中にエラーが発生しました: {e}[/red]\")\n",
        "            text_to_speech(f\"エラーが発生しました。詳細は以下の通りです: {str(e)}\")\n",
        "            traceback.print_exc()\n",
        "        # プログレスバーを更新\n",
        "        progress_bar.update()\n",
        "    # 短いスリープ時間を設けて、他のタスクが進行するのを待つ\n",
        "    time.sleep(0.1)\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "# 特徴量の重要度をデータフレームに保存\n",
        "feature_importances_df = pd.concat([result[0] for result in feature_importances], axis=1, keys=['Importance', 'Permutation_Importance', 'Mutual_Information', 'Correlation_Coefficient', 'Lasso_Importance', 'SHAP_Importance'])\n",
        "# 特徴量の重要度が0のものを除外\n",
        "feature_importances_df = feature_importances_df.loc[:, (feature_importances_df != 0).any(axis=0)]\n",
        "\n",
        "# 各モデルと各重要度の計算のセットに対してプロットを作成\n",
        "for column in feature_importances_df.columns:\n",
        "    fig = px.histogram(feature_importances_df, x=column, title=f'{column} Distribution', nbins=50)\n",
        "    fig.update_layout(autosize=False, width=1000, height=800)\n",
        "    fig.show()\n",
        "\n",
        "# アンサンブル学習の結果を取得\n",
        "ensemble_importances = feature_importances_df.mean(axis=1)\n",
        "\n",
        "# アンサンブルした特徴量の重要度をデータフレームに保存\n",
        "ensemble_importances_df = ensemble_importances.to_frame(name='Ensemble_Importance')\n",
        "\n",
        "# アンサンブルした特徴量の重要度のプロットを作成\n",
        "non_zero_importances = ensemble_importances_df[ensemble_importances_df['Ensemble_Importance'] != 0]\n",
        "fig = px.histogram(non_zero_importances, x='Ensemble_Importance', title='Ensemble_Importance_Distribution', nbins=50)\n",
        "fig.update_layout(autosize=False, width=1000, height=800)\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMtPplcJ2-W_"
      },
      "source": [
        "# **<font color='Blue'>カラム名の変更**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LiZHI0wPK0K"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#@title **カラム名の変更と分割**\n",
        "features_df=features_df_copy\n",
        "\n",
        "# 必要なカラムとその対応する値を辞書として定義\n",
        "columns_dict = {\n",
        "    \"date\": \"ds\",\n",
        "    \"unique_id\": \"unique_id\",\n",
        "    target: \"y\"\n",
        "}\n",
        "\n",
        "try:\n",
        "\n",
        "    # 'ds'または'date'カラムが存在するか確認\n",
        "    if 'ds' in features_df.columns:\n",
        "        time_col = 'ds'\n",
        "    elif 'date' in features_df.columns:\n",
        "        time_col = 'date'\n",
        "    else:\n",
        "        raise ValueError(\"Neither 'ds' nor 'date' column is found in the DataFrame.\")\n",
        "\n",
        "    # 'ds'または'date'列がobject型の場合、タイムスタンプに変換\n",
        "    if features_df[time_col].dtype == 'object':\n",
        "        features_df[time_col] = pd.to_datetime(features_df[time_col])\n",
        "\n",
        "    # 再度、'ds'または'date'列のデータ型を確認\n",
        "    dric(features_df[time_col].dtype)\n",
        "\n",
        "    # カラム名と順序が既に変更されているか確認\n",
        "    if set(columns_dict.values()).issubset(set(features_df.columns)) and features_df.columns.tolist()[:3] == list(columns_dict.values()):\n",
        "        dric(\"カラム名と順序は既に変更されています。\")\n",
        "        dric(f\"features_dfの長さ: {len(features_df)}\")\n",
        "        text_to_speech(f\"カラム名と順序は既に変更されています。\")\n",
        "        unique_values = features_df['ds'].unique()\n",
        "        # unique_valuesから分割する日付を取得\n",
        "        split_date = unique_values[-test_size]\n",
        "\n",
        "        # split_dateを基にデータフレームを分割\n",
        "        Y_train_df = features_df[features_df['ds'] < split_date]\n",
        "        Y_test_df = features_df[features_df['ds'] >= split_date]\n",
        "\n",
        "        # インデックスをリセット\n",
        "        Y_train_df = Y_train_df.reset_index(drop=True)\n",
        "        Y_test_df = Y_test_df.reset_index(drop=True)\n",
        "\n",
        "        display(Y_train_df.head())\n",
        "        dric(f\"Y_train_dfの長さ{len(Y_train_df)} \\n Y_train_dfの特徴量 {len(Y_train_df.columns)}\")\n",
        "        display(Y_test_df.head())\n",
        "        dric(f\"Y_test_dffの長さ{len(Y_test_df)} \\n Y_test_dfの特徴量 {len(Y_test_df.columns)}\")\n",
        "\n",
        "    else:\n",
        "        # 各カラムを処理\n",
        "        for old_name, new_name in columns_dict.items():\n",
        "            # カラムが存在する場合のみリネーム\n",
        "            if old_name in features_df.columns:\n",
        "                features_df.rename(columns={old_name: new_name}, inplace=True)\n",
        "\n",
        "        # 'y', 'ds', 'unique_id'をカラムの先頭に移動\n",
        "        cols = ['ds', 'y', 'unique_id'] + [col for col in features_df.columns if col not in ['y', 'ds', 'unique_id']]\n",
        "        features_df = features_df[cols]\n",
        "\n",
        "        # 'unique_id'と'ds'の順でソート\n",
        "        features_df = features_df.sort_values(by=['unique_id', 'ds'])\n",
        "\n",
        "        # カラムの順序が正しいかチェック\n",
        "        if features_df.columns.tolist() == cols:\n",
        "            dric(\"カラムの順序は正しく変更されました。\")\n",
        "            dric(f\"features_dfの長さ: {len(features_df)}\")\n",
        "            text_to_speech(f\"カラムの順序は正しく変更されました。\")\n",
        "            unique_values = features_df['ds'].unique()\n",
        "            # unique_valuesから分割する日付を取得\n",
        "            split_date = unique_values[-test_size]\n",
        "\n",
        "            # split_dateを基にデータフレームを分割\n",
        "            Y_train_df = features_df[features_df['ds'] < split_date]\n",
        "            Y_test_df = features_df[features_df['ds'] >= split_date]\n",
        "\n",
        "            # インデックスをリセット\n",
        "            Y_train_df = Y_train_df.reset_index(drop=True)\n",
        "            Y_test_df = Y_test_df.reset_index(drop=True)\n",
        "\n",
        "            display(Y_train_df.head())\n",
        "            dric(f\"Y_train_dfの長さ{len(Y_train_df)} \\n Y_train_dfの特徴量 {len(Y_train_df.columns)}\")\n",
        "            display(Y_test_df.head())\n",
        "            dric(f\"Y_test_dffの長さ{len(Y_test_df)} \\n Y_test_dfの特徴量 {len(Y_test_df.columns)}\")\n",
        "\n",
        "        else:\n",
        "            dric(\"エラー: カラムの順序が正しくありません。\")\n",
        "            text_to_speech(f\"エラー: カラムの順序が正しくありません。\")\n",
        "except Exception as e:\n",
        "    dric(f\"エラー: カラムの処理に失敗しました。\")\n",
        "    text_to_speech(f\"エラー: カラムの処理に失敗しました。\")\n",
        "    dric(str(e))\n",
        "text_to_speech(f\"カラム名の変更と分割が完了しました\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yEC2sG4H1RX"
      },
      "source": [
        "# **<font color='Blue'>モデル定義**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeEKd1yE1cAC"
      },
      "outputs": [],
      "source": [
        "#@title **モデル定義**\n",
        "\n",
        "try:\n",
        "    n_series=len(features_df.unique_id.unique())\n",
        "    result = undefined_vars_check()\n",
        "    if not result:\n",
        "        dric(\"[red bold]*\"*50)\n",
        "        dric(\"[red bold]エラーが発生しました: 一部の変数が定義されていません\")\n",
        "        text_to_speech(f\"エラーが発生しました: 一部の変数が定義されていません\")\n",
        "\n",
        "    else:\n",
        "        dric(\"[green bold]*\"*50)\n",
        "        dric(\"[green bold]モデルを定義します\")\n",
        "        text_to_speech(f\"モデルを定義します\")\n",
        "        model_alias=f\"_horizon={horizon}_backend={backend}_refit_with_val={refit_with_val}_num_samples={num_samples}_features={len(features_df.columns)}_len_{len(features_df)}_shape_{use_reshape_dataframe}\"\n",
        "        pre_models =[\n",
        "        AutoRNN(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                alias=f\"{AutoR NN.__name__}\"+model_alias\n",
        "                ),\n",
        "        AutoTCN(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                alias=f\"{AutoTCN.__name__}\"+model_alias\n",
        "                ),\n",
        "        AutoDeepAR(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                alias=f\"{AutoDeepAR.__name__}\"+model_alias\n",
        "                ),\n",
        "        AutoDilatedRNN(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                alias=f\"{AutoDilatedRNN.__name__}\"+model_alias\n",
        "                       ),\n",
        "        AutoBiTCN(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                alias=f\"{AutoBiTCN.__name__}\"+model_alias\n",
        "                  ),\n",
        "        AutoMLP(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                alias=f\"{AutoMLP.__name__}\"+model_alias\n",
        "                ),\n",
        "        AutoNBEATS(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                #    alias=f\"{AutoNBEATS.__name__}\"+model_alias\n",
        "                   ),\n",
        "        AutoNBEATSx(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                    alias=f\"{AutoNBEATSx.__name__}\"+model_alias\n",
        "                    ),\n",
        "        AutoNHITS(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                #   alias=f\"{AutoNHITS.__name__}\"+model_alias\n",
        "                  ),\n",
        "        AutoDLinear(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                    alias=f\"{AutoDLinear.__name__}\"+model_alias\n",
        "                    ),\n",
        "        AutoNLinear(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                    alias=f\"{AutoNLinear.__name__}\"+model_alias\n",
        "                    ),\n",
        "        AutoTFT(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                alias=f\"{AutoTFT.__name__}\"+model_alias\n",
        "                ),\n",
        "        AutoVanillaTransformer(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                               alias=f\"{AutoVanillaTransformer.__name__}\"+model_alias\n",
        "                               ),\n",
        "        AutoInformer(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                     alias=f\"{AutoInformer.__name__}\"+model_alias\n",
        "                     ),\n",
        "        AutoAutoformer(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                       alias=f\"{AutoAutoformer.__name__}\"+model_alias\n",
        "                       ),\n",
        "        AutoFEDformer(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                      alias=f\"{AutoFEDformer.__name__}\"+model_alias\n",
        "                      ),\n",
        "        AutoPatchTST(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                     alias=f\"{AutoPatchTST.__name__}\"+model_alias\n",
        "                     ),\n",
        "        AutoiTransformer(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,n_series=n_series,num_samples=num_samples,\n",
        "                         alias=f\"{AutoiTransformer.__name__}\"+model_alias\n",
        "                         ),\n",
        "        AutoTimesNet(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                     alias=f\"{AutoTimesNet.__name__}\"+model_alias\n",
        "                     ),\n",
        "        AutoStemGNN(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,n_series=n_series,num_samples=num_samples,\n",
        "                    alias=f\"{AutoStemGNN.__name__}\"+model_alias\n",
        "                    ),\n",
        "        AutoTSMixer(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,n_series=n_series,num_samples=num_samples,\n",
        "                    alias=f\"{AutoTSMixer.__name__}\"+model_alias\n",
        "                    ),\n",
        "        AutoTSMixerx(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,n_series=n_series,num_samples=num_samples,\n",
        "                     alias=f\"{AutoTSMixerx.__name__}\"+model_alias\n",
        "                     ),\n",
        "        AutoMLPMultivariate(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,n_series=n_series,num_samples=num_samples,\n",
        "                            alias=f\"{AutoMLPMultivariate.__name__}\"+model_alias\n",
        "                            ),\n",
        "        ]\n",
        "        dric(\"[green bold]*\"*50)\n",
        "        dric(\"[green bold]すべての変数が定義されています\")\n",
        "        text_to_speech(f\"すべての変数が定義されています\")\n",
        "\n",
        "except Exception as e:\n",
        "    dric(\"[red bold]*\"*50)\n",
        "    dric(f\"[red bold]エラーが発生しました: {str(e)}\")\n",
        "    text_to_speech(f\"エラーが発生しました: {str(e)}\")\n",
        "    traceback.print_exc()\n",
        "    # @title モデルの差分\n",
        "\n",
        "\n",
        "# 'Auto'が含まれる名前のモデルを抽出\n",
        "models_with_auto = [model for model in dir() if 'Auto' in model]\n",
        "pre_model_names = [model.__class__.__name__ for model in pre_models]\n",
        "models_with_auto\n",
        "# pre_model_namesとauto_namesの差分を見つける\n",
        "diff_models = list( set(models_with_auto)-set(pre_model_names))\n",
        "\n",
        "\n",
        "dric(f\"[green bold] neuralforecast.autoの中のAutoモデル \\n {set(models_with_auto)}\")\n",
        "dric(f\"[blue bold] \\n 定義済みのモデル \\n{set(pre_model_names)}\\n\")\n",
        "dric(f\"[red bold] neuralforecast.autoの中のAutoモデルと定義済みのモデルの差分　\\n {diff_models}\")\n",
        "git_save(git_email, git_username, git_token, git_repository)\n",
        "text_to_speech(f\"モデル定義が完了しました\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEWzXlaiw1IO"
      },
      "outputs": [],
      "source": [
        "# @title **モデルの選択**  { run: \"auto\" }\n",
        "\n",
        "# モデルの名前を取得\n",
        "model_names = [model.__class__.__name__ for model in pre_models]\n",
        "\n",
        "# チェックボックスを作成\n",
        "checkboxes = [widgets.Checkbox(value=True, description=name) for name in model_names]  # 初期値をTrueに設定\n",
        "\n",
        "# 全て選択/選択解除のチェックボックスを作成\n",
        "select_all = widgets.Checkbox(value=True, description='全て選択/選択解除')\n",
        "\n",
        "# models変数を初期化\n",
        "models = pre_models.copy()\n",
        "\n",
        "# 各チェックボックスに変更イベントを追加\n",
        "for checkbox in checkboxes:\n",
        "    checkbox.observe(on_change)\n",
        "\n",
        "# 全て選択/選択解除のチェックボックスに変更イベントを追加\n",
        "select_all.observe(on_select_all_change)\n",
        "git_save(git_email, git_username, git_token, git_repository)\n",
        "# チェックボックスを表示\n",
        "display(select_all)\n",
        "# チェックボックスを2列に表示\n",
        "widgets.HBox([widgets.VBox(checkboxes[:len(checkboxes)//2]), widgets.VBox(checkboxes[len(checkboxes)//2:])])\n",
        "text_to_speech(f\"モデルの選択が完了しました\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyQ0IO13LWsT"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "kPjBWmIOD8m3"
      },
      "outputs": [],
      "source": [
        "#@title **モデルの再学習と予測の評価　関数**\n",
        "\n",
        "error_directories=[]\n",
        "error_directories2=[]\n",
        "def evaluate_models(parent_folder,select_loto,target,Y_train_df,y_test,gpus,cpus,retrain=False):\n",
        "    \"\"\"\n",
        "    この関数は、指定したディレクトリに保存されているモデルのパフォーマンスを評価します。\n",
        "    モデルを再学習するか、予測のためにだけロードするかを選択できます。\n",
        "\n",
        "    引数:\n",
        "    parent_folder (str): モデルが保存されている親ディレクトリ。\n",
        "    retrain (bool): Trueの場合、モデルは再学習されます。Falseの場合、モデルは予測のためにだけロードされます。\n",
        "\n",
        "    戻り値:\n",
        "    csv_path\n",
        "    \"\"\"\n",
        "    # 使用例\n",
        "    dir_path = \"/content/lightning_logs\"\n",
        "    # remove_directory(dir_path)\n",
        "    parent_directory = os.path.dirname(parent_folder)\n",
        "    save_folder_name = os.path.basename(parent_folder)\n",
        "    # 結果用のデータフレームを初期化\n",
        "    # results_df = pd.DataFrame(columns=['Model', 'MSE', 'MAE', 'R2', 'RMSE', 'MAPE', 'MedAE'])\n",
        "    results_df = pd.DataFrame(columns=['Model', 'MSE', 'MAE', 'R2', 'RMSE', 'MAPE', 'MedAE', 'Feature', 'Time', 'loto', 'N', '学習量'])\n",
        "\n",
        "    # ディレクトリ内のすべての項目をリストアップ\n",
        "    items = os.listdir(parent_folder)\n",
        "    dric(\"$\"*100,\"\\n\",f\"items={items}\")\n",
        "    # ディレクトリをフィルタリング\n",
        "    directories = [item for item in items if os.path.isdir(os.path.join(parent_folder, item)) and item != 'lightning_logs']\n",
        "    error_directories = []\n",
        "    error_directories2 = []\n",
        "    # 各ディレクトリ（モデル）に対してループ\n",
        "    for directory in tqdm(directories):\n",
        "        dric(\"*\"*100,\"\\n\",f\"ディレクトリ {directory} の処理を開始します。\")\n",
        "        dric(\"*\"*100,\"\\n\",f\"親ディレクトリ {save_folder_name} の処理を開始します。\")\n",
        "        text_to_speech(f\"ディレクトリ {directory} の処理を開始します。\")\n",
        "        try:\n",
        "            first_string = directory.split('_')[0]\n",
        "            save_directory = f'{parent_folder}/'\n",
        "            dric(\"-\"*100,\"\\n\",f\"save_directory ={save_directory}\")\n",
        "            # 現在の時刻を取得\n",
        "            start_time = time.time()\n",
        "             # モデルをロード\n",
        "            model_path = os.path.join(parent_folder, directory)\n",
        "            dric(\"-\"*100,\"\\n\",f\"model_path ={model_path}\")\n",
        "            nf = NeuralForecast.load( model_path)\n",
        "\n",
        "            # 指定された場合はモデルを再学習\n",
        "            if retrain:\n",
        "                dric(\"モデルの再学習を開始します...\")\n",
        "                text_to_speech(f\"モデルの再学習を開始します...\")\n",
        "                nf.fit(df=Y_train_df)\n",
        "\n",
        "                # 現在の日時を取得\n",
        "                now = datetime.now(pytz.timezone('Asia/Tokyo'))\n",
        "                # 日時を文字列に変換（例：2024_04_14_00_29_50）\n",
        "                timestamp_str = now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "\n",
        "                elapsed_time = time.time() - start_time\n",
        "                elapsed_time_str = str(dt.timedelta(seconds=int(elapsed_time)))\n",
        "                dric(f\"再学習にかかった時間: {elapsed_time_str}\")\n",
        "\n",
        "                save_directory = f\"{parent_directory}/{select_loto}_{target}_{len(Y_train_df.columns)}_{len(Y_train_df)}/\"\n",
        "                dric(\"-\"*100,\"\\n\",f\"save_directory ={save_directory}\")\n",
        "                save_path = save_directory +f'{save_folder_name}_{first_string}_{select_loto}_{target}_{len(Y_train_df.columns)}_{len(Y_train_df)}_{elapsed_time_str}'\n",
        "                dric(\".\"*100,\"\\n\",f\"save_path ={save_path}\")\n",
        "\n",
        "                dric(f\"{save_path}\\nにモデルを保存しています...\")\n",
        "                nf.save(path=save_path, overwrite=True)\n",
        "                dric(f\"{save_path}\\nにモデルの保存が完了しました。\")\n",
        "\n",
        "                dric(f\"{save_path}\\nのモデルを読み込んでいます...\")\n",
        "                nf = NeuralForecast.load(save_path)\n",
        "                dric(f\"{save_path}\\nのモデルの読み込みが完了しました。\")\n",
        "\n",
        "\n",
        "            # 予測を実行\n",
        "            start_time = time.time()\n",
        "            y_pred = nf.predict()\n",
        "            elapsed_time_pre = time.time() - start_time\n",
        "            elapsed_time_str_pre = str(dt.timedelta(seconds=int(elapsed_time_pre)))\n",
        "            #y_pred_values = round(y_pred.iloc[:, 1])\n",
        "            #y_pred_values = y_pred.values\n",
        "\n",
        "            # y_pred_values = y_pred.iloc[:, 1].values\n",
        "            y_pred_values = y_pred.iloc[:, 1].values.astype(int)\n",
        "\n",
        "            # 値を小数点以下2桁に丸める\n",
        "            #y_pred_values = [round(value, 2) for value in y_pred_values]\n",
        "            # 評価指標を計算\n",
        "            mse = mean_squared_error(y_test, y_pred_values)\n",
        "            mae = mean_absolute_error(y_test, y_pred_values)\n",
        "            r2 = r2_score(y_test, y_pred_values)\n",
        "            rmse = sqrt(mse)\n",
        "            mape = np.mean(np.abs((y_test - y_pred_values) / y_test)) * 100\n",
        "            medae = median_absolute_error(y_test, y_pred_values)\n",
        "\n",
        "            if retrain:\n",
        "                elapsed_time_str=elapsed_time_str\n",
        "            else:\n",
        "                elapsed_time_str=elapsed_time_str_pre\n",
        "\n",
        "\n",
        "            # 結果をデータフレームに追加\n",
        "            new_row = pd.DataFrame({\n",
        "                'Model': [directory],\n",
        "                'MSE': [mse],\n",
        "                'MAE': [mae],\n",
        "                'R2': [r2],\n",
        "                'RMSE': [rmse],\n",
        "                'MAPE': [mape],\n",
        "                'MedAE': [medae],\n",
        "                'Feature': [len(Y_train_df.columns)],\n",
        "                'Time': [elapsed_time_str],\n",
        "                'loto': [select_loto],\n",
        "                'N': [target],\n",
        "                '学習量': [len(Y_train_df)],\n",
        "                'Predicted': [y_pred_values.tolist()],\n",
        "                'Measured': [y_test.tolist()]\n",
        "            })\n",
        "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
        "        except Exception as e:\n",
        "            dric(f\"ディレクトリ {directory} でエラーが発生しました: {e}\")\n",
        "            text_to_speech(f\"ディレクトリ {directory} でエラーが発生しました: {e}\")\n",
        "            traceback.print_exc()\n",
        "            # エラーが発生したディレクトリの名前をリストに追加\n",
        "            error_directories.append(directory)\n",
        "            error_directories2.append(e)\n",
        "            continue\n",
        "\n",
        "    # 平均指標を計算\n",
        "    results_df['Average_All'] = results_df[['MSE', 'MAE', 'R2', 'RMSE', 'MAPE', 'MedAE']].mean(axis=1)\n",
        "    results_df['Average_MSE_RMSE'] = results_df[['MSE', 'RMSE']].mean(axis=1)\n",
        "\n",
        "    # 平均MSEとRMSEでソート\n",
        "    sorted_df = results_df.sort_values(by='Average_MSE_RMSE')\n",
        "    error_df = pd.DataFrame(list(zip(error_directories, error_directories2)), columns=['dir', 'error'])\n",
        "    error_csv_path = f\"{parent_folder}/error_directories.csv\"\n",
        "    error_df.to_csv(f\"{parent_folder}/error_directories.csv\", index=False)\n",
        "    try:\n",
        "        if retrain:\n",
        "            # コピー元のパス\n",
        "            src = \"/content/lightning_logs\"\n",
        "            dst= save_directory + f\"lightning_logs\"\n",
        "            dric(dst)\n",
        "            # ディレクトリをコピー\n",
        "            shutil.copytree(src, dst)\n",
        "            dric(f\"{src}\\\\nは {dst} に保存されました\")\n",
        "            csv_path=save_directory+f\"{save_folder_name}_{len(Y_train_df)}_{elapsed_time_str}.csv\"\n",
        "            dric(f\"retrain_csv_path ={csv_path}\")\n",
        "            # 結果をCSVファイルに保存\n",
        "            sorted_df.to_csv(csv_path, index=False)\n",
        "            dric(f\"{csv_path}\\\\nにモデルの評価CSVの保存が完了しました。\",\"\\\\n\",\"-\"*100,\"\\\\n\")\n",
        "        else:\n",
        "            csv_path=save_directory+f\"{save_folder_name}.csv\"\n",
        "            dric(f\"csv_path ={csv_path}\")\n",
        "            # 結果をCSVファイルに保存\n",
        "            sorted_df.to_csv(csv_path, index=False)\n",
        "\n",
        "    except FileNotFoundError as fnf_error:\n",
        "        dric(f\"ファイルが見つかりません: {fnf_error}\")\n",
        "        text_to_speech(f\"ファイルが見つかりません: {fnf_error}\")\n",
        "        traceback.print_exc()\n",
        "        raise e\n",
        "\n",
        "    except Exception as e:\n",
        "        dric(f\"An error occurred: {e}\")\n",
        "        traceback.print_exc()\n",
        "        raise e\n",
        "    return csv_path,error_csv_path\n",
        "\n",
        "\n",
        "\n",
        "def get_directories(path, pattern):\n",
        "    \"\"\"\n",
        "    指定したパスの階層にある、指定したパターンという文字列が含まれたディレクトリの一覧を取得する関数\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path : str\n",
        "        ディレクトリのパス\n",
        "    pattern : str\n",
        "        検索するパターン\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        パターンに一致するディレクトリの一覧\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # パスとパターンを組み合わせて検索するパスを作成\n",
        "        search_path = os.path.join(path, pattern)\n",
        "        # パターンに一致するディレクトリの一覧を取得\n",
        "        directories = [d for d in glob.glob(search_path) if os.path.isdir(d)]\n",
        "        return directories\n",
        "    except Exception as e:\n",
        "        # エラーメッセージを表示\n",
        "        dric(f\"エラーが発生しました: {e}\")\n",
        "        text_to_speech(f\"エラーが発生しました: {e}\")\n",
        "        return []\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "git_save(git_email, git_username, git_token, git_repository)\n",
        "text_to_speech(f\"モデルの再学習と予測の評価　関数が完了しました\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djdCRjeYkPdE"
      },
      "source": [
        "# **モデルの生成**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaht61RHoZ3_"
      },
      "outputs": [],
      "source": [
        "retrain = True #@param {type:\"boolean\"}\n",
        "git_save(git_email, git_username, git_token, git_repository)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fB0qO6MOakdk"
      },
      "outputs": [],
      "source": [
        "#@title **モデルの再学習、予測、評価**\n",
        "if retrain_and_evaluate_model:\n",
        "\n",
        "    y_test=Y_test_df.y.values\n",
        "\n",
        "    # テスト\n",
        "    path = \"/content/drive/MyDrive/\"\n",
        "    # pattern = f\"*{select_loto}_*_f*_h{horizon}*\"\n",
        "    pattern = f\"*25772*\"\n",
        "    # pattern = f\"*cumsum*\"\n",
        "    dric(pattern)\n",
        "    directories = get_directories(path, pattern)\n",
        "    dric(directories)\n",
        "    # 空のデータフレームを作成\n",
        "    model_evaluation_df = pd.DataFrame()\n",
        "    model_evaluation_df_error = pd.DataFrame()\n",
        "    # 各ディレクトリの処理\n",
        "    for i in tqdm(directories):\n",
        "        dric(\"#\"*100,\"\\n\",f\"ディレクトリ {i} の処理を開始します。\")\n",
        "        text_to_speech(f\"ディレクトリ {i} の処理を開始します。\")\n",
        "        csv_path ,error_csv_path= evaluate_models(i,select_loto, target,\n",
        "                                Y_test_df, y_test,gpus,cpus,\n",
        "                                retrain=retrain)\n",
        "        dric(\"#\"*100,\"\\n\",f\"ディレクトリ {i} の処理が完了しました。\")\n",
        "\n",
        "        # select_lotoデータフレームを作成\n",
        "        model_performance_df = pd.read_csv(csv_path)\n",
        "        model_evaluation_df = pd.concat([model_evaluation_df,\n",
        "                                        model_performance_df])\n",
        "        # select_lotoデータフレームを作成\n",
        "        error_df_error = pd.read_csv(error_csv_path)\n",
        "        model_evaluation_df_error = pd.concat([model_evaluation_df_error,\n",
        "                                        error_df_error])\n",
        "    # 'Average_MSE_RMSE'カラムの値でソート\n",
        "    model_evaluation_df = model_evaluation_df.sort_values(by='Average_MSE_RMSE')\n",
        "\n",
        "    # 現在の日時を取得\n",
        "    now = datetime.now(pytz.timezone('Asia/Tokyo'))\n",
        "\n",
        "    # 日時を文字列に変換（例：2024_04_14_00_29_50）\n",
        "    timestamp_str = now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "\n",
        "\n",
        "    # 結果を表示\n",
        "    model_evaluation_df_path =(\n",
        "        f'/content/drive/MyDrive/model_evaluation/'\n",
        "        f'model_evaluation_{select_loto}_{target}_{timestamp_str}.csv')\n",
        "\n",
        "    # ディレクトリが存在しない場合は作成\n",
        "    os.makedirs(os.path.dirname(model_evaluation_df_path), exist_ok=True)\n",
        "\n",
        "    model_evaluation_df.to_csv(model_evaluation_df_path,index=False)\n",
        "\n",
        "    # 結果を表示\n",
        "    model_evaluation_df.to_csv(model_evaluation_df_path,index=False\n",
        "    )\n",
        "git_save(git_email, git_username, git_token, git_repository)\n",
        "text_to_speech(f\"モデルの再学習、予測、評価が完了しました\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRriQBFYpwDb"
      },
      "outputs": [],
      "source": [
        "#@title **評価結果**\n",
        "model_evaluation_df\n",
        "git_save(git_email, git_username, git_token, git_repository)\n",
        "text_to_speech(f\"評価結果が完了しました\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnHVEBdwLdwG"
      },
      "source": [
        "# <font color='Blue'>**モデルの生成**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryyx9uynqgP5"
      },
      "outputs": [],
      "source": [
        "#@title **モデルの生成**\n",
        "try:\n",
        "    if create_model:\n",
        "        feature =len(Y_train_df.columns)\n",
        "        leng =len(Y_train_df)\n",
        "        local_scaler_type=\"standard\"# Y_train_dfに欠損値があるかどうかを確認します\n",
        "        missing_values = Y_train_df.isnull().sum().sum()\n",
        "\n",
        "        # 必要なカラムが存在するか確認します\n",
        "        required_columns = ['ds', 'y', 'unique_id']\n",
        "        missing_columns = [col for col in required_columns if col not in Y_train_df.columns]\n",
        "\n",
        "        if len(missing_columns) > 0:\n",
        "            dric(f\"Y_train_dfには{', '.join(missing_columns)}カラムが欠けています。\")\n",
        "            text_to_speech(f\"Y_train_dfには{', '.join(missing_columns)}カラムが欠けています。\")\n",
        "        else:\n",
        "            # 欠損値の数を計算します\n",
        "            missing_values = Y_train_df.isnull().sum().sum()\n",
        "\n",
        "            # 結果を表示します\n",
        "            if missing_values > 0:\n",
        "                dric(f\"Y_train_dfには{missing_values}個の欠損値があります。\")\n",
        "                text_to_speech(f\"Y_train_dfには{missing_values}個の欠損値があります。\")\n",
        "            else:\n",
        "                dric(\"Y_train_dfには欠損値はありません。\")\n",
        "                text_to_speech(\"Y_train_dfには欠損値はありません。\")\n",
        "\n",
        "                # エラーが発生したモデルとそのエラーメッセージを格納するためのデータフレームを作成\n",
        "                error_df = pd.DataFrame(columns=['model', 'error'])\n",
        "\n",
        "                # すでに存在するモデルのリストを取得\n",
        "                folder_name = f\"{select_loto}_{target}_f{feature}_h{horizon}_l{leng}_n{num_samples}_{backend}\"\n",
        "                if not os.path.exists(folder_name):\n",
        "                    os.makedirs(folder_name)\n",
        "                existing_models = [f.name for f in os.scandir(f'/content/{folder_name}') if f.is_dir()]\n",
        "                # ソースディレクトリのパスのリスト\n",
        "                src_dirs = [f\"/content/{folder_name}\", \"/content/lightning_logs\"]\n",
        "\n",
        "                # 宛先ディレクトリのパス\n",
        "                dst_dir = f\"/content/drive/MyDrive/ColabNotebooks/forecast_loto/{select_loto}/model/{use_reshape_dataframe}/{target}/{horizon}/\"\n",
        "                # ディレクトリが存在しない場合は作成\n",
        "                if not os.path.exists(dst_dir):\n",
        "                    os.makedirs(dst_dir)\n",
        "                # 新しい名前を抽出\n",
        "                new_names = [name.split('_')[0] for name in existing_models]\n",
        "\n",
        "                # 新しい名前を表示\n",
        "                dric(new_names)\n",
        "                error_list = []\n",
        "                try:\n",
        "                    pbar = tqdm(total=len(models), desc=\"モデルの処理\")\n",
        "                    # 空のリストを作成します\n",
        "                    model_results = []\n",
        "                    for model in models:\n",
        "                        dric(model)\n",
        "\n",
        "                        dst_dir1 = f\"/content/{folder_name}\"\n",
        "                        src_dirs1 = [\"/content/lightning_logs\"]\n",
        "\n",
        "                        # First, copy /content/lightning_logs to /content/{folder_name}\n",
        "                        copy_directories(src_dirs1, dst_dir1)\n",
        "\n",
        "                        # Then, copy /content/{folder_name} to /content/drive/MyDrive/\n",
        "                        dst_dir2 = dst_dir\n",
        "                        src_dirs2 = [f\"/content/{folder_name}\"]\n",
        "                        copy_directories(src_dirs2, dst_dir2)\n",
        "                        # すでに存在するモデルはスキップ\n",
        "                        if model.__class__.__name__ in new_names:\n",
        "                            dric(f\"モデル {model.__class__.__name__} はすでに存在します。スキップします。\")\n",
        "                            text_to_speech(f\"モデル {model.__class__.__name__} はすでに存在します。スキップします。\")\n",
        "                            pbar.update(1)\n",
        "                            # continue\n",
        "\n",
        "                        try:\n",
        "                            model_name = model.__class__.__name__\n",
        "                            start_time = time.time()\n",
        "                            dric(\"+\"*100,f\"\\nモデル名: {model.__class__.__name__}\\n\",\"+\"*100)\n",
        "                            text_to_speech(f\"モデル名: {model.__class__.__name__}\")\n",
        "                            nf = NeuralForecast(models=[model], freq=freq, local_scaler_type=local_scaler_type)\n",
        "                            nf.fit(df=Y_train_df)\n",
        "                            elapsed_time = time.time() - start_time\n",
        "                            # elapsed_time_str = str(dt.timedelta(seconds=int(elapsed_time)))\n",
        "                            elapsed_time_str = str(datetime.timedelta(seconds=int(elapsed_time)))\n",
        "                            dric(f\"{model.__class__.__name__}の処理時間: {elapsed_time_str}\")\n",
        "                            path = f'/content/{folder_name}/{model.__class__.__name__}_{str(elapsed_time_str)}/'\n",
        "                            beep()\n",
        "                            nf.save(path=path, model_index=None, overwrite=True, save_dataset=True)\n",
        "                            if Path(path).exists():\n",
        "                                nf2 = NeuralForecast.load(path=path)\n",
        "                                prediction = nf2.predict().reset_index()\n",
        "                                prediction = prediction.iloc[:, 1].values.astype(int)\n",
        "                                dric(f'{path}のモデルによる予測: {prediction}')\n",
        "                                        # モデルの名前、予測結果、処理時間をリストに追加します\n",
        "                                model_results.append({\n",
        "                                    'model': model_name,\n",
        "                                    'prediction': prediction,\n",
        "                                    'elapsed_time': elapsed_time_str\n",
        "                                })\n",
        "                            # 関数の呼び出し\n",
        "                            copy_directories(src_dirs, dst_dir)\n",
        "                            pbar.update(1)\n",
        "                        except Exception as e:\n",
        "                            dric(f'モデル {model.__class__.__name__} のロード中にエラーが発生しました: {str(e)}')\n",
        "                            text_to_speech(f'モデル {model.__class__.__name__} のロード中にエラーが発生しました: {str(e)}')\n",
        "                            error_list.append({'model': model.__class__.__name__, 'error': str(e)})\n",
        "                            traceback.print_exc()\n",
        "                finally:\n",
        "                    pbar.close()\n",
        "\n",
        "                error_df = pd.DataFrame(error_list)\n",
        "                df_model_results = pd.DataFrame(model_results)\n",
        "                # データフレームを特定のディレクトリにCSVファイルとして保存\n",
        "                error_df.to_csv(f'{dst_dir}/{folder_name}/error_df.csv', index=False)\n",
        "                df_model_results.to_csv(f'{dst_dir}/{folder_name}/results_df.csv', index=False)\n",
        "\n",
        "    git_save(git_email, git_username, git_token, git_repository)\n",
        "except Exception as e:\n",
        "    dric(f\"エラーが発生しました: {str(e)}\")\n",
        "    text_to_speech(f\"エラーが発生しました: {str(e)}\")\n",
        "    traceback.print_exc()\n",
        "text_to_speech(f\"モデルの生成が完了しました\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edSwNuazKpEA"
      },
      "outputs": [],
      "source": [
        "#@title **モデルの生成 修正版**\n",
        "\n",
        "if create_model:\n",
        "    feature =len(Y_train_df.columns)\n",
        "    leng =len(Y_train_df)\n",
        "    local_scaler_type=\"standard\"# Y_train_dfに欠損値があるかどうかを確認します\n",
        "    missing_values = Y_train_df.isnull().sum().sum()\n",
        "\n",
        "    # 必要なカラムが存在するか確認します\n",
        "    required_columns = ['ds', 'y', 'unique_id']\n",
        "    missing_columns = [col for col in required_columns if col not in Y_train_df.columns]\n",
        "\n",
        "    if len(missing_columns) > 0:\n",
        "        dric(f\"Y_train_dfには{', '.join(missing_columns)}カラムが欠けています。\")\n",
        "        text_to_speech(f\"Y_train_dfには{', '.join(missing_columns)}カラムが欠けています。\")\n",
        "    else:\n",
        "        # 欠損値の数を計算します\n",
        "        missing_values = Y_train_df.isnull().sum().sum()\n",
        "\n",
        "        # 結果を表示します\n",
        "        if missing_values > 0:\n",
        "            dric(f\"Y_train_dfには{missing_values}個の欠損値があります。\")\n",
        "            text_to_speech(f\"Y_train_dfには{missing_values}個の欠損値があります。\")\n",
        "        else:\n",
        "            dric(\"Y_train_dfには欠損値はありません。\")\n",
        "            text_to_speech(\"Y_train_dfには欠損値はありません。\")\n",
        "\n",
        "            # エラーが発生したモデルとそのエラーメッセージを格納するためのデータフレームを作成\n",
        "            error_df = pd.DataFrame(columns=['model', 'error'])\n",
        "\n",
        "            # すでに存在するモデルのリストを取得\n",
        "            folder_name = f\"f{feature}_h{horizon}_le{leng}_n{num_samples}_{backend}\"\n",
        "            if not os.path.exists(folder_name):\n",
        "                os.makedirs(folder_name)\n",
        "            existing_models = [f.name for f in os.scandir(f'/content/{folder_name}') if f.is_dir()]\n",
        "            # ソースディレクトリのパスのリスト\n",
        "            src_dirs = [f\"/content/{folder_name}\", \"/content/lightning_logs\"]\n",
        "\n",
        "            # 宛先ディレクトリのパス\n",
        "            dst_dir = f\"/content/drive/MyDrive/ColabNotebooks/forecast_loto/{select_loto}/model/{use_reshape_dataframe}/{target}/{horizon}/\"\n",
        "            # ディレクトリが存在しない場合は作成\n",
        "            if not os.path.exists(dst_dir):\n",
        "                os.makedirs(dst_dir)\n",
        "            # 新しい名前を抽出\n",
        "            new_names = [name.split('_')[0] for name in existing_models]\n",
        "\n",
        "            # 新しい名前を表示\n",
        "            dric(new_names)\n",
        "            error_list = []\n",
        "\n",
        "            # 新しい名前を表示\n",
        "            dric(new_names)\n",
        "\n",
        "            # モデルの処理を開始します\n",
        "            pbar = tqdm(total=len(models), desc=\"モデルの処理\")\n",
        "            model_results = []  # 空のリストを作成します\n",
        "            for model in models:\n",
        "                dric(model)\n",
        "\n",
        "                # すでに存在するモデルはスキップ\n",
        "                if model.__class__.__name__ in new_names:\n",
        "                    dric(f\"モデル {model.__class__.__name__} はすでに存在します。スキップします。\")\n",
        "                    text_to_speech(f\"モデル {model.__class__.__name__} はすでに存在します。スキップします。\")\n",
        "                    pbar.update(1)\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    # モデルの名前を取得します\n",
        "                    model_name = model.__class__.__name__\n",
        "                    start_time = time.time()\n",
        "                    dric(\"+\"*100, f\"\\nモデル名: {model.__class__.__name__}\\n\", \"+\"*100)\n",
        "                    text_to_speech(f\"モデル名: {model.__class__.__name__}\")\n",
        "\n",
        "                    # モデルを訓練します\n",
        "                    nf = NeuralForecast(models=[model], freq=freq, local_scaler_type=local_scaler_type)\n",
        "                    nf.fit(df=Y_train_df)\n",
        "\n",
        "                    # 処理時間を計算します\n",
        "                    elapsed_time = time.time() - start_time\n",
        "                    elapsed_time_str = str(dt.timedelta(seconds=int(elapsed_time)))\n",
        "                    dric(f\"{model.__class__.__name__}の処理時間: {elapsed_time_str}\")\n",
        "                    # 宛先ディレクトリのパス\n",
        "                    dst_dir = f\"{dst_dir}/{select_loto}/model/{use_reshape_dataframe}/{target}/{horizon}/\"\n",
        "                    # ディレクトリが存在しない場合は作成\n",
        "                    if not os.path.exists(dst_dir):\n",
        "                        os.makedirs(dst_dir)\n",
        "                    # モデルを保存します\n",
        "                    path = f'{dst_dir}/{folder_name}/{model.__class__.__name__}_f{feature}_l{leng}_{bal}_t{elapsed_time_str}/'\n",
        "                    nf.save(path=dst_dir, model_index=None, overwrite=True, save_dataset=True)\n",
        "\n",
        "\n",
        "                    if Path(path).exists():\n",
        "                        # 保存されたモデルをロードします\n",
        "                        nf2 = NeuralForecast.load(path=path)\n",
        "                        # モデルを使って予測を行います\n",
        "                        prediction = nf2.predict().reset_index()\n",
        "                        prediction = prediction.iloc[:, 1].values.astype(int)\n",
        "                        dric(f'{path}のモデルによる予測: {prediction}')\n",
        "                        text_to_speech(f'{path}のモデルによる予測: {prediction}')\n",
        "\n",
        "                        # モデルの名前、予測結果、処理時間をリストに追加します\n",
        "                        model_results.append({\n",
        "                            'model': model_name,\n",
        "                            'prediction': prediction,\n",
        "                            'elapsed_time': elapsed_time_str\n",
        "                        })\n",
        "\n",
        "                        # 関数の呼び出し\n",
        "                        copy_directories(src_dirs, dst_dir)\n",
        "                        pbar.update(1)\n",
        "\n",
        "                    # エラーリストをデータフレームに変換します\n",
        "                    error_df = pd.DataFrame(error_list)\n",
        "                    # モデルの結果をデータフレームに変換します\n",
        "                    df_model_results = pd.DataFrame(model_results)\n",
        "\n",
        "                    # データフレームを特定のディレクトリにCSVファイルとして保存します\n",
        "                    error_df.to_csv(f'{dst_dir}/{folder_name}/error_df.csv', index=False)\n",
        "                    df_model_results.to_csv(f'{dst_dir}/{folder_name}/results_df.csv', index=False)\n",
        "\n",
        "                    # gitに保存します\n",
        "                    git_save(git_email, git_username, git_token, git_repository)\n",
        "                except Exception as e:\n",
        "                    # エラーが発生した場合は、エラーメッセージを保存します\n",
        "                    error_df = error_df.append({'model': model.__class__.__name__, 'error': str(e)}, ignore_index=True)\n",
        "                    dric(f\"モデル {model.__class__.__name__} の処理中にエラーが発生しました: {str(e)}\")\n",
        "                    text_to_speech(f\"モデル {model.__class__.__name__} の処理中にエラーが発生しました: {str(e)}\")\n",
        "                    traceback.print_exc()\n",
        "                finally:\n",
        "                    # プログレスバーを更新します\n",
        "                    pbar.update(1)\n",
        "ray.shutdown()\n",
        "text_to_speech(f\"モデルの生成　修正が完了しました\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zULSMaCg2fb8"
      },
      "outputs": [],
      "source": [
        "#@title **EDA**\n",
        "\n",
        "bal=f\"{target}_{window}\"\n",
        "pdpf_report_path= f\"/content/drive/MyDrive/pdpf_{select_loto}_{bal}_f_{feature}_len_{leng}\"\n",
        "profile = ProfileReport(merged_str_df, title=f\"pdpf_{select_loto}_{bal}_f_{feature}_len_{leng}\")\n",
        "profile.to_file(f\"{pdpf_report_path}.html\")\n",
        "report =create_report(merged_df)\n",
        "dtp_report_path= f\"/content/drive/MyDrive/dtp_{select_loto}_{bal}_f_{feature}_len_{leng}\"\n",
        "report.save(dtp_report_path)\n",
        "git_save(git_email, git_username, git_token, git_repository)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1peeNSQYaPm7ZYWesWiHDWNHNTt4ITdHb",
      "authorship_tag": "ABX9TyNJl0BTDbbvJatO6WDPQlZW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e817324ff0c4cdd8b0428953532722c": {
          "model_module": "jupyter-vue",
          "model_name": "HtmlModel",
          "model_module_version": "^1.11.1",
          "state": {
            "_dom_classes": [],
            "_events": [],
            "_jupyter_vue": "IPY_MODEL_ef883e9ab43743a9bae3ca996c56945a",
            "_model_module": "jupyter-vue",
            "_model_module_version": "^1.11.1",
            "_model_name": "HtmlModel",
            "_view_count": null,
            "_view_module": "jupyter-vue",
            "_view_module_version": "^1.11.1",
            "_view_name": "VueView",
            "attributes": {},
            "children": [
              "統計結果の保存データのロード"
            ],
            "class_": null,
            "layout": null,
            "slot": null,
            "style_": null,
            "tag": "h2",
            "v_model": "!!disabled!!",
            "v_on": null,
            "v_slots": []
          }
        },
        "6c7915c1fbed45689f279ebfd98ec936": {
          "model_module": "jupyter-vuetify",
          "model_name": "LayoutModel",
          "model_module_version": "^1.8.5",
          "state": {
            "_dom_classes": [],
            "_events": [],
            "_jupyter_vue": "IPY_MODEL_ef883e9ab43743a9bae3ca996c56945a",
            "_metadata": null,
            "_model_module": "jupyter-vuetify",
            "_model_module_version": "^1.8.5",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "jupyter-vuetify",
            "_view_module_version": "^1.8.5",
            "_view_name": "VuetifyView",
            "align_baseline": null,
            "align_center": null,
            "align_content_center": null,
            "align_content_end": null,
            "align_content_space_around": null,
            "align_content_space_between": null,
            "align_content_start": null,
            "align_end": null,
            "align_start": null,
            "attributes": {},
            "children": [
              "IPY_MODEL_d7a2a06b29364c84bb52b9ceda58386e",
              "IPY_MODEL_ba71d7a9fbc54fb48ac4621c169f9407"
            ],
            "class_": null,
            "column": null,
            "d_block": null,
            "d_contents": null,
            "d_flex": null,
            "d_grid": null,
            "d_inherit": null,
            "d_initial": null,
            "d_inline": null,
            "d_inline_block": null,
            "d_inline_flex": null,
            "d_inline_grid": null,
            "d_inline_table": null,
            "d_list_item": null,
            "d_none": null,
            "d_run_in": null,
            "d_table": null,
            "d_table_caption": null,
            "d_table_cell": null,
            "d_table_column": null,
            "d_table_column_group": null,
            "d_table_footer_group": null,
            "d_table_header_group": null,
            "d_table_row": null,
            "d_table_row_group": null,
            "fill_height": null,
            "id": null,
            "justify_center": null,
            "justify_end": null,
            "justify_space_around": null,
            "justify_space_between": null,
            "justify_start": null,
            "layout": null,
            "ma_0": null,
            "ma_1": null,
            "ma_2": null,
            "ma_3": null,
            "ma_4": null,
            "ma_5": null,
            "ma_auto": null,
            "mb_0": null,
            "mb_1": null,
            "mb_2": null,
            "mb_3": null,
            "mb_4": null,
            "mb_5": null,
            "mb_auto": null,
            "ml_0": null,
            "ml_1": null,
            "ml_2": null,
            "ml_3": null,
            "ml_4": null,
            "ml_5": null,
            "ml_auto": null,
            "mr_0": null,
            "mr_1": null,
            "mr_2": null,
            "mr_3": null,
            "mr_4": null,
            "mr_5": null,
            "mr_auto": null,
            "mt_0": null,
            "mt_1": null,
            "mt_2": null,
            "mt_3": null,
            "mt_4": null,
            "mt_5": null,
            "mt_auto": null,
            "mx_0": null,
            "mx_1": null,
            "mx_2": null,
            "mx_3": null,
            "mx_4": null,
            "mx_5": null,
            "mx_auto": null,
            "my_0": null,
            "my_1": null,
            "my_2": null,
            "my_3": null,
            "my_4": null,
            "my_5": null,
            "my_auto": null,
            "pa_0": null,
            "pa_1": null,
            "pa_2": null,
            "pa_3": null,
            "pa_4": null,
            "pa_5": null,
            "pa_auto": null,
            "pb_0": null,
            "pb_1": null,
            "pb_2": null,
            "pb_3": null,
            "pb_4": null,
            "pb_5": null,
            "pb_auto": null,
            "pl_0": null,
            "pl_1": null,
            "pl_2": null,
            "pl_3": null,
            "pl_4": null,
            "pl_5": null,
            "pl_auto": null,
            "pr_0": null,
            "pr_1": null,
            "pr_2": null,
            "pr_3": null,
            "pr_4": null,
            "pr_5": null,
            "pr_auto": null,
            "pt_0": null,
            "pt_1": null,
            "pt_2": null,
            "pt_3": null,
            "pt_4": null,
            "pt_5": null,
            "pt_auto": null,
            "px_0": null,
            "px_1": null,
            "px_2": null,
            "px_3": null,
            "px_4": null,
            "px_5": null,
            "px_auto": null,
            "py_0": null,
            "py_1": null,
            "py_2": null,
            "py_3": null,
            "py_4": null,
            "py_5": null,
            "py_auto": null,
            "reverse": null,
            "row": null,
            "slot": null,
            "style_": null,
            "tag": null,
            "v_model": "!!disabled!!",
            "v_on": null,
            "v_slots": [],
            "wrap": null
          }
        },
        "d7a2a06b29364c84bb52b9ceda58386e": {
          "model_module": "jupyter-vuetify",
          "model_name": "HtmlModel",
          "model_module_version": "^1.9.4",
          "state": {
            "_dom_classes": [],
            "_events": [],
            "_jupyter_vue": "IPY_MODEL_ef883e9ab43743a9bae3ca996c56945a",
            "_model_module": "jupyter-vuetify",
            "_model_module_version": "^1.9.4",
            "_model_name": "HtmlModel",
            "_view_count": null,
            "_view_module": "jupyter-vuetify",
            "_view_module_version": "^1.9.4",
            "_view_name": "VuetifyView",
            "attributes": {},
            "children": [
              "load"
            ],
            "class_": "d-inline-block",
            "layout": null,
            "slot": null,
            "style_": "font-size: 30px; vertical-align: middle;",
            "tag": "span",
            "v_model": "!!disabled!!",
            "v_on": null,
            "v_slots": []
          }
        },
        "ba71d7a9fbc54fb48ac4621c169f9407": {
          "model_module": "jupyter-vuetify",
          "model_name": "CheckboxModel",
          "model_module_version": "^1.8.5",
          "state": {
            "_dom_classes": [],
            "_events": [],
            "_jupyter_vue": "IPY_MODEL_ef883e9ab43743a9bae3ca996c56945a",
            "_metadata": null,
            "_model_module": "jupyter-vuetify",
            "_model_module_version": "^1.8.5",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "jupyter-vuetify",
            "_view_module_version": "^1.8.5",
            "_view_name": "VuetifyView",
            "append_icon": null,
            "attributes": {},
            "background_color": null,
            "children": [],
            "class_": "ma-2 d-inline-block",
            "color": "primary",
            "dark": null,
            "dense": null,
            "disabled": null,
            "error": null,
            "error_count": null,
            "error_messages": null,
            "false_value": null,
            "height": null,
            "hide_details": null,
            "hint": null,
            "id": null,
            "indeterminate": null,
            "indeterminate_icon": null,
            "input_value": null,
            "label": null,
            "layout": null,
            "light": null,
            "loading": null,
            "messages": null,
            "multiple": null,
            "off_icon": null,
            "on_icon": null,
            "persistent_hint": null,
            "prepend_icon": null,
            "readonly": null,
            "ripple": null,
            "rules": null,
            "slot": null,
            "style_": "width: 60px; height: 60px; font-size: 400px; font-family: Arial, sans-serif; vertical-align: middle;",
            "success": null,
            "success_messages": null,
            "true_value": null,
            "v_model": false,
            "v_on": null,
            "v_slots": [],
            "validate_on_blur": null,
            "value": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}